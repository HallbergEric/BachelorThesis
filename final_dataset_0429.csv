Id,Body_new
62363403,"I have a client website that serves the images through AWS CloudFront and S3  The images are in PNG format and the URL on the webpage is of the CloudFront domain rather than the custom domain  In order to reduce costs  we are planning to compress them to JPG format  However  we have found that the image URLs are hardcoded in the database  
The problem is when we compress the image to JPG  the file extension changes and thus the old URL will not work as it is  The client does not wants to make changes to the database right now  
Is there a way we can serve the compressed files (with a different extension) for the same requests coming from the webpage 
I was looking into a solution to route requests using Lambda Edge -  
Is there any other optimal solution for this which you could suggest  Is there a way CloudFront to check for both types of file (jpg and png) in S3 and serve one of them  Example: request came for images/car png -- &gt; CloudFront to check for both images/car png and images/car jpg  If jpg exists serve this one 
"
57220692,"I would like to get the usage cost report of each instance in my aws account form a period of time 
Im able to get linked_account_id and service in the output but I need instance_id as well  Please help

"
56704657,"Im confused about Firebase and serverless in general  as I was just introduced to this concept recently (note that Im still studying computer science and Im just exploring on my own now) 
In the past Ive been part of a project that had the following structure:

Front End in a Single-page-app
Back End built as a REST API

Now lets say I want to build a product  that might have a website and mobile apps  It also has to have backend logic as there are accounts  objects owned by users  and possible integration with a payment service 
What I initially expected from this  before knowning about serverless  is that you build a backend using something like Go (was my case)  where you handle all the database data and third-party integrations  build a front end with something like Vue  and then use the backends REST API to communicate between both of them 
Is this still the case with serverless  Do you build the whole backend server code  or does it work in another way 
I dont need/want you to explain all of it to me  I just need some insight on what is done and common so I can investigate further 
"
44863996,"I am making a simple app where the user can create a text post and optionally include media (pictures only for now  but videos in the future) 
Currently  the user sends a  request to API Gateway that invokes a Lambda function that inserts the post data into the database  This works great  API Gateway uses body mapping to format the event data  
In order to upload the media  it seems I have at least three options:

Make the HTTP  request as normal THEN upload the media to S3 (via Cloudfront )  

S3 would trigger a Lambda function that updates the post record with the media url 
This would require at least 2 API invocations on the frontend  - - 
What if the media upload fails  I would have to invoke another Lambda function to delete the post  What if that fails  This is a rabbit hole 

Upload the media to S3 (via Cloudfront ) THEN make the HTTP  request  

This would require 2 API invocations on the frontend  - - 
What if the  request fails  I would have extra objects in my bucket  I suppose I could have a bucket cleaning scheduled task but ugg  
Would the S3 key not correspond to the  of the post  ( is generated on database insertion )

Upload the media with the HTTP  request in  

This is how I have done it in the past  but I have also had a web server (not lambda)  If the photo isnt huge  the transfer to S3 should be relatively quick and my lambda costs wont increase too drastically  But what if I decide to add video  Now my lambda invocations would be seconds long  


What is the best practice here  This seems like a common problem but all the guides Ive found online are not concerned with the post data (only media data)  
"
56580868,"I have an AWS Lambda function which does a couple of API calls then saves whatever information it gets to a DynamoDB table 
Would it be a good practice for me send a message to an SQS queue after completing whatever the Lambda was doing  The queue will then trigger the Lambda function to start another process again 
So with regards to processing and the costs involved  is this a good idea or not 
The other idea I had was to trigger the Lambda function using a CloudWatch Event but the problem is I want it to start the new process once the old one has completed so if it happens that the Lambda function gets triggered while processing its then going to stuff up my records on DynamoDB 
So if anyone has a better solution or alternative let me know 
"
60682030,"I am working on an integration with a Vendor that can only send me XML requests in a predefined structure
That is not compatible with my system  
Changing the structure of the XML is possible but might be an expensive project if the Vendor would do it for me  
To try and solve this issue i was wondering  would it be possible to convert the said XML requests to JSON on the fly using an AWS Lambda function  
I was thinking about a solution in which an XML requests comes in from the Vendor to my ALB  converted to a JSON request using a Lambda function and returned to my system for processing in a JSON format  
Would this be a scalable solution 
"
69724457,"I am using AWS Lambda to host a nodeJs service that fetch my open invoices on Stripe and execute a payment and update my database 
The problem is that most of the time  but not all the time (sometimes everything goes how it should)  it hang on the call of invoice list and do nothing 
Heres the part of the code where log stops :

And here the log output :

And when it gooes all right its like that :

I dont get why it hangs with no error or log   
"
61312110,"Im creating my application with the as much serverless as possible premise  
Long story short  2 services cannot be implemented as lambda functions  hence I bet on ECS tasks with EC2 autoscaling groups  due to GPU requirements  etc  
After doing my homework on the Lambda + VPC resources lesson I was shocked theres no easy and pleasant way to expose VPC services extension of AWS services  So the official approach stands for incorporating a lambda function into a VPC plus establishing a NAT gateway/instance or VPC endpoints in order to reach the internet and AWS services  Moreover  I can read this is not recommended and should be treated as the final solution  It slows down lambda and increases cold starts 
Generally  I need access to the internet and reach other AWS services from the lambda  which must make requests to ECS tasks  Those tasks are crucial contributors to my flow Id like them to be easily callable from lambda functions  Im not sure if VPC lambdas would make sense if I need to pay for NAT  which is comparatively expensive  Maybe I missed something 
Is it possible to avoid incorporating lambdas into VPC and still be able to call ECS services  If not  what is the best way to cuts costs related to NAT 
Id appreciate any form of help 
"
58410362,"Ive already managed to create a lambda function that loads a model pb from S3 and apply object detection to an input image (installed tensorflow 1 12)
Is it possible to load a Sagemaker model/endpoint-configuration inside a lambda function   I mean install all packages needed inside the lambda  without deploying an endpoint/ec2-like instance 
I guess inference performance would drop  but the solution seems to be more cost effective and scalable ready 
"
35108295,"Id like to do Universal rendering of react components using serverless  react-router  lambda  API gateway and Cloudflare  How would you map the API gateway endpoint URLs to a server-side instance of react-router running inside an AWS lambda function in a way that was compatible with Cloudflare 
I found an interesting hack/approach to doing it with CloudFront (  )  but Id prefer using Cloudflare for cost and DDoS attack prevention reasons 
Thanks 
"
52972258,"Im new to AWS Lambda (and AWS in general)  I need to write some development code for AWS 
Since Lambda functions are billed by execution time and number of requests  Id like to guarantee that no out-of-control function or route spam would skyrocket costs out of my budget and put me in debt  (It is development code  so I expect there to be mistakes and I dont want them to be expensive ones )
I know AWS has budget alarms which send you emails  but this is not good enough for me  since it might take days/weeks until I notice a message somewhere 
Is there a way to tell AWS to shut down a service if it is exceeding a budget  Im looking for something similar to what DigitalOcean does  where you can set a fixed budget 
"
71469455,"Lets say a user needs some information from a database  When the user clicks a button  a request is routed through cloudfront to lambda at edge  which puts the request on an SQS queue  The SQS sends a batch of requests over to a lambda function  For each request  the lambda pulls relevant information from a dynamodb instance and returns it back to the client 
Is this flow possible  Whats missing to me here is how the request is actually routed back to the client session  Ive worked with API-Gateways where requests are sent to methods  I assume API-Gateway handles the routing here  but it isnt clear to me what exactly is happening when a request goes through cloudfront 
If the flow I first shared doesnt make sense  how would you set up a flow to handle 10 000 or 20 000 of these requests a minute  It seems having lambda handle requests in batches is the only possible way to do this with serverless  individual lambda instances just screw you on the start up/spin down times and costs
"
65786713,"Im having a Microservice Architecture completely build around AWS Lambda  also including a producer/listener which is loosely-coupled via SQS to the business lambda functions  Its working nicely via following approach:

lambda has a reserved concurrency of 1
gets triggered every 1 minute via CloudWatch Events: as the max concurrency is 1  if one instance is running  there wont be a parallel invocation if a function is already provisioned
if the function approaches the timeout of 15 minutes  it will shutdown itself gracefully

I did not experience any troubles yet &amp; the solution is really cost-efficient but as you probably already noticed  theres at least one major downside: the consumer/producer will be offline for up to 1 x minutes (next CloudWatch invocation could take up to 59s + bootstrapping the producer/listener) every ~15 minutes (max execution time for Lambda) 
Im not having any hard real-time requirements  but Im sure theres a better approach or improvements without switching to running a container in ECS  what I really want to avoid 
What are my options 
"
69285126,"mouthful title but the point is this  I have some data science pipelines with these requirements ( based):

are orchestrated with an internal orchestrator based off on a server
are run across a number of users/products /etc where N could be relatively high
the load of this jobs I want to distribute and not be tethered by the orchestrator server
these jobs are backed by a docker image
these jobs are relatively fast to run (from 1 second to 20 seconds  post data load)
these jobs most often require considerable I/O both coming in and out 
no  required
I want minimal hassle with scaling/provisioning/etc
data (in/out) would be stored in either a  space in a cluster or 
 image would be relatively large (encompasses data science stack)

I was trying to understand the most (a) cost-efficient but also (b) fast solution to parallelize this thing  candidates so far:


 with Container Image Support

please note for all intents and purposes scaling/computing within the cluster is not feasible
my issue is that I worry about the tradeoffs about huge data transfers (in aggregate terms)  huge costs in calling  images a bunch of times  time you would spend setting up containers in servers but very low time doing anything else  serverless management and debugging when things go wrong in case for lambda functions 
how generally are handled these kind of cases 
"
51475033,"So I have been working on a couple Lambda functions for a Alexa skills including DynamoDB (actually 5 tables each with 5 RCU/WCU  I am on the free tier and I havent used the work-in-progress functions for a couple of days  but today I realized in the cost overview that I have used about 9000 hours and will possibly use about 12000 at the end of the month  See here:

So was wondering why 
I know that you reserve the hourly capacity  And since none of the skills is live  I sticked with 5 RCU/WCU for each table (it says 25 RCU/WCU is okay for the free tier)  But these numbers doesnt make sense  
Or do they  
And the question is what happens when I scale this down to 1 RCU/WCU when all the skills go live  
I know that this would mean that only one request per second can be processed  but I am sure that this would be enough for the skills (at least for the first couple of month) - I guess that I wont have more than 200-300 monthly users  Will this significantly reduce the above numbers  Or will I be charged huge bill for some reason I dont understand after going though the documentation 
"
41789192,"How to build serverless web site on Azure  as auto-scaling  pay-per-execution  event-driven app 
There are tons of good examples how to build serverless-arhitecture web site on AWS Amazon  e g  
It consumes S3 for HTML and JS  Lambda for REST API  Simple DB for data 
Microsoft has Azure Functions that is analogue for AWS Lambda  but it is serverless computing  not serverless web site  I can create serverless REST API with Azure Functions  but what about HTML  JS  CSS for web site  database  etc   
I tried Azure App Service  but it lacks pay only for what you use option  as all plans have Monthly payments  as well as Azure SQL for database  And App Service doesnt seem to be constructed to host serverless-architecture web sites  more for classic ASP NET web sites that you can easily deploy there 
Also  there is popular library  and they even mentioned Azure: using AWS Lambda  Azure Functions  Google CloudFunctions &amp; more  but there is no a single example how to use it for Azure and all Docs are for Amazon AWS 
Thanks 
"
62491950,"Currently  my application resides in lambda which I serve using HTTP API (API Gateway V2)  This setup exists in multiple regions  Meaning  API Gateway invokes lambda in the same region which accesses DynamoDB Global Table in the same region  I use Route 53 to serve nearest API Gateway to user 
The problem I faced: API Gateway doesnt support redirection from http to https  I can achieve this with CloudFront  But  itll increase cost as well as latency 
Can I remove API Gateway from the equation and use Lambda@Edge to access DynamoDB Table near the user  Can CloudFront be used to replace API Gateway 
"
62356635,"I have a use case where an API backed by a lambda has to be latency critical for a few clients but there are clients how call the API with high volume in bursts and the latency restrictions are liberal   
We are using provisioned concurrency for the latency critical calls and do not want to use it for non latency critical calls as the cost is high  
Since provisioned concurrency can only be used with alias/version  is it possible to choose the lambda version at runtime based on the API Key 
Determine the client based on the API Key and point to the appropriate version  I am trying to avoid creating 2 API endpoints one for latency critical clients and the other for non-latency critical clients  
"
61241060,"I have a lambda function accessing a S3 bucket using 
There are a high number of operations(requests) to the S3 bucket  which is increasing considerably the cost to use lambda 
I was hoping that the requests use the  protocol but there are going over the internet
I understand that one solution could be:

Attach the Lambda to a VPC 
Create a VPC endpoint to S3
Update the route tables of the VPC 

Is there a simpler way to do so  
"
39249813,"I am submitting tasks (eventually this will be hundreds of thousands of tasks) to AWS lambda using   and I am interested in performance characteristics of the task: execution time  memory usage  etc 
Note that I will eventually want to compute various performance statistics and plots of the submitted tasks in costum code 
"
57070054,"I made some research about Containers  Serverless  and Virtual machines all of these has its own benefits like cost  deployments  reliability  etc  but I am still confused when to use these  and what kind of situations 
"
62959419,"I use AWS Simple Email Services (SES) for email  Ive configured SES to save incoming email to an S3 bucket  which triggers an AWS Lambda function  This function reads the new object and forwards the object contents to an alternate email address 
Id like to log some basic info  from my AWS Lambda function during invocation -- who the email is from  to whom it was sent  if it contained any links  etc 
Ideally Id save this info  to a database  but since AWS Lambda functions are costly (relatively so to other AWS ops )  Id like to do this as efficiently as possible 
I was thinking I could issue an HTTPS GET request to a private endpoint with a query-string containing the info  I want logged  Since I could fire my request async  at the outset and continue processing  I thought this might be a cheap and efficient approach 
Is this a good method  Are there any alternatives 
My Lambda function fires irregularly so despite Lambda functions being kept alive for 10 minutes or so post-firing  it seems a database connection is likely slow and costly since AWS charges per 100ms of usage 
Since I could conceivable get thousands of emails/month  ensuring my Lambda function is efficient is paramount to cost  I maintain 100s of domain names so my numbers arent exaggerated  Thanks in advance 
"
60253671,"I have an AWS Lambda function written in python that is starting to get a bit too big  It often runs over the AWS Lambda limit of 15 minutes  
The function is responsible for making loads of API calls  and unfortunately I have not taken the time to make them all async yet 
The workflow for the function looks something roughly like this:

Receive data for xxx clients (1 api call)
Place API call for each client and wait for response (xxx api calls)
Based on #2 API call response  place yet another API call for each client and wait for response (xxx api calls)
Store response from #3 in DynamoDB (xxx DB updates)

Initially my plan was to just keep everything in 1 lambda function  and modify my code such that all API calls run async  and to do one big dynamoDB batch update at the end 
However  it occurs to me that theoretically this function could still grow too large in the future  if we start needing to run it for enormous numbers of clients  Additionally  in my opinion  managing all those python async calls can be a bit cumbersome in specific situations 
My second approach  is to chain together lambda functions  That is  create a second lambda function  lets name it order_for_single_client  which perform steps #2-4 for just one client 
The top level lambda function will gather data on all clients  and for each one  make a separate lambda call to order_for_single_client  So  if we need to order for 500 clients  the top level function will just make 500 separate lambda calls  Naturally  all the async behavior should take care of itself on the end of AWS since it will run the lambda functions in parallel  (with the exception of the batch dynamoDB update we wanted  but we can worry about that later) 

What is the preferred way of handling this situation from an architecture perspective  Splitting things up into a lambda chain  or trying to speed things up using async inside a single lambda function 
If we were to implement the lambda chain  will it be more or less expensive to run at scale compared to the single function async approach 
Is there a third design solution to this problem that I have not considered  (Apart from spinning up an EC2 instance  which I would prefer not to do) 

"
61437558,"I am looking to work on real-time chat application in a serverless architecture  
I am new to AWS so did some research on it but I found may option to do so 
Like: 

app sync
WebSocket
elasticache redis

I am a bit confused about which I should go with 
I am looking for a cost-effective(low charges) setup for my app 
"
66247419,"Ie read AWS Lambda documentation for Quarkus ad it looks pretty interesting 
Id like to deploy on AWS some Quarkus native lambda as explained here   my goal is to leverage Java ecosystem power (and not have JS NPM based Lambda) and still having very low cold and warm execution time  in order to lower AWS billing 
I do not want to code the logic who maps the requests on the right controllers method  like this :

Too expensive to code and error prone  its a show stopper for me
Rather Id like to leverage a mechanism such as the one described here  : long story short the Lambda Handler maps the Lambda input data (Stream  Context  etc  ) to a Http Request and the JAX-RS implementation does the rest of the work  or something similar  responsibilities are not completely clear to me 
This is very interesting because you can continue write your controllers as always  with annotation and all the stuff and your lambda stays very simple and just maps the objects :

Do a ProxyStream implementation exist for Jersey  Spring and other framework  do a similar ProxyImplementation exist for Quarkus JAX-RS implementation (Jackson  )
"
44230875,"Im trying to make each call to lambda to log the billed duration  to track the cost of using lambda 
When you invoke lambda with SDK or CLI  you could easily get the LogResult by just adding the parameter 
Then you get the LogResult as a part of Response  where you can extract the billed duration 
Now  I was trying to do similar thing when we invoke lambda through API Gateway 
How could I get the LogResult and BilledDuration in this case 
"
51202756,"I have an AWS SQS queue that Im going to setup with a Lambda function trigger to run the Lambda function for every item that gets added to the queue to do some processing work 
One step of processing is going to be hitting an API endpoint to get some data back for every item added to the queue  then storing that away in an DynamoDB table  In order to manage costs  and stay in control of this process Im wanting to throttle the amount of times this Lambda function gets called in a certain period of time 
For example  I want this function to be run a maximum of 100 times per day  in order to not overwhelm the DynamoDB table capacity or the API endpoint  It would also be nice to throttle it  to where it will only have a maximum of 5 concurrent actions being run at once  with a 1 second delay between running again  This type of control would allow me to directly map the function to the DynamoDB table limits to ensure Im not going over capacity  and to I comply with any API rate limits  
I have looked into   Specifically the Function Level Concurrent Execution Limit section  But this section doesnt seem to address the 100 times per day limit  or the 1 second delay between running the next function 
I also know that I could just limit it on the other side  by limiting the number of items I put in the queue at a time (or per day)  But because of how Im planning this system  that would add a lot of complexity that I would love to try to avoid 
Is there a way using AWS SQS and Lambda to achieve this and limit these Lambda functions 
"
53781371,"I need to create something on Azure that can process incoming streams of messages for a set of entities  We will have anywhere between 20 and 2 000 entities at any point in time; these get created and discarded dynamically  Messages will be generated using our on-premises system  and sent to Azure using some queueing mechanism  Each message will be associated with a specific entity through an  property  Messages belonging to the same entity must be processed in-order with respect to each other  
At the same time  the solution must be scalable with respect to entities  If I have steady streams of messages for 1 000 entities  Id want to have 1 000 concurrent executions of my logic  If an entity takes a long time to process one of its messages  this must not block any of the other entities from processing their messages  Each message may take anywhere from 100ms to 10s to process (vast majority below 1s)  and each entity would receive an average of one message per second 
Disappointingly  the Azure serverless stack does not seem to have any means of achieving this  These are the options Ive considered and their problems:

Azure Functions triggered by Service Bus queue with sessions  Azure Functions can be run as serverless on a consumption plan  making them perfect for elastic scaling  Service Bus sessions provide for in-order delivery  and are the closest implementation of my requirements  However  they are not supported in Azure Functions:  
Logic Apps triggered by Service Bus queue with sessions: This is supported out-of-the-box through the  template  The Logic App can then hook to an HTTP-triggered Azure Function for processing messages  The Logic Apps only purpose is to prevent multiple messages belonging to the same entity/session from being processed concurrently  However  from the comments to my   I found this would not be scalable either  A Logic App can only execute 300 000 actions per 5 minutes  has a trigger concurrency limit of 50  and is said to be expensive  See  
Azure Event Hubs with partitions  as discussed in   This tends to be the most popular option  and the one recommended by Microsoft  However  Event Hubs only permit up to 32 partitions  with the number of partitions needing to be specified at creation:   This limitation of a fixed static set of partitions goes against the spirit of serverless; if were limiting our degree of parallelism to 32  then were not getting any better scalability than a parallel application running on a 32-core machine  The partition limit can be increased beyond 32 via a support ticket to Microsoft  but I wouldnt want to ask for scalability thats two orders of magnitude beyond whats available for general use  Event Hubs also lack some other basic properties  such as at-most-once delivery 
We can dynamically create a Service Bus queue per entity  and have a singleton Azure Function spawned for it  bound exclusively to that specific queue  However  this would entail invoking the Azure resource management APIs as part of our operational code  and my impression is that Azure Functions werent designed to be spawned dynamically this way 
Optimistic concurrency control against a persistent backing store  such as Redis  using the  property of the Service Bus queue messages for ordering  However  the programming model for this is quite complex and easy to get wrong – operations need to be performed in retry loops with consideration explicitly paid to atomicity and idempotency each time  Also  it requires all messages to contain the full entity state; otherwise  information would be lost when we discard stale messages in case of races  It would be expensive for us (in terms of computation and bandwidth) to send the full entity snapshot with each incremental change  so wed rather find a means that would allow us to process incremental messages in-order instead 

Is there any clean way of achieving in-order processing for a scalable number of entities on the Azure serverless stack 
"
59306187,"I noticed that we are racking up quite a bit of data transfer costs from RDS  I would like to understand what is causing it and if our networking architecture is flawed  
So heres the architecture:

Aurora cluster running on (Availability Zone) AZ-c   belonging to 3 public subnets (1 for each AZ)
Lambda in 3 private subnets (1 for each AZ)
Lambda is allowed to communicate with the RDS instance through a security group

I think the only reason why the RDS instance is in a public subnet is to avoid using a proxy to connect to it from the office (we have an SG allowing access from the lambda and our office IP) 
Should I try running the lambda only from 1 subnet  that is in the same AZ as the RDS cluster 
"
63146466,"Im working on a JAVA project which uploads files to AWS S3 bucket  Now I need to process those files in S3 (validate and send data to database) everyday at 8 00 a m  Im planning to use AWS scheduler for this  But Im confuse whats the scheduler I have to use and how to use  I went through documentation and found about AWS Batch and AWS cloud watch scheduler through Lambda  But I have no idea about whats the best way to use AWS scheduler in this scenario  Not sure weather AWS Batch works for this  Actually I need to consider the cost as well 
Im glad if you could suggest me the best way to resolve this  Alternative methods are also welcome 
P S: File process will take more than 15 mins  And also I need to config several other schedulers as well 
"
42853269,"Were integrating Amazons Alexa to work with our application  We have created a dictionary of items that Alexa might be asked  in DynamoDB  Now we need an algorithm to match the text from Alexa to the strings stored in the DynamoDB table which would be phonetically similar  but possibly differently spelled or with special characters in between  e g 

X-Men may be requested as xmen or ex men or x men
Claire may be requested as clare or clair

I find the  a plausible option  but i havent learnt enough about it yet  This could be pretty expensive too 
I also tried to find out if there are node modules that would help find similar strings that I could match against the database 
The  would probably not work for us either especially because we have the constraint of finding a single match and not a list of possible match for a single string input 
Eg  A search for  should return only  and not  and 
My last resort would be to write an Approximate String Matching Algorithm along with Levenshtein distance computing algorithm from scratch 
"
51130235,"* APOLOGIES for the IMAGES Posted * 
I am looking for potential cost cutting measures for an application that is hosted on AWS with the following configuration / setup 

EC2 Instances
Java Dynamic Web Application with Web Server  App Server
RDS - MySQL

The application is used 95% of the time for 1 week in a month  and the remaining time 5% distributed over the remaining 3 weeks 
For the sake of cost cutting so as to not pay for the EC2 instances  we are looking to go serverless 
My Background w r t  Cloud / AWS:

No Previous Professional Working Knowledge in any Cloud Based System except for EC2 where I was managing a Java Web Application with a similar setup as above 
I have only been searching online and reading a lot of websites / blogs 

I have prepared a presentation based on the materials I have read online  But I need expert opinion / confirmation that the solution options in the presentation are 

Possible to Implement
Not Too Complex to implement compared to the EC2 Implementation 
Potentially saves money as a generic case  compared to renting EC2 instances

The presentations slides are as below:















I am not limiting to AWS  but since current application is hosted on AWS would like to use the same platform 
But if similar implementations are possible using Azure or other platforms  we are open 
All that we are looking for is to cut costs 
I may be missing to provide some important information for you to help advice me  Please let me know what you need and I will get it for you 
Thanks 
Regards
"
44818898,"My handler python-function call another python-function in a new thread and return result on the next line - like this:

I already have result for client and for speed I want to return it NOW without waiting a few seconds for finishing of the second python-function  But I found that AWS Lambda terminates after few milliseconds after  in the handler 
I can extract my second python-function to the new Lambda and call it before  but I think that this will little more expensive for money and time 
Maybe exists some way to not shutdown Lambda after  in handler  I tried long  but of course this is not for such case 
"
44158457,"I have the following use case scenario for which I am considering aws services to see how I can come up with a scalable solution  Thanks in advance for your help 
Scenario: 
Users can sign up to an application(which is named say Lets Remind or something else) using their email and phone  
The app does one thing that is to send email and sms alerts to user 
User can create n number of tasks for which he wants to be reminded  For instance he can set up a 
monthly reminder for paying card dues  Currently the value of n is from 5 to 10 per user 
The notifications are flexible meaning it can be daily  weekly  monthly  bi-weekly  User can also 
specify the start date of a notification  The end date is the date when the event is due (for instance 
the day the card payment is due)  Once this date is expired the notification is rendered inactive for 
the current month  
For weekly daily bi-weekly notifications  the notifications are deleted once the event date is passed  
These are not recurring in nature 
For monthly recurring events such as payment of apartment rent etc  notification itself is not 
deleted but rendered inactive after the event due date  Once the next event cycle (typically next 
month billing cycle for payments use case) starts  the notification comes back to life and starts all 
over again 
Use can delete any event anytime he wants  If an event is deleted  the notifications for that event 
will be deleted as well 
First of all  I hope the use case is clear  Now heres my thoughts so far about solving this use case -
1) Use SNS since I need to send email and sms both  SES only supports emails 
2) When a user registers for the app  create 2 subscriptions(one for his email and one for his sms endpoint) and also create a topic for the user(maybe a dynamically generated random userid)
3) Once user creates an event (e g  reminder for monthly apartment rental)  store the event data such as userid  startdate  duedate  frequency  isactive in a dynamodb table 
4) Create a lambda function that will wake up when an entry is written to the dynamodb table (step 3); it will do the following -
i) it will read the event data from the dynamodb table
ii) determine the next date of the notification to be sent based on the current date and event 
data
iii) For active events (check isActive column of the dynamodb record) create a scheduled cron 
expression rule based on ii above in cloudwatch events and add the 
target as the users topic (created in step 2 above)  For now  the notification message is 
static 
I have some doubts/queries about step iii -
Is it possible to create cloudwatch event cron rule dynamically and add the users topic as target dynamically as I described  Or is it better to trigger a second lambda function dedicated for sending messages to the users topic using SNS notification  Which approach will be better for this use case 
If user base grows large  is it recommended to create one topic per user 
Am I on the right track with my approach above in general from a scalability point of view 
If not  can anyone suggest any better idea for implementing this use case 
Thanks in advance 
"
57155426,"I currently have one AWS Lambda function that is updating a DynamoDB table  and I need another Lambda function that needs to run after the data is updated  Is there any benefit to using a DynamoDB trigger in this case instead of invoking the second Lambda using the first one  
It looks like the programmatic invocation would give me more control over when the Lambda is called (ie  I could wait for several updates to occur before calling)  and reading from a DynamoDB Stream costs money while simply invoking the Lambda does not  
So  is there a benefit to using a trigger here  Or would I be better off invoking the Lambda myself 
"
42320204,"Im interested in hosting a website for a small business  (&lt; 100 users / month) and I wanted to try going serverless  Ive read that using Amazon S3  Lambda and DynamoDB is a way to set this up  by hosting the front-end on S3  using Lambda functions to access the back-end  and storing data in DynamoDB  Ill need to run a script on page load to get data to display  save user profiles/allow logins  and acccept payments using Stripe or Braintree  
Is this a good situation to use this setup  or am I better off just using EC2 with a LAMP stack  Which is better in terms of cost 
"
42878938,"I have an AWS lambda script that produces a json file  
and a django app on an AWS EC2 instance 
I want to make the json available to the django app 
The django app has a default sqlite3 db  how can I get lambda to post to EC2  
I am using the code below to post the results to a AWS RDS instance  but this might be costly for my needs and Id be better off updating a db in the django app  of possible 

(The lambda script is in python2)
"
61916850,"Problem Description 
I created a simple REST API using AWS Lambda and Im saving the data in AWS DynamoDB (all using Serverless framework)  The latter is defined as   Currently  the API is not very much used  however when the app scales  it can induce significant additional costs 
What I have tried
I came to the conclusion that there are two options:

either I cache the DB values
or I cache the API Gateway response

Although paid  I have tried the AWS DynamoDB DAX but its a paid feature and Im looking for an alternative (with code) to minimize requests to the Database when it comes to  requests that are unlikely to change within 24 hours  
I also made some research and found out that its possible to enable caching in API Gateway  but Im not sure whats the best/cost-effective method of doing this  Maybe someone has a practical example that explains how to achieve this 
"
54923071,"One Lambda is calling another in a synchronous manner  gets some data and continues in processing  
This means  the costs are taken into account for both Lambdas in the call time period 
Is it possible to use AWS Step Functions in this case without breaking the processing into a state machine blocks  which would make the code too complex 
Node js 8 10 code:

"
41707732,"Having trouble configuring AWS Lambda to be triggered by a Rule-&gt;Trigger as a Scheduled Event Source using CloudFormation (in reality  using Pythons Troposphere ) This has cost me a couple of days already  and any help would be appreciated 
Heres the relevant CF JSON snippet -

The AWS Lambda function shows zero invocations  and the Events-&gt;Rules metric shows the correct number of invocations  however they all fail  The Lambda shows the trigger in the Triggers section  and the Rule shows the lambda in its trigger sections  They link up fine 
However  if I go in and manually create the same trigger under the rule in the web console  it will happily start sending events to the Lambda  
PS - heres the troposphere code:

"
44126820,"Im trying to create an AWS Lambda function that is to be invoked by an Amazon Echo Skill  The Lambda function should connect to an MQTT broker  which is not in the AWS  and I noticed that the Lambda function alone was not able to access to the external resource  I have tried several configurations and it could connect to the broker after creating an NAT gateway  However  the NAT gateway is a charged service and I wonder if it is necessary 
Here is my question  Is it necessary to have the charged NAT gateway in my situation for the Lambda function to access to the external resource  If not  what else should I do  I would welcome any idea that would let an Echo Skill publish an MQTT message to my MQTT broker  even without the AWS Lambda 
Thanks 
"
55260750,"I am trying to send a Woocommerce webhook to AWS API Gateway  When i put in my API Gateway URL on Amazon I get the following error:

I think this is related to headers  there is an option to Create CORS in API-Gateway that I have now done  Which then adds an OPTION method but I still get  in Cloudwatch

I created a POST method and used the mapping template below with application/json and the setting 


Here is a mini Lambda Node function that just outputs a Woocommerce order number to the console and shows in Cloudwatch whether the API passthrough is working 

If anyone did want to have a go at re-creating this  you can knock up a quick Wordpress install on cPanel and install the Woocommerce Plugin  Setup a dummy product and then just use the Cash on Delivery as a payment method to get your Order Created webhooks firing  Only takes 2 minutes 
You can use  or webhook site to test out webhook outputs 
Can anyone help sorting out the Headers so i can pass a Woocommerce payload to API Gateway 
"
46733970,"when thinking about lambda costs for memory/requests  is there any evidence to suggest having larger functions with many package includes vs many smaller functions with minimal packages is a better option 
for example

vs

"
58876798,"Im doing a POC to find out how fast DynamoDB is  The example problem Im trying to solve is the following: 
I have a 100 keys on the input  For each key I have to look up associated info  The associated info for each key has ~8kB  
Ive stored the keys with their associated info to DynamoDB  table   set the capacity to on-demand mode  Im getting the info from an AWS Lambda function  The table and the Lambda are in the same region (EU Frankfurt)  Here is the code sample for getting info for the given key list:

I always run the Lambda a few times to make sure its warmed up  When I did this test for the first time  it took ~2000ms  My expectations are to get this in ~500ms  Things I did to speed it up:

Increased Lambda memory from 1GB to max (~3GB)  I got to ~1300ms  On Lambda  with more memory  you get more bandwidth  so I guess this is why it got faster 
Ive provisioned big read capacity in DynamoDB (1000)  to see if auto-scaling isnt slowing things down  I saw no measurable effect 
I checked CloudWatch metrics for the DynamoDB table  the latency there is ~180ms  This is pretty good  so it looks like its not a DynamoDB issue 
I installed aws x-ray sdk to check if theres something slowing things down on the lambda side  The  call is taking ~1250ms out of ~1300ms  the rest is lambda initialization  So My guess was that the slowdown must be happening somewhere between the Lambda and DynamoDB
Ive put the Lambda into a VPC and used a Service Endpoint for DynamoDB - it had no measurable effect 
Ive put the code to a EC2 instance with as much network bandwidth as I could get (100 Gigabit) and it took ~900ms  Still not good 

So my guess is that the bottleneck is somewhere between the Lambda and the DynamoDB table 
I havent tried DAX  because it involves some extra costs for the cluster  plus Im not sure it would help  as DAX promises to speed things up on the DynamoDB side  which doesnt seem to be the bottleneck 
My question is: Is it somewhat normal that getting ~8MB from a DynamoDB to a Lambda takes &gt;1000ms  Or am I doing something wrong 
"
44687654,"I am creating a publicly available API using API Gateway which is backed with lambda functions to do some processing  I have secured it with a custom security header that implements hmac authentication with timestamp to protect against replay attacks  
I understand that API Gateway protects against DDOS attacks through its high availability  but any invalid requests will still be passed to the lambda authentication function  So  I guess an attacker can submit invalid unauthenticated requests resulting in high costs  It will take a considerable number of requests to cause damage but it is still very doable  What is the best way to protect against that   
Thank you
"
58014734,"I created a new Lambda based on a 2MB zip file (it has a heavy dependency)  After that  my S3 costs really increased (from $12 27 to $31) 
Question 1: As this is uploaded from a CI/CD pipeline  could it be that its storing every version and then increasing costs 
Question 2: Is this storage alternative more expensive than choosing directly an owned s3 bucket instead of the private one owned by Amazon where this zip goes  Looking at the S3 prices list  only 2MB cant result in 19 Dollars 
Thanks 
"
32561554,"I need to copy a large chunk of data  around 300 GB of files from say bucket A which is in us-east region and to bucket B which is in ap-southeast region  Also I need to change the structure of the bucket  Like I need to push the files to different folders on bucket B according to the image name which is in the bucket A  I tried to using AWS Lambda but its not available in ap-southeast  
Also how much would it cost since data will be transferred between regions 
"
59508880,"I created a new GCP Project  and created a hello-world serverless cloud function from GCP Console 
I immediately get a mail that a Firebase project has been created as well  and my Cloud Function has been upgraded to Blaze plan of firebase 
My question is  which pricing model should I refer  
 - GCP
OR
 - Firebase
There is a difference in both pricing  where if you see in firebase pricing  125K invocations/month are free  while in GCP Pricing  2M invocations/month are free 
I am confused on which pricing is applicable if I simply want to use Cloud Functions  because even if I create a function from GCP Console  firebase console also shows the function in its console 
"
60424500,"Im working on ingesting metrics from Lambda into our centralized logging system  Our first idea is too costly so Im trying to figure out if there is a way to lower the cost (instead of ingesting 3 metrics from 200 lambdas every 60s) 
Ive been messing around with MetricMath and have pretty much figured out what I want to do   Id run this as a k8s cron job like thing and variabilize the start and end time 
How would this be charged  Is it the number of metrics used to perform the math or the number of values that I output 
i e  m1 and m2 are pulling Errors and Invocations from 200 lambdas  To pull each of these individually would be 400 metrics 
In this method  would it only be 1  3  or 401 

Output:

Example 2:
Same principle  This is pulling the invocations by of each function by FunctionName  It then sorts them and outputs the most invoked  Any idea how many metrics this would be 

Same question  1 or 201 metrics 
Output:

"
43367012,"I have written following code in Nodejs for Lambda and get an output which shows all the lambda function filtered by node and none-node run-time across all regions (as expected ) 
But  somehow the code looks bulky with lot of function calls to different regions  Can the code be cut short or can the execution time be decreased in some way 

UPDATE 1
As suggested by   I added regions to an array  It looks more cleaner now  but still it contains few loops which can be eliminated  Like: to return callback  condition is checked whether all regions are executed or not  if callback is kept outside loop  it will return null response  as asynchronous Node will execute it first  Promises can be used to overcome that situation  but still not sure how to use promises when loops are nested and execution time is a concern  Also  can there be a way other than promises this can be done without adding more cost in execution 

"
56923955,"I have a Python 3 6 AWS Lambda Function I am building out to query Cost Explorer  and a few other services  I want to write out the string response I am returning into a JSON object I can either upload to S3 or into DynamoDB 
A working example of the Function is below

That returns just fine in the console  now I tried this to put the Response into the Body of an object I wanted to write into S3

That is not working as expected  and I am getting this error from CloudWatch

I thought I could just stuff that into the object and write it out  Is there a better way to do what I am trying to do 
"
48711787,"Im making a web app using AWS lambda   Everything is working great and my cold start requests are under 200ms   Go has absolutely blazing speed   But there is an issue with user registration and auth 
Computing a bcrypt hash takes 19 seconds with 128 mb of reserved memory   Increasing the memory does take the request time down but increases the cost per transaction 
For only two of my calls needing the increased space this seems pretty wasteful   Im considering making a separate endpoint for just auth   They share a DB so would not matter to much 
Is there a better way 
Different auth scheme 
Different infrastructure 
"
45261473,"I am trying to implement a solution on AWS which is as follows:
I have a crawler that will run once a day to index certain sites  I want to cache this data and expose it the the form of an API since after crawling  this data will not change for an entire day  After the crawler refetches  I want to invalidate and rebuild this cache to serve the updated data  Im trying to use serverless architecture to build this 
Possible Solutions
It is clear that the crawler will run on AWS Lambda  What is unclear to me is how to manage the cache that will serve the data  Here are some solutions I thought of

S3 and Cloudfront for caching: After crawling  store the data in the form of  json files in S3 that will be cached using AWS Cloudfront  When the crawler refetches new data  it will rebuild these files and ask Cloudfront to invalidate the cache 
API Gateway DynamoDB: After Crawling store the data in DynamoDB which will be then served by API Gateway which is cached  The only problem here is how can I ask for this cache to be invalidated at the end of the day when the crawler re-crawls  Since the data will be static for a day  how can I not pay for the extra time that DynamoDB will be running (because if I implement caching on API Gateway  there will only one call to DynamoDB for caching after that it will be sitting idle for a day)

Is there any other way that I am missing 
Thanks 
"
38757271,"
I want to host a scalable blog or application of this sort in nodeJS on AWS making use of AWS technologies  The idea here is to have a small EC2 server that is not responsible for serving the website  but only for running the CMS/admin panel  While these operations could be serverless as well  I think having a dedicated small VM EC2 instance could be more efficient  and works better with existing frameworks  etc 
In my diagram above  you can see theres two type of users  and    Admin CRUD operations also cause lambda to run  Lambda generates the static site after Admin changes  which is delivered to S3  Users are directed to the static site hosted in S3  Only admins/writers have access to the server-connecting part of the site 
I think this is a good design for an extremely scalable and relatively cheap site  as long as the user-facing side is all static  An alternative to this is a CDN  but then I have to deal with cache invalidation issues  a site that updates slower  and a larger server 
This seems like a win-win to me  Feedback 
"
61521108,"I created the S3 bucket first  With the necessary permission  And enabled notification to lambda function on all object:put 
I then created a Cost and Usage report and selected the above S3 bucket as the storage  Permissions look correct  as it could create/update the test file with the name aws-programmatic-access-test-object
Its been few days now  and CUR say it has been generating reports  But I cannot see the files in the S3 bucket 
Interestingly my lambda function is being invoked with notifications about object:put 
But the files are nowhere to be found  
Can someone help understand what might be happening please   



"
59863241,"I have some tables in dynamodb and I simply want to take a cost variable  of a service and create a function that adds (like sum(column)) up all from one id and returns the result  how can I do it 
"
32079113,"Im evaluating some scenarios for my needs with media extraction from mp4 video files to mp3 using AWS lambda approach  
The main requirement is once a new mp4 file is available or saved in some S3 bucket by a custom application the Lambda function will be triggered and send metadata to Dynamo DB and then the lambda function will extract the audio and store it in another S3 bucket 
There are available four options as described below to design the Lambda function:

For example  use Java plus JAVE encoder library to do the job (with
embed  ffmpeg binary in the lib/jar)
Use NodeJS with some npm package with media encode capacity
(including spawn ffmpeg process)
Use NodeJS with AWS Elastic Transcode Service 
Use Java with AWS Elastic Transcode Service

Which of option above will result in less cost in terms of resource (memory/cpu usage tiers) 
I’m guessing the two initial scenarios sound more amateur but could be less expensive  But I have doubt if in terms of memory and CPU resources usage choosing between NodeJS  or Java could affect the amount lost because of memory or the time execution of a lambda function will take to to the task  
I need care about these aspects it is desirable to spend the less amount as possible with AWS Lambda for this kind of task 
Doesnt matter choosing between NodeJs or Java  
Should I consider use the Elastic Transcode Service instead a custom library in lambda function 
Thanks for your help 
"
43200113,"Im building a site and API for my own personal purposes  and I figured Id use API Gateway and Lambda functions to keep costs down 
I need a way to authenticate  and using my Google or GitHub account with OAuth seems to be a good idea  
However  since:

Theres only going to be one user for the foreseeable: me 
Id like to be able to build command-line tools around these APIs Im building 

Im not sure that OAuth is the right approach  Is there a way to limit who can sign up/sign in with OAuth as an authentication backend  Additionally  should I add more allowed users  is it easy to build authorization around an OAuth based system 
"
45222993,"Background
I am building an API using AWS Lambda and API Gateway  Rather than splitting each API endpoint into individual lambda functions I am wrapping them into a single library and using the  library 
Question
Given that only a portion of the entire API might be used in a single Lambda execution— from a memory utilization standpoint (to cut down on cost) is there a difference between: 

or

So for example  a single API request might result in only  being called before the Lambda function is powered down  In that case are we effectively wasting memory by calling  up top 
I suppose the more direct question is  when I  does the node js runtime actually allocate memory for  at that moment  Or is it effectively a no-op until I actually do something with  
"
60201185,"I have an Athena table of data in S3 that acts as a source table  with columns       For every unique  value in this table  I would like to output a new table with all of the rows corresponding to that  value  and save to a different bucket in S3  This will result in n new files stored in S3  where n is also the number of unique  values in the source table 
I have tried single Athena queries in Lambda using  and CTAS queries  but cant seem to get the result that I wanted  It seems that AWS Glue may be able to get my expected result  but Ive read online that its more expensive  and that perhaps I may be able to get my expected result using Lambda 
How can I store a new file (JSON format  preferably) that contains all rows corresponding to each unique  in S3 
Preferably I would run this once a day to update the data stored by   but the question above is the main concern for now 
"
36268775,"Ive been tinkering with nodejs code in AWS Lambda  called by some API Gateway endpoints  Ive noticed that after a certain amount of time passes without any API Gateway calls  the next API Gateway request will time out  Ill get the standard Lambda error message saying the function timed out  However  subsequent HTTP requests to trigger my Lambda work fine  
Superficially  it looks like something is going into idle mode and needs to be charged up before the API Gateway-Lambda request can work properly  Ive considered setting up a wget cron to keep things non-idle  but is there a real fix and how can I better understand whats happening  
"
47771693,"I am trying to implement an event-driven architecture using Amazon Kinesis as the central event log of the platform  The idea is pretty much the same to the one presented by  
I have done similar things with Apache Kafka before  but Kinesis seems to be a cost-effective alternative to Kafka and I decided to give it a shot  I am  however  facing some challenges related to event persistence and replaying  I have two questions: 

Are you guys using Kinesis for such use-case OR do you recommend using it 
Since Kinesis is not able to retain the events forever (like Kafka does)  how to handle replays from consumers 

Im currently using a lambda function (Firehose is also an option) to persist all events to Amazon S3  Then  one could read past events from the storage and then start listening to new events coming from the stream  But Im not happy with this solution  Consumers are not be able to use Kinesis checkpoints (Kafkas consumer offsets)  Plus  Javas   which would be useful in such implementation 
"
52862167,"I am new to Serverless architecture using AWS Lambda and still trying to figure out how some of the pieces fit together  I have converted my website from EC2 (React client  and node API) to a serverless architecture  The React Client is now using s3 static web hosting and the API has been converted over to use AWS Lambda and API Gateway  
In my previous implementation I was using redis as a cache for caching responses from other third party APIs  
API Gateway has the option to enable a cache  but I have also looked into Elasticache as an option  They are both comparable in price with API Gateway cache being slightly costlier  
The one issue I have run into when trying to use Elasticache is that it needs to be running in a VPC and I can no longer call out to my third party APIs  
I am wondering if there is any benefit to using one over the other  Right now the main purpose of my cache is to reduce requests to the API but that may change over time  Would it make sense to have a Lambda dedicated to checking Elasticache first to see if there is a value stored and if not triggering another Lambda to retrieve the information from the API or is this even possible  Or for my use case would API Gateway cache be the better option 
Or possibly a completely different solution all together  Its a bit of a shame that mainly everything else will qualify for the free tier but having some sort of cache will add around $15 a month  
I am still very new to this kind of setup so any kind of help or direction would be greatly appreciated  Thank you      
"
62172546,"When creating a NodeJS API that accesses my serverless mysql cluster  the notes out there all point to NPM-loading the mysql package  I really try to avoid contaminating my lambdas with NPM and all the other dependencies that are going to spawn 
Is there no AWS native mysql client like the one for dynamoDb 
To clarify further  Im looking for the mysql equivalent to this:

The advantage here is no package installation required and still being able to write classes without all the overhead code for managing types etc etc 
This project seems to acknowledge some work is needed in this regard:


Update: So I bit the bullet and npm-installed a mysql package Total cost is 11 modules and just 1 42Mb (below the 3Mb limit I like to set)  Im able to run all my CRUD ops as well as db and table management on Aurora  
If youre not doing sophisticated cluster management and are happy to leave that to Aurora  I think this is good enough  
I see a lot of code out there for lambdas crowded with AWS libraries  data-clients; this pushes the lambda to more than 20Mb  Totally not needed; for the rare case of cluster management involvement  you could just use a different lambda with those packages 
"
66114258,"I have a client application that uses StripeJS + Stripe Checkout to create a session and then redirects to a success URL 
My  call is conveniently called alerting the application to successful payment  To update a Cognito user with a  attribute  Im attempting to pass the users access token around through my Lamda routes authorizer and then into the Stripe object through either metadata or  
Stripe limits the character length of both of those fields which prevents using that approach exactly 
How can one pass Cognito user credentials through Stripe to correlate successful payments to the existing user scheme 
"
69298298,"I am trying to reduce time on installing python packages on AWS Lambda 
For now  my codes are

but numpy and pandas take too long to install (~120s for pandas and ~50s for numpy) 
I think this is a big charge if my function is called too frequently 
So I think that if I can install them into temp folder and push to S3  I can download and add to Lambda layer to call them without installing again 
I try zipping all temp directory but Lambda prevents me to writing files  Is there any way to overcome this 
Thank you for your reading 
"
39851894,"I have a question reagrding AWS and Lambda functions  as I plan to design a notifications system for my app 
I have events and I want to send a reminder an hour before every event to every user attending  The dates are stored in the data base  as well as are the attending users  So I thought about the Lambda function which would send the notification to the users device when it reached the right time 
However  is that possible with LAMBDA AWS to write such a function which would periodically look for this  I also wouldnt like to check it every-minute as it is quite costly then (I assume)  How else I could design it 
Thank you in advance 
Grzegorz
"
57827691,"Kindly note answers need to work in an AWS Lambda - as such this is not a generic MySQL question 
I have a pandas dataframe in AWS Lambda  It contains 50k rows and I need to load this into Amazon Aurora (MySQL)  
Using  is woefully slow 
The best way to do it would be to save a  csv  and then use the superfast MYSQL      command 
I save the df to a csv in lambdas \tmp\foo csv but then  Doesnt work 
I get an SQL error

Access denied for user   

I log in to the db as root  but cant grant  The MySQL flag is set to local-infile=1 
So  in summary: How can I FAST load 50K rows from a csv to MySQL Aurora db in AWS Lambda 
Discounted Solution
One solution Ive already discounted is to export the csv to a S3 bucket  and then use the Amazons  LOAD DATA FROM S3  This seems terribly inefficient (not to mention all that S3 transfer/storage cost) 
"
58467621,"Im new to OAuth2 and cloud-functions/serverless 
So I was wondering whether it makes sense to create cloud-functions to handle OAuth2 requests 
My Idea:

User sends auth request to and API Gateway (to prevent cloud-function abuse  as of my understanding  or how else should that be prevented  Cloudflare )
Gateway redirects request to cloud-function
Cloud-function stores user authentication in DB
User is now authenticated 
The authenticated user can now request actual data  like profile  through other cloud-functions 
Response with data to the user 

Is this a correct understanding of how OAuth works  If so  does this make sense  or would a usual server be cheaper to handle OAuth 
"
66245987,"I am creating a design for my eCommerce application  It will have multiple services backed by AWS Lambdas  Orderservice  InventoryService  PaymentService  LoggingService  dashboardService are some of those services  I cannot give the exact number of services but it will surely be more than 15  As per this link   a good microservices architecture should have one gateway that will route to the corresponding services  The code for my AWS ApiGateway with order Lambda function looks like below   My question is that each of Orderservice  inventoryservice  paymentservice etc can have multiple routes for get  post  delete  put  Most of them will have nested resources  In this situation should I include api routes and lambda functions for all these services within the same SAM template  If yes  wouldnt it be a monolith Template  If I need to change in any service  I have to deploy the whole template and breaks the microservice principles  Ideally  I want to deploy all these services independently and yet share the ApiGateway  Is this possible    If not  should I create separate ApiGateway for each service in different SAM template so they can be deployed separately  This will cause authentication  authorisation  monitoring be repeated in all gateways which again doesnt sound like way to go  
Please suggest what is the right way to do this 

"
57120893,"My problem statement is as follows:
I have configured AWS SES to receive emails on a subdomain  SES then send a notification to our web application via SNS  Now  SNS has a 150kb limit and therefore any emails with an attachment of sive&gt;150kb is bounced  
My question is:
Is there a way to strip the SES email of the attachments before dispatching through SNS  
One solution is to save the attachments in S3  but we have absolutely no use for the attachments at this point and would prefer not incurring additional S3 costs for nothing  I have looked at multiple AWS documentation and have not been able to find a solution  Any pointers will be greatly appreciated 
"
56520042,"I am building an app that allows people to share items with other people in the community  I wanted to use AWS as my platform 
My idea was to use react Native for the app  AWS Cognito for the authentication  AWS lambda for the server calls  Relational database for storing data about the items and user data such as geolocation  Dynamodb for real-time chat  requests for borrowing and transaction data between users  My primary focus is low cost and I was thinking of using PostgresSQL for relational database 
What do you guys think of my database choices  Of course the PostgresSQL database on rds  Is there a flaw in database plan so far  Any help would be greatly appreciated 
"
58019678,"bcrypts thing is that it takes a set amount of time to run  so if someone wants to run a brute-force or dictionary attack against your server  bcrypt limits the number of guesses that can be run in a set amount of time 
AWS Lambda functions auto-scale  If a Lambda is busy  AWS will helpfully run up another one 
If you want to use bcrypt in a lambda function  the auto-scaling will negate the benefits of a function that takes time to run 
In addition  AWS will charge you for the extra lambda instances 
So you are effectively paying for someone else to hack into your server 
Is there a way to prevent this  eg limit the number of concurrent lambda instances for a particular function (to 1 maybe )
"
53723822,"Ive seen a lot of people using SNS to trigger their lambda function rather than using the API gateway to do it  Any specific reasons to do this 
Personally i think allowing the API gateway to do this is a lot more flexible than using SNS  Any good elaboration as to why do this   Would i get any performance or cost improvements if i use SNS to trigger the function 
"
55859414,"Setting response headers with API Gateway with AWS Lambda proxy integration is straight forward and looks like this:

Everything is returned gzipped as expected  Because we set the content-encoding the browser decompresses the response 
Question is how can headers be similarly set when the Lambda function is invoked from the browser directly using AWS SDK JS  API Gateway is the service which implements the headers in the previous setup  without having API Gateway in front of AWS Lambda headers are ignored and being generically set to:

AWS SDK JS browser invoke code looks something like this:

The returned response is the response object above as a string with the generic headers  Browser does not decompress the gzipped content  presumably because the content-encoding header is not being set  AWS Lambda when invoked from the browser  treats the whole Lambda response object as the response and performs no transformations that happen with API Gateway  For instance  API Gateway would pick up on the response object structure and map response object headers to the response before sending to the client 
Is there no way to set AWS Lambda headers without API Gateway  Or is the only option to decompress the gzip content manually on the client using something like  (sigh)  
Idea to not use API Gateway came from AWS docs found here  like to avoid the API Gateway costs: 
Any guidance  expertise  thoughts are much appreciated 
"
56049038,"What are other cloud-based  serverless  managed databases that have a pricing system similar to DynamoDB  Im specifically talking about the On-Demand mode of DynamoDB
By similar I mean  being able to pay per requests and per GB/Month or similar  instead of paying a fixed monthly fee  I understand this will mostly gear towards NoSQL databases but for me it doesnt matter the type of database 
Apart from DynamoDB  I have also found FaunaDB  but it lacks documentation and tools/integrations
Its important to note that Im not considering pay per hour here  as that is irrelevant once you go to production 
"
65774612,"I am creating website on AWS using serverless framework 
There are 3 parts which I need to serve clients:

endpoints of lambda functions (/getusers)
index html served throught lambda (I need to insert some constants to it)
static html  js  css  img files  which should be served directly from S3  without going throught costly lambda 

How do I accomplish that  I need all parts of the app to be able to cooperate thus  probably on the same domain  I need index html and js files to be able to call the lambda endpoints (setted up by API Gateway)  Also I would like all files be cached throught CloudFront  I searched google but did not found any example 
"
62641547,"Building an app to be launched in production - and unsure how to handle the dev/production environments on AWS 
If I use multiple buckets  multiple DynamoDB tables  multiple Lambda functions  multiple Elastic Search instances  EC2  API gateway - it seems SUPER cumbersome to have a production and a dev environment 
Currently there is only ONE environment  and once the app goes live - any changes will be changing the production environment 
So how do you handle two environments on AWS  The only way I can think of - is to make copies of every lambda function  every database  every EC2 instance  every API and bucket     But that would cost literally double the price and be super tedious to update once going live 
Any suggestions 
"
46502462,"Im new to AWS and would like to deploy a microservice on Amazon Web Services  The function code shall be in AWS Lambda and this functions shall be triggered through AWS API Gateway 
My lambda functions itself are protected via authorization  Furthermore  the number of authorised requests are within the free tier 
Now my questions:

Can unauthorised attacks to Amazon API Gateway let the costs explode 
Can i prevent my Amazon API Gateway from such attacks 
Can i set a costs limit and shut the API off  in case of too high bills 
Are intentionally API attacks common 

Thanks
"
69641677,"have a good day 
Im new to AWS  I have created a web application using angular  a backend using NodeJS and Express framework  I copied the dist folder(output of angular built) into the backend root and served the frontend from the app js file of backend 
Deployed this backend to EC2 instance with elastic beanstalk  It was working great  The backend had a public folder containing all the required  png icons to be served to the frontend UI on load in the browser 
But now the requirement is to deploy this solution in a serverless architecture since it is cost effective and zero server maintenance  I have deployed the angular dist folder to AWS amplify  working great  And deployed the NodeJS Express backend to AWS Lambda as a function using serverless framework available as a NodeJS library  got an endpoint link too that I already added in the angular frontend using proxy  so that all the requests for icons from browser will be redirected to the lambda based function endpoint 
The issue is that the front end is served to the browser from amplify but the icons are not getting loaded from the lambda based function backend  The icons are still in the public folder of the backend which is deployed on the lambda using serverless framwork  The web app successfully connects with the backend in lambda  authorizes users successfully  The only thing it doesnt server those static images 
Is there any way that AWS lambda backend can serve the  png icons to the frontend in browser as the backend serves if deployed in AWS EC2 server 
Regards
"
61605991,"Do I get charged for transfer from S3 to aws Lambda 
For example a user uploads a file client side to my S3 bucket  My aws lambda retrieves the file to generate thumbnails  Does that count as S3 out to internet or S3 to cloudfront or something else 
Lambda and S3 are in the same region 
"
71513209,"Ive been planning out an architecture that gets a request from a user  basically the user passes a piece of information to the system  the system performs some lookups  and updates a value in a database reflecting the new information  The application is latency sensitive  faster is better 
At first glance it seemed like SQS was a good fit  Basically  the request is picked up by lambda at edge  which performs some basic tasks and shoots a message off to SQS  The SQS message is picked up by a lambda  which processes it  Boom  good to go 
Heres what I think I might be missing  It sounds like if youre using long polling theres a minimum 1 second wait between when the message is sent and when its picked up  Is this correct  My assumption was that SQS could be used with latency-sensitive applications  but 1-2 seconds is a pretty big cost  If Im understanding this right  whats the correct service to use here 
"
59452548,"AWS allows a Lambda function to be triggered by an SQS queue  With respect to the   Lambda polls the queue and invokes the function synchronously with a batch of messages 
AWS takes the execution time into account while charging for a Lambda function  Does the polling time counted as the execution time and be charged  Or is it free 
"
63085775,"For my application on AWS  I want to host a temporary HTTP server and dispose it in a few minutes  I think EC2 instance / Fargate would be a costly overkill for this  So thinking of doing this on a Lambda function  Is this possible 
Can a Lambda function expose an IP address (could be temporary)  Or provide some way for others to communicate with the lambda function - after it has started 
Or is there any other way to achieve this goal 
Adding more detail:
I want to achieve something like this  The external client invokes an API  to get a URL  The client should then be able to interact with this URL in a stateful session  defined by the parameters passed in the initial API invocation 
This session would last a couple of minutes  after which the state/session/client is forgotten  The Lambda will use the time between requests to work in the background and prepare for next request from the client 
I know we can do this by saving session details in the dynamodb  triggering a fresh lambda function for every new request from the client  and more lambda functions in the background with SNS    But  I thought would be more exciting to do everything in a single Lambda invocation
"
57333870,"I currently have a lambda that is triggered by requests made to an API Gateway route  and I made some research about how to set a payload limit (e g  2kb) for this route  My goal is to guarantee that my lambda will never receive a large input to deal with  so it will have a slight execution time and low costs 
I found that the default payload limit for AWS API Gateway is 10 MB  while the default limit to AWS Lambda is 6 MB  Both of them cannot be increased 
However  I did not found any docs or discussion about how to decrease it  Is it possible  Are there any other AWS services that I should use as a middleware between API Gateway and my lambda to limit the received input  Or should I solve it by another approach 
"
60894096,"Im working on AWS Lambda with the java SDK provided by AWS  I need to get an object from an S3 bucket 
I use an S3Client for it (with apache HTTP as custom configuration)
Times are acceptable 
Now Im looking to replace my S3Client by an S3AsyncClient (netty) 
I use custom configuration as explained in the AWS documentation 
I ve defined a StopWatch to count the full lambda processing time 
I can see some improvement :
total time: 254 4 ms (from my StopWatch)
BUT AWS adds +/- 2250 ms of billing time 
16:34:22
END RequestId: 3a8a2313-f3c7-4933-85a3-2f18e8876364
16:34:22
REPORT RequestId: 3a8a2313-f3c7-4933-85a3-2f18e8876364 Duration: 2460 98 ms Billed Duration: 2500 ms 
So I pay a lot more 
Where does this difference come from 
I think that some netty/executor threads keep in WAITING STATE for while then AWS kills them     But not sure about it    
I have configured my executor service 
At the end for my lambda I try to stop all threads by using an executor shutdown();
But It doesnt change anything   
As S3AsyncClient the extends AutoCloseable I ve defined it in a try with resources statement 
I precise that it occurs at both cold / hot start  
Need some help to understand this behaviour     
Thank you
"
42390164,"Im working on a website that mostly displays items created by registered users  So Id say 95% of API calls are to read a single item and 5% are to store a single item  System is designed with AWS API Gateway that calls AWS Lambda function which manipulates data in DynamoDB 
My next step is to implement voting system (upvote/downvote) with basic fetaures:

Each registered user can vote only once per item  and later is only allowed to change that vote 
number of votes needs to be displayed to all users next to every item 
items have only single-item views  and are (almost) never displayed in a list view 
only list view I need is top 100 items by votes but it is ok to calculate this once per day and serve cached version

My goal is to design a database/lambda to minimize costs of AWS  Its easy to make the logic work but Im not sure if my solution is the optimal one:

My  table currently has hashkey  and sortkey 
I created  table with hashkey  and sortkey  and also  field (containing -1 or 1)
I added field  to  table
API call to upvote/downvote inserts to  table but before checks constraints that user has not already voted that way  Then in second query updates  table with updated votes count  (so 1 API call and 2 db queries)
old API call to show an item stays the same but grabs new  count too (1 API call and 1 db query)

I was wondering if this can be done even better with avoiding new  table and storing user votes inside  table  It looks like it is possible to save one query that way  and half the lambda execution time but Im worried it might make that table too big/complex  Each  field is a 10 chars user ID so if item gets thousands of votes Im not sure how Lambda/DynamoDB will behave compared to original solution 
I dont expect thousands of votes any time soon  but it is not impossible to happen to a few items and Id like to avoid situation where I need to migrate to different solution in the near future 
"
46553447,"I am a bit new to AWS / Lambda from the technical side so I have a scenario adn I wanted your help  
I have a file that drops daily  I only care about the file on the last day of the month  They all drop to the same bucket the file drops at 8 EST  
I then need to rename the file from the last day of the month to a static name  and copying it to a bucket lets say the file is called bill  I would want the previous file there called bill_september if we are in october  
So my thought is to have a cron job kick off a Lambda function every day at noon to move a file except for the last day of the month  the first day of the month at 8 AM I will have it kick off a lambda job at 5 AM to copy to new bucket 
So the questions are

Does this make sense  
Can I have lambda rename existing file to file+month  

I am always open to a better solution so please tell me if i am totally turned around 
"
55716767,"when I make an unauthenticated (public) Cloud Run endpoint to host an API  what are my options to protect this endpoint from malicious users making billions of HTTP requests  
For $10 you can launch a Layer 7  that can send 250k requests per second  Lets assume your Cloud Run endpoints scale up and all requests are handled  For invocations alone  you will pay $360 -/hour (at $0 40 per million requests)  
Note that there is a  and a  that you might hit if the attack is not distributed over multiple Cloud Run endpoints  What other controls do I have  
As I understand  the usual defenses with  and  are bound to the   which is unavailable for Cloud Run  but is available for Cloud Run on GKE  
"
43459873,"I have an infrastructure consisting of the following services in a VPC (except S3 and Transcoder obviously):

EC2 (webserver)
RDS (database)
Lambda function with Node js
S3
Elastic Transcoder

The scenario is the following:

the user uploads a video to the S3 bucket directly
the upload triggers the lambda function which would create a new job in the Elastic Transcoder (using the AWS SDK) and update the resources row in the database (RDS)

The problem is that since RDS is not publicly accessible  the lambda needs to be in the same VPC as the RDS in order to allow connections to it  This also results in generic Internet connection loss in the lambda function which means that it cannot access Elastic Transcoder (since its an out-of-VPC from the point of view of the VPC)  Now  I had similar problem with S3 but it was fairly easy to solve that by adding an endpoint to the VPC which points to the S3  however  theres no such option for Elastic Transcoder (or any other service as a matter of fact) 
I dont want to create a NAT gateway as its pretty expensive for such a nonsense thing 
So the simple question is: how can I solve that Lambda can communicate with RDS and Elastic Transcoder at the same time 
P S : The lambda role contains the policy that has access to Elastic Transcoders 
"
54137776,"I have data in Google Cloud Storage that I need to transfer to s3 bucket in a serverless fashion   
one possible approach is to use cloud function and transmit data from cloud storage to s3 bucket using gsutil and boto3 for was credentials  I believe their is an extra fee from Google for outbound network request but this approach is possible  
Does anyone has a better approach or a suggestion 
"
36036500,"I am using API Gateway to build a patch method 
In then  i added:

As a patch http method  the users API is not required to pass all the parameters 
So if the user doesnt pass  for e g  payment_day  the field is going to be   The  can be a valid value field  So i have two options:

Put a NULL value on the payment_day field 
Remove the payment_day from JSON request 

Is it possible to do this on   Does anyone has a workaround 
"
56771017,"I am trying to upload large files (100+ Gb) to several cloud storage services from a Django app  I have written a first view to do this for S3 and it is working: 

I have written these views for S3 multipart upload  my question is  should I write similar views for the other cloud services (Google Cloud Storage  Azure)  or would it be best to implement a S3 lambda function that responds to the upload to the S3 bucket and replicates these files in the other cloud services  What would be less costly for my Web App  thanks 
"
65790802,"Im accessing Secrets Manager in my serverless yml via

which works out nicely 
Problem is  Im keeping all my secrets in a single region &amp; now Im trying to add another region (= stage in serverless)  but I dont know how to reference secrets from my main region  To keep costs low  I dont want to replicate my secrets to the secondary regions though 
Is there any way to achieve this without some pre-scripting magic but solely using Serverless 
"
56997106,"I am working on creating a lambda manager that interacts with other lambda instances 
The manager  which is also a lambda function will manage another lambda function that is executing a workload 
edit:
I am trying to execute workloads on a lambdas as if they were in a VM to take advantage of the serverless pricing model  performance  and convenience  This is a research project inspired by the findings of a few recent research papers 
This gives a quick overview of one of the papers: 
The manager will have the ability to:

act as a keep alive function to allow the workload to persist
destroy the lambda executing a workload (in python: call sys exit()) 
have some scheduling properties

and so my thinking is that I need a way to send a message or 
interact with that lambda instance 
Methods for communicating between two lambda instances 
I have tried using the Gateway API with websockets but that only lets me redirect to specific lambda functions  which is useful but not for the current problem 
I have looked at SNS  I think it can be done with SNS by creating a new topic and passing the arn to the invoked worker lambda but that seems ineffecient  The idea  came from here:  
Thank you so much 
"
48474979,"Im developing a stocks app and have to keep users browser updated with pricing changes
I dont need to access past data  browser just have to get current data whenever it changes
is it possible to filter a dynamodb stream and expose an endpoint (behind api gateway) that could be used with a javascript EventSource 
"
62713941,"I have an AWS Lambda within VPC (connects to RDS) which suffers from a typical cold start issue  I have read a couple of articles on how to make things faster so I deployed 
Details:  NET Core 3 1 environment  ASP NET Core project running in AWS Lambda  connecting PostgreSQL RDS dbo  VPC environment 
During the testing phase  to keep costs as low as possible  I have just 3 Provisioned Concurrency ($10)
Before Provisioned Concurrency  the first request after few hours of inactivity took between 15 to 20 seconds  Next requests  fired shortly after  took less than a second  Some of the requests then randomly took again 15 seconds (I think due to parallel invocation) 
After Provissioned Concurrency first requests after a day of inactivity took 14 seconds 
My expectations of Provisioned Concurrency was to get rid of the Cold Start  AWS Blogs or other Blogs have supported my wishes  however  there is still a gotcha  I think this is due to VPC 
Thanks for any hints or experience sharing 
"
54473954,"i am new to aws serverless  and trying to host django app in aws serverless 
now aws serverless uses s3 bucket for static website hosting which cost around $0 50 (I am in free tier)  
my question is instead of hosting static website can i not give public access to s3 bucket  as it would save me money  is it possible to use public bucket for aws serverless   
"
59022523,"I would like to schedule triggering my Lambda function 
AWS EventBridge allows me to do this (e g  by creating cron based rule) but I dont understand  
It states All state change events published by AWS services are free but Im not sure if an event fired by EventBridge (generated by EventBridge rule) relates to this free one  Probably not 
If its not free  then how 30 events per month will be billed if pricing is based on million of events 
Googling didnt help  Do you have ideas how 30 events will be billed 

Update:
While experimenting I found that we should not pay for 30 events per months but its not clear why  Probably less than million of events are free 
"
62593375,"One of my customers needs us to copy files from their SFTP to our S3  They copy files into SFTP every 15 minutes  so we have files there added incrementally and then they delete files on SFTP which are older than 3 days 
So imagine we have 3000 or more files in our S3 (we need to keep them all in a S3 bucket) and then every day we have around 100 new files that need to be copied from SFTP to S3 ( all the new files which are added into SFTP) 
I have a lambda function which runs every hour to handle it  but what is the most optimised way to do it:

Reading all SFTP file names (using ssh2-sftp-client library) and
check which ones are not copied in S3 (using s3 headObject to check
if file exists in S3) and then copy them  A bit expensive to iterate
through all SFTP file name and see if they exists in S3  more than 1
minute 
Reading all S3 bucket file names  reading all SFTP file names and then compare which ones are not included and then copy those  (not sure if its reasonable performance wise)
or any other solutions

any better ideas 
"
59771715,"We have a production scenario with users invoking expensive NLP functions running for short periods of time (say 30s)  Because of the high load and intermittent usage  were looking into Lambda function deployment  However - our packages are big  
Im trying to fit AllenNLP in a lambda function  which in turn depends on pytorch  scipy  spacy and numpy and a few other libs  
What Ive tried
Following recommendations made  and the example   tests and additional files are removed  I also use a non-cuda version of Pytorch which gets its size down  I can package an AllenNLP deployment down to about 512mb  Currently  this is still too big for AWS Lambda  
Possible fixes 
Im wondering if anyone of has experience with one of the following potential pathways:

Cutting PyTorch out of AllenNLP  Without Pytorch  were in reach of getting it to 250mb  We only need to load archived models in production  but that does seem to use some of the PyTorch infrastructure  Maybe there are alternatives 
Invoking PyTorch in (a fork of) AllenNLP as a second lambda function  
Using S3 to deliver some of the dependencies: SIMlinking some of the larger  files and serving them from an S3 bucket might help  This does create an additional problem: the Semnatic Role Labelling were using from AllenNLP also requires some language models of around 500mb  for which the ephemeral storage could be used - but maybe these can be streamed directly into RAM from S3 

Maybe im missing an easy solution  Any direction or experiences would be much appreciated 
"
59031075,"I have set up a FIFO queue and Id like to partition messages by a message group ID 
As an event trigger  Im using a lambda function 
Now my question: Is it possible to allow only one concurrent lambda function invocation for every message group 
So  if I have  and   and each message group has 20 messages  every message group passes one message at a time (I have set up the batch size of 1) to a lambda function and only passes the next one as soon as the previous message processing has finished 
Is that possible using FIFO queues and lambda or do I need to look into other services to allow that 
Note: Ive looking into Kinesis with separate shards already  but because therell be many message groups  the total cost of the shards would be way too much 
Thank you 
"
62750324,"Serving APIs from  offers more latency benefit than serving APIs from  stack  if my understanding is correct 
Plus  cost of API-Gateway ($3 5/million call) + Lambda ($0 2/million call) == $3 7 / million call seems to be more expensive than  ($0 6 / million call) 
If both of the above observations are true  shouldnt we all migrate our API-Gateway + Lambda (for those who use this stack) to lambda@edge stack 
"
43601226,"I would like to call the  command from within an AWS Lambda function with a runtime version of Python 3 6  How can I do this 

Why dont you just use the included boto3 SDK 



 (If you do not provide anything for ContentType to ExtraArgs  the end content type will always be binary/octet-stream )
 (By default the mime type of a file is guessed when it is uploaded)




For my use case I think it makes sense architecturally and financially  but Im open to alternatives  :

downloads Git and Hugo
downloads 
runs Hugo to generate my small (&lt;100 pages) website
uploads the generated files to s3

Right now  Im able to do all of the above on a 1536 MB (the most powerful) Lambda function in around 1-2 seconds  This function is only triggered when I commit changes to my website  so its inexpensive to run 

Maybe it is already installed in the Lambda environment 

As of the time of this writing  it is not 
"
60781641,"I want to support a light-weight functionality (a DDB lookup and forward the request to backend service) supporting around peak 50 TPS with an acceptable latency &lt;1s  I was thinking about using lambda with provisioned concurrency feature  or is it better to use Fargate 
When should we prefer Fargate to Lambda with Provisioned concurrency feature 
Any pointers to cost  performance study of both the services is helpful 
"
67279181,"I am building out an e-commerce site  with next js and stripe checkout  I keep running into this error when I am going to checkout  I am using the  package as well  and Im starting to think it maybe causing the below response error from 

What is super confusing is that the checkout session in created  along with the cart and payment intent (I know this to be true because I can verify this information thru the stripe dashboard)  Currently the stripe dashboard does not indicate there is an error either 
Has anyone experienced this  and does anyone have any idea on how to fix it 
Thanks in advance 
"
61662447,"I want to develop a Web API using  NET Core that needs to be able to handle a large number of concurrent requests   Furthermore  the WebAPI needs to connect to a database   The Web API will be internal and wont be exposed on Internet 
Im considering two possibilities:  

Hosting an ASP NET Core application in Kestrel in one or more containers / EC2 instances  with or without IIS 
A serverless solution using AWS Lambda

Im trying to understand what considerations I need to be aware of that will impact the performance and cost of each of these solutions 

I understand that a Kestrel server with an application that uses async / await patterns can be expected to handle large numbers of concurrent requests   Database connection pooling means database connections can be efficiently shared between requests 
In  I read that:


I understand this questions more in terms “if AWS Lambda calls:
  response = Function(request) are thread-safe” 
The answer is yes 
It is because of one very simple reason  AWS Lambda does not allow for
  another thread to invoke the same lambda instance before the previous
  thread exits  And since multiple lambda instances of the same function
  do not share resources  this is not an issue also 

I understood and interpreted this as meaning:

Each lambda instance can only handle one request at a time 
This means a large number of instances are needed to handle a large number of concurrent requests 
Each lambda instance will have its own database connection pool (probably with only a single connection) 
Therefore the total number of database connections is likely to be higher  bounded by the Lambda function level concurrency limit 
Also as traffic increases and new lambda instances are created to respond to the demand  there will be significant latency for some requests due to the cold start time of each lambda instance 

Is this understanding correct   
"
44208268,"I have a Python 3 project which I am trying to deploy to AWS Lambda via AWS Codestar -&gt; Codepipeline -&gt; Codebuild -&gt; Cloudformation  
My project (which really just consists of a simple API Gateway handler method) imports a Python 3 (requires 3) project (newspaper)   I am using Virtualenv 15 1 0 on my home computer and if I install Newspaper with Python 3 5 and then upload to Lambda (Python 3 6 runtime)  it throws errors related to PIL / Pillow   
First it says it cant find _image  which appears to be resolved by deleting the PIL directory in site-packages  however that just results in it throwing the error that it cant find PIL 
If  however  I build with Python 3 6 and then upload to Lambda  it works just fine (whether I delete PIL or not) 
So  that appears to me that I cant install Newspaper with 3 5 and try to execute in a 3 6 runtime 
So  now I am trying to deploy via Codestar  however Codestar seems to default to aws/codebuild/eb-nodejs-4 4 6-amazonlinux-64:2 1 3  even for Python projects  and all it seems to have available in the Yum repository is Python 3 5 and of course Lambda only has the 3 6 runtime 
Even if I switch the image within Codebuild itself  there dont seem to be any images built with the Python3 6 runtime (according to the documentation)  Even the Docker images seem to lack Python 3 6 
So  I am trying to install Python 3 6 in Codebuild during the INSTALL phase in my buildspec yml file  however I cant find the python3* executable after the install 
The only other thing I can think of is to create the Codestar project  edit codebuild to use Ubuntu and then install everything (just like I did locally)  but there is no way to do that from within Codestar and I feel like that may bring me down a rabbit hole and thats hardly automated   Is there a way to make that configuration as code from within my project 
EDIT
Attempting to build and install Python 3 6 from source works  but then when trying to install Pip  I get errors saying SSL was not installed   And when looking back at the build logs  it seems other bits were not installed as well 
So  my questions here are:

How do I get Python 3 6 into a Codebuild environment provisioned from a Codestar project 
Should I continue trying to build it from source or make the switch to the Ubuntu environment 
How can I automatically configure the image / environment within my code/project 

EDIT 1 For anyone else  my complete buildspec yml for installing and using Python3 6 is below  Note  it keeps everything as quiet as possible in order to reduce the log messages  reduce Cloudwatch cost and speed up the process   I ended up shaving about 90 seconds off the whole process by doing that (installing Python and building my app)   Since CodeBuild charges based on time spent  this is crucial 

"
56591312,"I want to stream HTTP requests into BigQuery  in real time (or near real time)   
Ideally  I would like to use a tool that provides an endpoint to stream HTTP requests to and allows me to write simple Node such that:
1   I can add the appropriate insertId so BigQuery can dedupe requests if necessary and
2   I can batch the data so I dont send a single row at a time (which would result in unnecessary GCP costs)
I have tried using AWS Lambdas or Google Cloud Functions but the necessary setup for this problem on those platforms far exceeds the needs of the use case here   I assume many developers have this same problem and there must be a better solution 
"
60602511,"Im trying to print out every snapshot that hasnt got the specific Tag CostReference inside my aws account  
To Iterate through the snapshots Im using: 

So far so good the code is working  but Im also getting the public Snapshots that are owned by amazon  wich have no relevance for me 
Is there any way to filter those public snapshots 
Greets
Code for the other functions:

managedpsp is a list with valid Costreference - tags
"
43263923,"Im new to Lambda and trying to figure out how to process Stripe charge in Lambda function 
My app creates token from Stripe API and now I need to send that token to Lambda function to execute  and  
Here are the issues Im having

Im not sure how to load  into Lambda function so I can use  function
Would love to get a sample code to charge credit card by token

Thank you 
"
53990306,"I have to upload video files into an S3 bucket from my React web application  I am currently developing a simple react application and from this application  I am trying to upload video files into an S3 bucket so I have decided two approaches for implementing the uploading part 
1) Amazon EC2 instance: From the front-end  I am hitting the API and the server is running in the Amazon EC2 instance  So I can upload the files into S3 bucket from the ec2 instance 
2) Amazon API Gateway + Lambda: I am directly sending the local files into an S3 bucket through API + Lambda function by calling the https URL with data 
But I am not happy with these two methods because both are more costly  I have to upload files into an S3 bucket  and the files are more than 200MB  I dont know I can optimize this uploading process  Video uploading part is necessary for my application and I should be very careful to do this part and also I have to increase the performance and cost-effective 
If someone knows any solution please share with me  I will be very helpful for me to continue my process 
Thanks in advance 
"
42964429,"I have couple of lambda functions and all of these functions have one function common  Since it is common and most of the code is in that common function  So it is logical to consider separate lambda function for that particular function 
But It discouraged me when i think about cost prospective  I mean  invoking one lambda will automatically invoke another lambda  So one event will hire two different resources  and it does not seems me cost effective  Is it so 
"
56772299,"We have been using AWS S3 notifications to trigger lambda functions when files land on S3 and this model has worked reasonably well until we noticed that some files are processed multiple times  generating duplicates in our datastore 
We noticed that it happened for about 0 05% of our files 
I know can guard against this by performing an upsert  but what is of concern to us is the potential cost of running unnecessary lambda functions  as this impacts our cost 
Ive searched Google and SO  but only found similar-ish issues  We are not having a timeout problem  as the files have been processed fully  Our files are rather small  with the biggest file being less than 400k  We are not receiving the same event twice  as the events have different request ids  even though they are running on the same file 
"
59736237,"I have a aws lambda function which is invoked by API Gateway  The Lambda function calls external API endpoints and it sometime receives network time out while calling external API 
What is the best way to implement retry mechanism in aws lambda to handle network time out or other server side errors  Also is it good to use retry inside lambda function  which cost as per execution time 
Any recommendation is highly appreciated 
Regards
"
60787022,"I am new to aws lambda and I am moving my spring boot 2 x based project to lambda But I am struggling with lambda cold-start and warm-up  I tried a few things mentioned in this link:  but still the application takes around 45 secs to start 
Things I tried:  

Async initialization from the above link  It did help a bit but not enough   
Skip the Init phase of the lambda  It helped reduce almost 8 secs   
Provisioned concurrency but as far as I could see  it is not helping either  When I saw the logs  the spring context is getting initialized every time  if any request comes after an interval of 15-20 mins 

The response time of my lambda in different scenarios is: 

To reduce this response time  I am thinking of making a REST call to my lambda every 5 or 10 mins so as to keep the spring context in memory and that in turn would help serve the requests faster  This call will be like a health check call  very less to no processing at all 
Is this an advisable approach  Or is there a better way of achieving this goal  
I am unclear about AWS will charge in this case 
"
62238188,"Im trying to build a serverless NuxtJS app  utilizing firebase for authentication  netlify for deployment (and functions) and stripe for payment  
This whole payment-process and serverless functions on netlify is all new to me  so this might be a nooby question  
Ive followed serveral docs and guides  and accomplished an app with firebase authentication  netlify deployment and serverless functions making me able to process a stripe payment - now I just cant figure out the next step  My stripe  leads to a  route containing a success message -&gt; though here Id need some data response from Stripe  making me able to present the purchased item and also attaching the product id as a bought-product entry on the user object in firebase (the products will essentially be an upgrade to the user profile) 
Click buy product function

create-checkout Netlify function

Please let me know if you need more information  or something doesnt make sense 
tldr; Ive processed a Stripe payment in a serverless app using Netlify function  and would like on the success-page to be able to access the bought item and user information 
"
56453496,"Quickly introducing my scenario: I have a VPC that contains an API Gateway that redirects its calls to my Lambda functions and then they access both an RDS instance and external API calls (internet access) 
How its structured
Due to the fact that the functions need to access the RDS  Ive put both RDS and Lambdas in the same VPC  properly securing the RDS without public accessibility  Now  because the Lambdas are in a VPC  they need a NAT Gateway to access the internet (almost all of those functions need to call third parties APIs)  and this is where Im facing an enormous problem 
The problem
I have a small project to serve a few users (ranging from 10 to 200 users) and with the serverless setup that Ive created  Im expecting costs to be from $3 00 to $10 00 each month  Thats the cost without a single NAT Gateway  Now  and if we add the price of a Gateway  which is  - and Im not even taking into consideration the $0 045 per GB of data transferred -  thats &gt;$30 per month  It would be dumb of me to not create another to be Multi-AZ and mitigate possible availability zone failure - so &gt;$60 00 for 2 NAT Gateways  
This is not only impractical for me  but wouldnt it also invalidate the point of the whole serverless structure that normally follows an on-demand approach 
How to solve this 
One of my alternatives is to move the Lambdas out of the VPC (meaning no VPC) and accessing the RDS through some mechanism without making it publicly accessible - and here is where Im also failing  how would one securely access the RDS in the scenario where Lambdas functions are outside the RDS VPC 
In the worst case scenario - I know its bad to expose my RDS to the public - but how big of a vulnerability is exposing it 
Keep in mind that Im not blaming AWS prices  this is solely focused on finding alternatives to the NAT Gateway one - I appreciate suggestions to solve this case  Also  Im sorry if I made a totally wrong assumption  Im new to the AWS ecosystem 
"
69707921,"I have registered a free tier AWS Lambda account and created a simple  public service for me and others to play around with  However  since I do not know yet how usage is going to be  I want to be careful for now  Otherwise someone could simply flood my service with one million requests and I get billed for it  Id rather not have the service available 
Therefore  I want to create a budget action that shuts down all services as soon as $0 01 is exceeded  The way Ive done this is that Ive granted the Lambda service role (which was auto-created when I setup the lambda service) the budget permission (budgets amazonaws com) and then have an IAM action setup that adds the  managed policy to the role itself once the budget is exceeded 
This does not seem to work  If I manually attach the  policy  the Lambda service still is available  My understanding of the roles/policies system may be also fundamentally wrong 
How can I achieve a total shutdown action that can be triggered from a budget alert 
"
69109082,"I have a chatbot that I made with selenium  This chatbot should work on multiple users  At the same time  I need to pull and push data from the chatbot  And I want users to be able to command the bot whenever they want  Closing the bot  Writing a message  etc 
When the button is pressed from the panel  I want to raise the bot to its feet  I thought of many ways to do this  Django Celery build  Heroku  Docker Container or Aws Lambda Container   With which platform can I ensure that the bot works perfectly  that the communication takes place and that the cost is the least  Do you have a previous source 
"
45944285,"I am looking for a place to buy/sell AWS lambda/azure functions/google functions scripts  Does anyone know if such a thing exists  Would anyone else be willing to pay for this 
"
62065707,"I am looking into different FaaS providers and am interested how much disk space I have per function  A function in AWS Lambda has 512 MB of disk space available (see ) and Azure functions have up to 1000 GB of disk space  depending on the pricing model (see ) 
How much does a GCP Function have  
When searching the documentation  I could only find that functions do have disk storage  but not how much (see ) 
"
69674140,"Im using axios in a lambda function to download a file from a user provided url  Obviously that file could be any size  and might be served at any speed  I am concerned that might create Denial of Service and Denial of Wallet risks 
I dont know if aws have any charges for lambda ingress  I havent been able to find a definitive answer yet  Even if they dont though  large uploads could still force my lambdas to run for longer (costing me money) and potentially pushing me up against the rate limits I have set  in part  to mitigate flooding attack risk (denying people service) 
Likewise  very slow downloads might cause my lambdas to run til they time out  My timeouts are set fairly high because there is processing to do once the file is downloaded  Id rather bale after a small handful of seconds as the input data should always be small and fast 
So what I want is for downloads to abort if they hit a preset maximum size in bytes OR a maximum download time 
If adding these limits isnt possible with Axios then Im open to using different libraries like node-fetch 
"
66060449,"Im making a lambda function that will generate a pdf file that then needs to be sent to S3 
The file is generated in the lambda function  so I cant use a pre-signed url to upload it from the client since the client does not have the file  The file generated will not be on the range of 512MB (lambda /tmp storage limit) but will be more than 6MB 
Im not sure yet if i should convert this to a container instead since lambda has a maximum request payload of 6MB 
One idea that came to mind is to use s3 multipart-upload and upload the parts into chunks of 4MB 
Does that actually solve the problem though  Or should i just create a container instead 
Taking into account lambda cost savings having a way to go around the lambda 6MB limit would be very beneficial in my case 
"
48630799,"I have a Lambda that is generating and returning a value  This value can expire  Therefore I need to check the values validity before returning 
As generating is quite expensive (taken from another service) Id like to store the value somehow 
What is the best practice for storing those 2 values (timestamp and a corresponding value) 

DynamoDB  but using a database service for 2 values seems to be a lot of overhead  There will never be more items; The same entry will only get updated 
I thought about S3  but this would also imply creating a S3-Bucket and storing one object containing the information  only for this 2 values (but probably the most lean way )
Would love to update Lambdas configuration in order to update the environment variables (but even if this is possible  its probably no best practice   Also not sure about inconsistencies with Lambda runtimes   )

Whats best practice here  Whats the way to go in terms of performance 
"
42877521,"There are a few pieces of my app that cannot afford the additional 1-2 second delay caused by the freeze-thaw cycle that Lambda functions go through when theyre new or unused for some period of time 
How can I keep these Lambda functions warm so AWS doesnt have to re-provision them all the time  This goes for both 1) infrequently-used functions and 2) recently-deployed functions 
Ideally  there is a setting that I missed called keep warm that increases the cost of the Lambda functions  but always keeps a function warm and ready to respond  but Im pretty sure this does not exist 
I suppose an option is to use a CloudWatch timer to ping the functions every so often    but this feels wrong to me  Also  I dont know the interval that AWS uses to put Lambda functions on ice 
"
56067806,"Lets say in my client I have a list of PKs :

And I need to get the objects that have these corresponding PKs 
I can think of 3 ways :
Transaction
Using TransactGetItems  I can fetch 10 items at a time  so I would just get each item individually untill I get them all
Batch get Items
Same as Transaction  but not transactional and I can fetch 25 items at a time 
Query with filter (probably messy)
I could instead have a GSI that has a immutable attribute as Partition key  and set the original Partition key as a attribute  and I could just chain a bunch of ORs in the condition expression 
For example (boto3):

Now  according to the pricing page :

DynamoDB charges one read request unit for each strongly consistent
  read (up to 4 KB)  two read request units for each transactional read 
  and one-half read request unit for each eventually consistent read

Im not sure what 1 read is  does it considers every object returned or every object scanned  Will each different request be 1 RCU at minimum or do they sum untill it reaches 1 RCU 
Which of the 3 examples above would be the cheapest following DynamoDB pricing system  Is there another way of doing this 
Bonus points for the calculation 
"
55702144,"Ive just figured out a big mistake I had while creating the dynamodb structure 
Ive created 11 tables  whereas one of them is the table mostly refereed to and the others are complementary tables 
For example  I have a table where I hold names (together with other info) called Names and another table called NamesMappings holding all these names added to the Names table so that each time a user wants to add a name to the Names table he first tries to put the name in NamesMappings and only if it succeed (therefore this name doesnt exist) he can add the name into the Names table  This procedure helps if the name is not unique and is not the primary key in the Names table and with this technique I dont have to search inside the Names table if the name exists  but instead I can try to add it to the NamesMappings table and only if it succeed I know this is a unique name 
First of all  I would like to ask you if this is a common approach or there is a better one 
Next  I figured out that with this design I soon reached to 11 tables each has 5 provisioned capacity of read and write which leads to overall 55 provisioned read and write under the free-tier  Then I understood why I get all these payments each month  because as the number of tables is getting bigger  and I leave the provisioned capacity as default (both read/write capacity are 5) I get more and more provisioned capacity 
So  what should be my conclusion from this understanding  Should I try to reduce the number of tables even if it takes more effort to preform scanning and querying inside the table  Or should I split the table same as I do but reduce the capacity of these mappings tables used only for indication if an item exists or not in another table 
"
38982603,"What is a good way to deploy a WebSockets client on AWS 
Im building an app on AWS which needs to subscribe to several WebSockets and several REST sources and process incoming messages (WebSockets) or make periodic requests (REST)  Im trying to go server-less and maximize use of AWS platform services  to eliminate the need to manage VMs  OS patches  etc  (and hopefully reduce cost) 
My idea so far is to trigger a Lambda function every time a message arrives  The function can then transform/normalize the message and push it to an SQS queue for further processing by other subsystems 
There would be two types of such Lambda clients  one that subscribes to WebSockets messages and another that makes HTTP request periodically when invoked by a CloudWatch schedule  It would look something like this:

This approach seems reasonable for my REST clients  but I havent been able to determine if its possible to subscribe to WebSockets messages using Lambda  Lambdas can be triggered by IoT  and apparently IoT supports WebSockets now  but apparently only as a transport for the MQTT protocol:

What is the best/easiest/cheapest way to deploy a WebSockets client without deploying an entire EC2 or Docker instance 
"
45209250,"Im building an API that will act as a proxy to n underlying APIs that all do the same thing   It will use  pattern to determine when one of the underlying APIs is unavailable  therefore the proxy API will have state  One solution is to run the API on AWS lambda and store the circuit breaker state in AWS ElastiCache  
Is there another more cost effective solution that would not require me to run an always on service like ElasticCache 
"
46916670,"I have a lambda that is coded in python 3 6 with some SQL queries in it to parse to aws Athena  This lambda will be triggered by a dynamoDB whenever there is a new item that falls into dynamodb  For each new item  I want to spin up a lambda  For suppose  if there are 100 new items that fall into DynamoDB- there will be 100 concurrent Lambda that will execute  But in this process  there was a moment where one of the SQL query failed in Athena and lambda cannot complete the calculation for that dynamodb record  
Note: the data of each record in dynamodb will be parsed to SQL queries in python and to AWS ATHENA 
My question: When there is an error in one of the concurrent Lambdas how do I stop this process  the lambda is repeating the execution for the same record which is costing me  
"
61040234,"Is there a way to get current status from an AWS account either through AWS cli or programmatically 
I am conducting some research in relation to FaaS and would like to get and log the cost after each experiment but havent been able to find a solution for this  
Would really appreciate if somebody could point me in the right direction here :)
Thanks 
"
58805577,"I am trying to come up with a solution for aws cost optimization  I am able to do it with cloudwatch rule and Lambda  this approach is working fine if I have to directly stop the instance and no auto-scaling group is associated with that instance 
Problem is when we are  managing the instances using auto-scaling group  I am able to scale up the only instance associated with one auto-scaling group at one time using lambda  My use case is that I have to scale up multiple instances associated with multiple auto-scaling groups using lambda 
There is one method which aws provide to update the autoscaling configuration as below:


But this way I can only update the configurations of 1 auto-scaling group at one time  Is there any way we can do it for multiple instances associated with multiple auto-scaling groups 
"
48269652,"I have an application running in N Virginia Region  I want to configure Regional failover such that if my N Virgina region or application goes down  same application should come up secondary Region  Initially secondary Region should not have any resources  May be we can only have a CloudFormation template for application or an Lambda function in secondary Region which could bring up all the resources in secondary Region 
For data replication between regions  I will have snapshots of EBS copied periodically to secondary region  and will run a Read replica of RDS in secondary region  But I want  EC2  Loadbalancer  EBS and other resources to spin up on failover 
My primary concern is to achieve Region level high availability without having to spend cost on secondary Region until failover happens 
"
62663403,"I have a python script which copy files from one S3 bucket to another S3 bucket  This script needs to be run every Sunday at some specific time  I was reading some of articles and answers  So I tried to use AWS lambda + Cloudwatch events  This files run for minimum 30 minutes  would it be still good with Lambda as Lambda can run max 15 minutes only  Or is there any other way  I can create an EC2 box and run it as a Cron but that would be expensive  Or any other standard way 
"
41479792,"I am just looking for ideas on how to solve one specific thing Id like to build 
Say I have two sets of items  Each item is just a couple of lines of JSON  Any time an item is added to one set I immediately (well  almost) want to process this against the full other set  So item is added to set A: Process against each item in set B  And vice versa 
Items come in through API Gateway + Lambda  Match processing in Lambda from a queue/stream 
What AWS technology would be a good fit  I have no idea and no clear pattern on when or how often the sets change  Also  I want it to be as strongly consistent as possible  And of course  I want it to be as serverless and cost-effective as possible  :)
Options could be:

sets stored in Aurora  match processing for a new item in A would need to query the full set B from the database each time
sets stored in DynamoDB  maybe with DynamoDB stream in the background; match processing for a new item in A would need to query the full set B from Dynamo; but spiky load  not a good fit because of unclear read/write provisioning
have each set in its own static Kinesis stream where match processing reads through items but doesnt trim  Streams to be replaced with fresh sets regularly

My pain point is: While processing items from A there might be thousands of items in B to be matched  And I want to avoid having to load the full set B from some database every time I process an item from A  I was thinking about some caching of sets but then would need a good option to invalidate that cache whenever something changes  
"
54961279,"We have a aws lambda function that processes some data and incase there is an error it sends out an email 
We experienced a surge of email from the lambda function so we changed the script and disabled the part where it sends email    Unfortunately we still see the emails comming in 
So we deleted the function and we still keep receiving the error emails 
How can the lambda function still be running    Would i be experiencing charges since the function is running 
John
"
61664757,"I have a nextjs app that Im using to process stripe payments that Ive deployed to Vercel  The app is simply a form with tons of functionality built in but requires the use of an api (which is why Im using nextjs)  What is the best way to get this into a php site  I need to access the nextjs api in order to communicate with stripe  Otherwise I would have just built the react app in the php site and rendered it on the page in question per usual  Ive never done this before  so please any recommendations would be huge 
Here are the options Ive come up with: 

iframe  Ive never been a huge fan of these  but figured this was an option  I can render my app via iframe on the php site  
use the vercel deployed nextjs app strictly for the api and build the react form into the php site  Then I would simply change the api requests to point to the vercel deployed nextjs app instead of a local api 

Are there better more efficient methods  
"
71486476,"I have 8 TB of on premise data at present  I need to transfer it to AWS S3  Going forward every month 800gb of data will be required to update   What will be the cost of the different approaches 

Run a python script in ec2 instance 
Use AWS Lambda for the transfer 
Use AWS DMS to transfer the data 

"
62765780,"I have created a model endpoint which is InService and deployed on an ml m4 xlarge instance  I am also using API Gateway to create a RESTful API 
Questions:

Is it possible to have my model endpoint only Inservice (or on standby) when I receive inference requests  Maybe by writing a lambda function or something that turns off the endpoint (so that it does not keep accumulating the per hour charges)

If q1 is possible  would this have some weird latency issues on the end users  Because it usually takes a couple of minutes for model endpoints to be created when I configure them for the first time 

If q1 is not possible  how would choosing a cheaper instance type affect the time it takes to perform inference (Say Im only using the endpoints for an application that has a low number of users) 


I am aware of this site that compares different instance types ()
But  does having a moderate network performance mean that the time to perform realtime inference may be longer 
Any recommendations are much appreciated  The goal is not to burn money when users are not requesting for predictions 
"
65906702,"Seems a little inefficient the way it currently is:

Lets say the userService and friendsService are configured on different API Gateway endpoints 
Then wouldnt that make the network request take longer than if I were to just package my entire backend into one zip file thats uploaded to AWS Lambda 
Seems like this is very inefficient 
Is there a way to call other lambdas without having to make a network request  I understand putting the lambdas/gateway in the same VPC as the main Gateway endpoint exposed to the internet  but this is expensive 
Anyway to do this more efficiently 
"
58498009,"Consider my Lambda package size is 100 mb (unzipped) and on its invocation  it uses say x mb  So will I be charged for the memory slot w r t (x + 100) mb OR only x mb 
"
65309501,"I am implementing the server side of my app in azure functions  I usually make a lot of smaller private functions(e g parsing data) to keep my code clean and improve usability and readability but working in azure functions is making me wonder what are the best practices in the current scenario 
Should I make smaller private functions and do they incur additional cost when called from my main http trigger functions or should I put all code in the http trigger function  The latter seems like a very unintuitive approach 
"
54562914,"Im trying to take advantage of db connection reuse in Lambda  by keeping the code outside of the handler  
For example - something like: 

The issue is I dont decide what database to connect to until I do a lookup to see where they should be connecting  In my specific case I have customer=foo in a query param then I can look to see that foo should connect to database1  
So what I need to do is something like this : 

The way it is now I need to do this in every handler method which is expensive  
Is there some way I can pull the query parameter  look up my database and set it / switch it globally within the Lambda execution context  
Ive tried this: 

Everything works locally with  but doesnt work through the AWS Lambda execution context  Thoughts  
"
63925195,"I am working on a node js back-end for an application where customers make requests for a certain service  Once they make a request  the payment amount get held on Stripe  then get captured once the service is delivered 
But if the service was not delivered within a certain number of days  the request get canceled (on database) and the payment get released 
For that  I needed an external service which allows me to schedule a call (once) to an API (of mine) programmatically for each customer request 
This way I can schedule a call for each customer request to run on the final date of that request while holding its info  My API can then use that info to check the status of the request and make the required changes to the database as well as payment release in case the service was not delivered 
I Knew that I can do this by scheduling a rule (problematically via the put-rule command using the aws-sdk) that triggers a lambda function which execute against my API  but I need an example on how to do this Knowing that Ill be passing an API parameter (which is the request_id) from the cloudwatch event to the lambda function 
"
69420211,"According to the AWS Solutions Architect labs that I am currently following  AWS Lambdas are ideal for IoT applications 
Im unclear on why this is 
Is it because the compute capacity of such devices are typically very limited so it makes sense to offload processing to the cloud 
If this is the case  why is Lambda more effective for the purpose than a more typical server running on EC2 or EKS 
Is this assessment based purely on the costing model 
"
61587158,"Actually i want to reduce AWS bill  I am using some of the instances in my project  I want a notification after certain time period(every 3rd/4th hour) on my login email id and shutdown on a particular time duration  So  how can i do this  

"
69246714,"I have two AWS accounts with VPCs connected with peer connections  I have RDS Proxy on account 1 and Lambda in the private  isolated subnet on account 2 
I cannot figure out how to connect to RDS Proxy  I was trying all possible VPC endpoints and interfaces and whatnot 
The only way I managed to connect was through NAT Gateway  but its expensive  And to be honest  weird  if I want to keep a private network 
Is it possible to have a PrivateLink or something 
How should I connect to RDS Proxy from Lambda 
I have attached the CF template (I hope I cleaned it from all sensitive data 😑):

"
53203024,"Using ExpressJs and ClaudiaJs I have published a web server to AWS Lambda  This servers job is to process Stripe payments  I am trying to get my React SPA to submit the Stripe checkout from the client  but am receiving a CORS error when I try to submit  
How can I avoid this CORS error  I would imagine I need to either publish both client and AWS server on the same TLD (not sure how to make that work)  or Id need to disable CORS on the server (but that seems insecure) 
Stripe server call:

Form submission

"
55871395,"Lets say I have an app where  can make   I store these in a single DynamoDB table using the following design:

When a  makes a   my Lambda function receives the following data:

My question is  should I first verify that the  exists before adding the  to the table by using   This would make sure there wont be any orphaned   but also the function will require both a read and write unit  
One idea I have is to just write the   potentially allowing orphaned   Then  I could have another Lambda function that runs periodically to find and remove any orphans 
This is obviously a simple case  but imagine a more complex system where objects have multiple relationships  It seems it could easily get very costly to check for relationship existence in these cases 
"
63936826,"Heres my thing:
I got 2 functions A &amp; B:

A is in a default Lambda VPC  provided by AWS  that has open internet access
inbound and outbound
B is in a specific VPC with a RDS DB  with inbound access but no
Internet access (no NAT Gateway) 

The process is this :

A sends data to B (via API Gateway) while B inserts that data in a RDS Database
B is supposed to send confirmation (via another API Gateway) of whether its okay or not but A keeps getting a 502 error (timeout I guess) 

At first I thought it was a stupid Lambda proxy output format error but now I realised its more serious than that 
Im looking for some easy/cheap way out (im a student on a budget and this is a PoC)  Is there some kind of easy solution to this problem 
"
52834146,"Im using IoT Core for recieve MQTT and HTTPs petitions
Now I want to use something similar to azure cloud services to listen all the time from a devices whose send me data through UDP/TCP
It would be possible to use a Lambda function  Maybe this will be too expensive because it could be called thousands of times per day 
If I use an EC2  how I could do it to receive and then send this data  for example  to S3/DynamoDB 
"
53811923,"I am accessing  service from my   code  Here I set my lambda concurrency as 1  
Since creating/closing database connection is an expensive process  I have created the  connection and made it static  So it will reuse the same connection every time  I havent added the code to close the connection  
Will it cause any problems  
Will it automatically close after some days 
"
53629318,"Question
Ive read  and  and  articles  But they provide contradictory answers to the question: how to customize partitioning on ingesting data to S3 from Kinesis Stream  
More details
Currently  Im using Firehose to deliver data from Kinesis Streams to Athena  Afterward  data will be processed with EMR Spark 
From time to time I have to handle historical bulk ingest into Kinesis Streams  The issue is that my Spark logic hardly depends on data partitioning and order of event handling  But Firehouse supports partitioning only by  (into Kinesis Stream)  not by any other custom field (I need by )  
For example  under Firehouses partition  I can get data for the last few years  
Workarounds
Could you please help me to choose between the following options 

Copy/partition data from Kinesis Steam with help of custom lambda  But this looks more complex and error-prone for me  Maybe because Im not very familiar with AWS lambdas  Moreover  Im not sure how well it will perform on bulk load  At  it was said that Lambda option is much more expensive than Firehouse delivery  
Load data with Firehouse  then launch Spark EMR job to copy the data to another bucket with right partitioning  At least it sounds simpler for me (biased  I just starting with AWS Lambas)  But it has the drawback of double-copy and additional spark Job 

At one hour I could have up to 1M rows that take up to 40 MB of memory (at compressed state)  From  I know that Kinesis to Lambda event sourcing has a limitation of 10 000 records per batch  Would it be effective to process such volume of data with Lambda 
"
69042070,"I am stuck in my current situation: I have a regular Aurora MySQL RDS cluster and some apps that make use of it (some query the database constantly)  now I also have a Next js application hosted on Vercel  this moment I realised I cannot connect to the database in my serverless functions 
How can I deal with this situation  I figured one easy way would be to migrate to Aurora serverless but I think that will be expensive because of the apps that constantly query the database (both the serverless function and apps should access the same data)
"
62801694,"I want some solution where a CloudWatch rule triggers the lambda function that takes a snapshot and shutdown the cluster at the given time  and resume the cluster from the created snapshot at another time 
This way a lot money can be saved 
As of now  AWS does not provides such solutions  Cluster Pause and Resume can be done by scheduling but still we need to pay for the storage resource of the cluster 
"
62207524,"I am working on a AWS amplify application and I have an existing AWS API gateway(payments api  payments path) which points to a  Net lambda function(payments namespace  payments class  createPaymentIntent method name) 
a  If I edit the  Net lambda functions payments class to add another public method  how do I expose it as an api  
b  Similarly if I add another class(charges ) and a public method(ListAllCharges) to the  Net lambda function project  how do I expose it as an api  


"
39590227,"So I have created a lambda function (the purpose of which doesnt matter anymore) and have tested that it works when run from my laptop   However the bigger problem is that I cannot get it to run off of a test event or on a schedule in AWS  
When I try to run it from AWS I get a 300s timeout error  
The following is included for your consideration:

Function
Logs
Trigger Event
Policy
VPC Related Configuration

If anyone can tell me what the issue might be  I would appreciate it as I have been searching for the solution for about 3 days 
FUNCTION:

LOGS:

TRIGGER_EVENT:

EDIT-1
IAM POLICY:
From my understanding all I need to allow VPC Access to my function is to add the following privilages to the lambda functions assigned policy  

ec2:CreateNetworkInterface
ec2:DeleteNetworkInterface
ec2:DescribeNetworkInterfaces




EDIT 2
CONFIGURATION:
The subnets  security groups and VPC attached to the function 

EDIT 3 (CONCLUSION)
Mark Gave an excellent answer  informing me that I had set my function up to run inside a VPC yet I was not accessing resources within the VPC   Rather  I was accessing the Amazon API endpoint which required that I have access to the internet or the transaction would timeout 
As such  there were two options available to fix this situation  

Remove my VPC settings
Create a NAT Gateway inside my VPC

I chose the one that costs the least money 
"
43294224,"Would it be possible to use AWS Lambda to run unsafe user scripts  It should be:

should have memory limit (seems like AWS Lambda has it) 
should have execution timeout (seems like AWS Lambda also has it)  Additionally it should be impossible to setup something like  
(would be nice to have) different scripts should be isolated 

Would it be efficient  Like for example you have lets say 5000 different scripts and every one of it get executed once for every 1-30 sec 
How much more would it cost compared to do the same using usual AWS instance  Order of magnitude precision would be fine  like saying it will cost you no more than 10x same on usual AWS instance would be good enough 
"
58953674,"I have a AWS Lambda function that I invoke with every 1 minute with &gt;1000 SNS events  This is a problem because my account concurrency is set at 3000  so if I start adding more jobs then eventually Im going to have &gt;3000 concurrent Lambda instances 
Each job takes around 2-5 seconds to complete which means that within each 1 minute window the concurrency limit will only be threatened within the first 5 seconds and Ill have 0 concurrency for the remaining 55 seconds 
If I set a concurrency limit (e g  1000) for the lambda will it handle the first 1000 SNS events and then automatically pick up the remainder once the concurrency frees up  And will I only be charged for the actual runtime rather than time spent waiting for concurrency to reduce 
Otherwise  is there a way that AWS will allow me to spread the load of jobs throughout the 1 minute window so that I can invoke the lambda every ~5 seconds with a subset of the total number of jobs 
"
69779139,"Quick Summary:
I can not make the Payment Sheet compatible with a Market Place Concept 
I am implementing the flutter_payment Package to create an App where Vendors can offer Products which can be purchased by clients  I use Stripe Standard Accounts and a Direct Charge 
The Working Process is:
1 ) User clics on Button and request Data from Firebase Cloud Functons 
2 ) Firebase Cloud Functions:
2 1 ) Create CustomerId (automatically on Platform Account)/ Get Customer Id from Firebase
2 2 ) Get ephemeralKeys from CustomerId

2 3 ) Create Payment Intent

3 ) Then I pass the Data back to the App and pass them into the Payment Sheet

Problem:
The Client is created on the Platform Account and the payment data is stored there  If I try to create the Payment Intent with the stripeAccount: vendorId property  the Customer Id is not being recognised as its not being stored on the Connect account 
Now what the Stripe Documentation says is to clone the Payment Method:

I can not clone the Payment Method because it is being created by flutter_stripe
So I have no idea how to proceed as the flutter_stripe package is not well documented and the package is not compatible to the Stripe Documentation 
Is a Payment Sheet a possible solution here at all 
Thank you very much 
Tim
"
47114831,"I am looking to use some serverless api server for AWS Lambda /zappa that uses a custom API Gateway authorizer for user authentification  In serverless AWS lambda service is there a considerable security or cost benefit in using custom authorizer rather than checking the issued JWT token directly in your code controller  For me checking with the code could be more convenient 
UPDATE
I went for pre request hooks  however there is header level authorizer  it is easier to use for CORS  yet it is not supported by zappa I believe  Also setting mock API for Options might be possible via swagger upload  will update if succeed 
"
55421789,"The goal is to scan and return all of the items in a DynamoDB table  but before the response is returned  modify a specific attribute of each specific item 
I have this completed already  but Im curious to know if there is a more cost-effective way without looping through all the items 
Currently Im returning a complete scan of the table and looping through each list item (found out it is not an object but a list):

I doubt the solution can be resolved without looping but if there is a solution that avoids looping Im eager to hear it 
"
63130531,"This is my use case:
I have a JSON Api with 200k objects  The dataset looks a little something like this: date  bike model  production time in min  I use Lambda to read from a JSON Api and write in DynamoDB via http request  The Lambda function runs everyday and updates DynamoDB with the most recent data 
I then retrieve the data by date since I want to calculate the average production time for each day and put it in a second table  An Alexa skill is connected to the second table and reads out the average value for each day 
First question: Since the same bike model is produced multiple times per day  using a composite primary key with date and bike model wont give me a unique key  Shall I create a UUID for the entries instead  Or is there a better solution 
Second question: For the calculation I would need to do a full table scan each time  which is very costly and advised against by many  How can I solve this problem without doing a full table scan 
Third question: Is it better to avoid DynamoDB altogether for my use case  Which AWS database is more suitable for my use case then 
"
52779003,"For an interface from our VPC to a FTP Server in the WWW we think about realizing it with talend  From our Security Officer and some other sources I heard that connecting from a VPC via talend to a source in the WWW is not the best idea  So we came up with two other versions:

Put a microservice in between 
Use a lambda function and let the
function put the data into a bucket

From security &amp; cost &amp; efficiency perspective I think V3 would be the best idea but maybe someone else experienced something different or having even a better idea    

"
44792573,"In my first foray into any computing in the cloud  I was able to follow Mark Wests  on how to use AWS Rekognition to process images from a security camera that are dumped into an S3 bucket and provide a notification if a person was detected  His code was setup for the Raspberry Pi camera but I was able to adapt it to my IP camera by having it FTP the triggered images to my Synology NAS and use CloudSync to mirror it to the S3 bucket  A step function calls Lambda functions per the below figure and I get an email within 15 seconds with a list of labels detected and the image attached 

The problem is the camera will upload one image per second as long the condition is triggered and if there is a lot of activity in front of the camera  I can quickly rack up a few hundred emails 
Id like to insert a function between make-alert-decision and nodemailer-send-notification that would check to see if an email notification was sent within the last minute and if not  proceed to nodemailer-send-notification right away and if so  store the list of labels  and path to the attachment in an array and then send a single email with all of the attachments once 60 seconds had passed 
I know I have to store the data externally and came across  explaining the benefits of different methods of caching data and I also thought that I could examine the timestamps of the files uploaded to S3 to compare the time elapsed between the two most recent uploaded files to decide whether to proceed or batch the file for later 
Being completely new to AWS  I am looking for advice on which method makes the most sense from a complexity and cost perspective   I can live with the lag involved in any of methods discussed in the article  just dont know how to proceed as Ive never used or even heard of any of the services 
Thanks 
"
60593344,"I am going to mention my needs and what I have currently in place so bear with me  Firstly  a lambda function say F1 which when invoked will get 100 links from a site  Most of these links say about 95 are the same as when F1 was invoked the previous time  so further processing must be done with only those 5 new links  One solution was to write to a Dynamodb database the links that are processed already and each time the F1 is invoked  query the database and skip those links  But I found that the database read although in milliseconds is doubling up lambda runtime and this can add up especially if F1 is called frequently and if there are say a million processed links  So I decided to use Elasticache with Redis 
I quickly found that Redis can be accessed only when F1 runs on the same VPC and because F1 needs access to the internet you need NAT  (I dont know much about networking) So I followed the guidelines and set up VPC and NAT and got everything to work  I was delighted with performance improvements  almost reduced the expected lambda cost in half to 30$ per month  But then I found that NAT is not included in the free tier and I have to pay almost 30$ per month just for NAT  This is not ideal for me as this project can be in development for months and I feel like I am paying the same amount as compute just for internet access 
I would like to know if I am making any fundamental mistakes  Am I using the Elasticache in the right way  Is there a better way to access both Redis and the internet  Is there any way to structure my stack differently so that I retain the performance without essentially paying twice the amount after free tier ends  Maybe add another lambda function  I dont have any ideas  Any minute improvements are much appreciated  Thank you 
"
57165405,"This really wasnt clear for me in the Docs  And the console configuration is very confusing 
Will a Docker Cluster running in Fargate mode behind a Load Balancer shutdown and not charge me while its not being used 
What about cold starts  Do I need to care about this in Fargate like in Lambda 
Is it less horizontal than Lambda  A lambda hooked to API Gateway will spawn a new function for every concurrent request  will Fargate do this too  Or will the load balancer decide it 
Ive been running Flask/Django applications in Lambda for some time (Using Serverless/Zappa)  are there any benefits in migrating them to Fargate  
It seems to be that it is more expensive than Lambda but if the Lambda limitations are not a problem then Lambda should always be the better choice right 
"
66430023,"Just wondering if I am able to trigger a lambda function with a tweet from a specific user 
My plan is to use the lambda function to send out a pinpoint notification about the tweet that triggered the function 
Im aware that you are able to link the two via Zapier but you require a premium membership  so was wondering if there is a free method or cheaper 
Any help is greatly appreciated 
"
56812833,"I am creating a lambda with c# several different ways (serverless  lambda  with/without tests) and I end up with a lot of items in the publishing artifacts  zip file that really dont need to be there  If Im deploying the Lambda and there is a test project in the solution  I right click on the  -&gt;   follow the prompts and it ends up zipping the  libraries along with many localized versions of  and  artifacts  The output will look similar to the following:


Is there a way to limit what files go into the zip folder that gets sent to AWS   
Is there a way to exclude localized libraries  
Can I exclude other projects that are not dependencies  
Can I keep all my projects to be in the same solution and be able to publish using the built in mechanisms without sending extraneous projects 

The problem I have is that it inflates the size of the deploy package and the files are never used  so it impacts my s3 storage costs  causes slower lambda cold start times  and inefficiencies  
Searching the internet   looked promising  but it didnt make any difference for me (perhaps I did something wrong ) 
"
55249817,"I have a Django app deployed on AWS Lambda through Zappa and my app needs to communicate with the public internet  so I need to use a NAT Instance  I am using a NAT instance because its about 10x cheaper than a NAT Gateway using the free tier  The downside is that unlike NAT Gateway  a NAT Instance needs actual maintenance  and I am unsure what type of maintenance it needs  I want to learn about things I need to do to keep my server running well and healthy 
What are things I can do to make sure of that 
Here is my AWS Architecture:
All of the following is in my VPC  I have 1 subnet in ca-central-1a and 1 in ca-central-1b  In the route table  both subnets point to my NAT Instance  I have a 3rd subnet in ca-central-1b and in the route table it points to an internet gateway  My NAT Instance is in ca-central-1b 
My NAT Instance security group NATSG has HTTP and HTTPS inbounds from both of my subnets in ca-central-1a and ca-central-1b and outbound to 0 0 0 0/0  Should I make another NAT Instance in ca-central-1a and make it only inbound from the subnet in ca-central-1a i e 1 NAT Instance for each subnet  Would that be healthier/safer 
Extra information:
I disabled Source/dest check  Was that a good idea 
For my AMI I chose a recent community AMI amzn-ami-vpc-nat and I created an Auto Scale Group which has my NAT instance  It only has 1 instance  is there any point of the Auto Scale Group if theres only 1 instance in it  I am not sure that I am using the Auto Scale Group right  I simply created it but havent configured anything 
"
61915861,"I need to permanently store a string between runs of a lambda function   The function will never overlap runs  it will pull the string at the beginning and update the stored version at the end of its run 
I want to use inline nodejs in an aws lambda function  so no free tier postgres   I want to stay within the aws framework  so no http api access to free personal cloud storage   Im guessing a single s3 file is my best bet  even aurora serverless has lag time to spin back up  and will charge for storage   Are there any other options for persisting this string between runs of a lambda function   Some sort of aws caching mechanism  hopefully accessible with their aws-sdk 
"
54459262,"I have a simple one  Static website available after login - easily build and running on nginx 
But it seems to me cumbersome to server static web with small amount of connections (few per day) and spent a hours to set properly and maintain virtual machine during the lifespan of this project 
I use mostly GCP and consider their load balancer  or buckets made for static content  but none of this is able to give you a chance to auth users with passwords 
Do you have any tip for this  Provider is not concern or some kind of serverless with a pay as go will be perfect in my situation 
Thank you for your time
"
63915422,"Im running a system with lots of AWS Lambda functions  Our load is not huge  lets say a function gets 100k invocations per month 
For quite a few of the Lambda functions  were using warmup plugins to reduce cold start times  This is effectively a CloudWatch event triggered every 5 minutes to invoke the function with a dummy event which is ignored  but keeps that Lambda VM running  In most cases  this means one instance will be warm 
Im now looking at the native solution to the cold start problem:   which at first glance looks awesome  but when I start calculating  either Im missing something  or this will simply be a large cost increase for a system with only medium load 
Example  with prices from the  region as of 2020-09-16:
Consider function RAM  (GB)  average execution time  (s)  million requests per month   provisioned concurrency  (number of instances):
Without provisioned concurrency
Cost per month = 
= $16 87 per million requests @  = 1 GB   = 1 s
= $1 87 per million requests @  = 1 GB   = 100 ms
= $1 69 per 100 000 requests @  = 1 GB   = 1 s
= $1686 67 per 100M requests @  = 1GB   = 1 s
With provisioned concurrency
Cost per month = 
= $12 04 + $11 04 = $23 08 per million requests @  = 1 GB   = 1 s   = 1
= $12 04 + $1 28 = $13 32 per million requests @  = 1 GB   = 100 ms   = 1
= $12 04 + $1 10 = $13 14 per 100 000 requests @  = 1 GB   = 1 s   = 1
= $12 04 + $1104 07 = $1116 11 per 100M requests @  = 1 GB   = 1 s   = 1
There are obviously several factors to take into account here:

How many requests per month is expected  ()
How much RAM does the function need  ()
What is the average execution time  ()
What is the traffic pattern  few small bursts or even traffic (might mean  is low  high  or must be dynamically changed to follow peak hours etc)

In the end though  my initial conclusion is that Provisioned Concurrency will only be a good deal if you have a lot of traffic  In my example  at 100M requests per month theres a substantial saving (however  at that traffic its perhaps likely that you would need a higher value of  as well; break-even at about  = 30)  Even with  = 1  you need almost a million requests per month to cover the static costs 
Now  there are obviously other benefits of using the native solution (no ugly dummy events  no log pollution  flexible amount of warm instances     )  and there are also probably other hidden costs of custom solutions (CloudWatch events  additional CloudWatch logging for dummy invocations etc)  but I think they are pretty much neglectible 
Is my analysis fairly correct or am I missing something 
"
71521903,"I know that cloud functions charge money based on execution time and network costs 
I am writing a cloud function that calls 2 external APIs to authenticate a user  Both external APIs just return a single boolean and therefore dont send much info 
Which technique is better overall 

Make both external API calls using  at the same time knowing that 1 may be useless half the time 

Make the external API call one after the other  and not make the second one if not needed 


Im thinking doing #1 will shorten the wall time of my cloud function and therefore may be cheaper  But I make more external calls which may be expensive 
But doing #2 will make the cloud function stay in memory for longer and therefore more wall time 
"
58569706,"due to huge costs in our environment  I have a task to create a lambda to tag all log groups like corresponding resources (the source of these log groups)  However  I am facing a challenge to identify the resource arn of log groups  There are many logs in our environment like logs for lambda  logs for elastic-beanstalk  logs for ec2  But how can I match the log group with the corresponding resource  I would appreciate any help very much 
"
69284722,"Currently i have a state machine that receives two parameters as input 

When starting  the first step is to wait for the time determined by the  (time to execute) attribute  Finally send the content of the  attribute to a queue in sqs 
I understand that aws charges me for changes in the status of my machine  but I have no idea if a long waiting time  for example 1 week  could incur additional costs 
"
55031936,"The context here is simple  theres a lambda (lambda1) that creates a file asynchronously and then uploads it to S3 
Then  another lambda (lambda2) receives the soon-to-exist file name and needs to keep checking S3 until the file exists 
I dont think S3 triggers will work because lambda2 is invoked by a client request
1) Do I get charged for this kind of request between lambda and S3  I will be polling it until the object exists
2) What other way could I achieve this that doesnt incur charges 
3) What method do I use to check if a file exists in S3  (just try to get it and check status code )
"
55119544,"Im creating a monitoring system for an external API on which I need to invoke a function if the response is different from the initial request 
Currently without any long polling around my functions Ive got the following: 

Would AWS Lambda be a good solution for this theory  if so  how would I go about doing it since Lambda charges for computer power usage 
"
44794464,"I want to prototype an app and I thought Apps Script could be a quick way to do this  but being new to Google toolset I need someone to put me in the right direction to figure what is available and what components I need to put together to get this working 
Heres what the app does:

I put in an order in a form on a web page  (Google Forms  App Script web app )
Some inputs in the form are dynamically shown depending on previous inputs 
The inputs are validated 
There is a list of receivers with mobile numbers (Google Spreadsheets )
When submitted  the order is sent to a web service (Twilio REST API) that sends SMS text messages to each of the receivers 
Before submitting I want to be able to see a preview of the generated text message and the total cost for sending SMS 
After submitting  the order is also logged (Spreadsheets )
In the text message there is a link to a web page that is specific to that order for more details

I dont need specific code but I need to find out what to use for each step  Also any examples or samples that could help me on the way would be very useful 
Update - My specific question for now to get started is:
Is it possible to use Google Forms to have dynamic fields (entering data in one field defines next fields with their choices)  custom validations (validations are more than regex and multiple fields are validated together) and previews (when entering data  show some live calculations)  If not  how can I use Apps Script with Html to do that 
Thanks 
"
46452685,"I am developng an app with xamarin and azure serverless functions as backend for the app 
I will be syncing map coordinates from the users in real time with a database on the cloud  i e : taking coordinates from all users and then pushing the updated coordinates to all users at the same time  continuously so that all users can see live location of each other 

So I have to call an azure function in continous loop in order to sync database with cloud  so it can check db after every  4-5 secs  is it the best way to do this  or will this cause too much execution of azure function and might be costly  If there is a better way to sync the db please suggest  Thankyou 

"
54708106,"Im currently working on an indexing component where it creates the indexes in different database tables (DynamoDB  ElasticSearch etc) based on client configurations 
There could be potentially 100+ clients who need different indexing records and systems TPS is 700  Currently I have 2 approaches 

Have a single lambda listening to SQS (where events are subscribed) and pulls the data from the source and build index records for each clients and put the indexes in DB in parallel  
Or  In above approach  execution time will be longer - as parallel computation is depending on total number of cores available  So  have a small lambda that duplicates the incoming events with small number of clients (lets say for 1 incoming message  this lambda will create 10 new messages with 10 clients name in it) and push it to another SQS  And another lambda subscribed to it will listen to these messages and build index records for each clients and put the indexes in DB in parallel 

So  both approaches have few shortcomings 

Execution time is higher but less lambda invocations  Higher memory &amp; higher CPU 
Less execution time but more lambda invocations  Less memory and moderately high CPU 

So  I want to have a cost effective solutions where I can achieve indexing components maximum fan-out for building indexes for multiple clients  Also  whats the maximum parallelization I can achieve per AWS lambda instance 
"
60452363,"I am not an expert in AWS but have some experience  Got a situation where Angular UI (host on EC2) would have to talk to RDS DB instance  All set so far in the stack except API(middle ware)  We are thinking of using Lambda (as our traffic is unknown at this time)  Again here we have lot of choices to make on programming side like C# or Python or Node  (we are tilting towards C# or Python based on the some research done and skills also Python good at having great cold start and C#  NET core being stable in terms of performance) 
Since we are with Lambda offcourse we should go in the route of API GATEWAY  all set but now  can all the business logic of our application can reside in Lambda  if so wouldnt it Lambda becomes huge and take performance hit(more memory  more computational resources thus higher costs )  then we thought of lets have Lambda out there to take light weight processing and heavy lifting can be moved to  NET API that host on EC2 
Not sure of we are seeing any issues in this approach  Also have to mention that  Lambda have to call RDS for CRUD operations then should I think to much about concurrency issues  as it might fall into state full category 
"
67124114,"Im running a backend app with several endpoints on Cloud Run(fully-managed)  My endpoints are publicly available by its nature so I dont want to authenticate users through my client app hosted on Netlify 
What I do need is to restrict access to my endpoints so that other applications or malicious users cant abuse it  It is not about scaling  I just dont want to exceed the  since it is a demo of an opensource application 
Ive already set the  and  limits to minimum but this alone is not enough  There is also a product named  but it seems an expensive one  not free 
I was expecting to have a simple built-in solution for this but couldnt find it 
What other solutions do I have  How can I block the traffic coming out of my website on Netlify 
"
62132808,"I am developing a smart home skill for Alexa  So all requests from Alexa are sent to my AWS Lambda function which then forwards the requests to our servers which contacts the individual smart home devices  
So according to the Alexa documentation () I can answer these requests Synchronously  meaning I wait all the way till the operation on the device has completed (while the http connection between the lambda and our servers remain open -&gt; causing charges as lambda is running longer) and send the response via the lambda back to Alexa  
The other option is to answer Asynchronously by sending the answer as a new http request to the Alexa event gateway  
As some operations take some time (considering the way from our servers to the smart home devices  performing the operation  answering etc ) Id prefer the async method  as it also saves the time on the lambda  I already implemented all the necessary components to answer async but I dont know what I should answer the lambda in case Ill answer async 
My Lambda currently looks somewhat like this:

When I just do a context succeed() without a proper response Ill get an error in the Alexa app  telling me the device is not reacting  followed by indicating the correct status as quickly after that Alexa receives a valid StateReport directive via the event gateway 
How do I properly end the lambda function in case Ill answer asynchronously 
"
38065018,"Is there a service or framework or any way that would allow me to run Node JS for heavy computations letting me choose the number of cores 
Ill be more specific: lets say I want to run some expensive computation for each of my users and I have 20000 users 
So I want to run the expensive computation for each user on a separate thread/core/computer  so I can finish the computation for all users faster 
But I dont want to deal with low level server configuration  all Im looking for is something similar to  but for high performance computing  i e   letting me scale as I please (maybe I want 1000 cores) 
I did simulate this with AWS Lambda by having a master lambda that receives the data for all 20000 users and then calls a computation lambda for each user  Problem is  with AWS Lambda I cant make 20000 requests and wait for their callbacks at the same time (I get a request limit exceeded error) 
With some setup I could user    or   but they only go up to 64 cores  so if I need more than that  Id still have to setup all the machines I need separately and orchestrate the communication between them with something like   handling the different low level setups for master and compute instances (accessing via ssh and etc) 
So is there any service I can just paste my Node JS code  maybe choose the number of cores and run (not having to care about OS  or how many computers there are in my cluster) 
Im looking for something that can take that code:

And run each thread on a separate core so they can run simultaneously (therefore finishing faster) 
"
44822837,"Django  on using a Redis or Memcached cache for high traffic sites  to cut down on the work done by the server 
Apps running on  via  have fantastic horizontal scale-ability  There does not seem to be the need to minimise the processing efforts of a server when another server can be fired up easily and very cheaply 
Are Caches such as Memcached and Redis redundant when using server-less architectures 
UPDATE: having CDN (eg cloudfront) infront of your app is still adviseable (eg ) 
"
57043464,"My goal is to store data received through an SNS subscription in Amazon Redshift  I have successfully managed to store the data using a lambda function  simply through creating a Redshift connection and calling a prepared insert statement  While the lambda does reuse the connection  I use connection pooling to ensure that I dont lose the connection and end up spending 5-10 seconds reconnecting 
This process has worked perfectly well for smaller scale tests  and I dont come close to using all of my lambda concurrency  But  Im afraid that this flow may cause problems when I begin to subscribe to a considerably more active SNS (up to 100 records/sec) 
While I know the aws documentation and many online forums recommend firehose because of its scalability  one of my number one priorities is cost reduction  and firehose seems extremely costly (the price of firehose + cost of intermediate s3 bucket)  Does anyone have any experience with trying to bypass firehose by programmatically storing in Redshift/other databases 
"
67104220,"We are developing an application in which we are using serverless architecture  Here each and every action invokes a lambda function the result of which is logged in to cloudwatch 
Now we have a requirement that the logs need to be available in the application and the data should be able to be filtered using different options along with custom search options 
We are looking for a cost effection AWS solutions 
"
62723924,"Im planning to promote a set of Azure Functions (~15) to production  Today were using for development purposes the Consumption plan but the cold start nature of this plan might impact the overall experience 
Ive been searching for a best cost-benefit plan for deploying the application and found that the Elastic Plan EP1 would fit our needs (e g  no cold start  rapid scale out      share an App Service Plan accross multiple funcion apps      etc) 
The problem is that I didnt find precisely how this Plan would be charged   
In the scenario exposed  would I be charged 388 67 BRL for each of the approx  15 functions deployed to the Plan  Or would the charge be for the Plan itself and the Functions would share the resources of the Plan 
And also  all the Function Apps on the Plan would be pre-warmed 


EDIT:
Even not finding the answers clearly on the official documentation  I created the EP1 Plan and deployed the Functions 

I found that for a given App Service Plan (e g  Elastic Plan EP1)  I can deploy many Function Apps to it  but they share resources of that Plan  increasing the  
I still dont get the answer for the cold start question: for that Plan  if I deploy the 15 Function Apps to it would them be pre-warmed  I found that I can set pre-warmed=1 in every Function App  but still experiencing cold starts 

"
39153410,"I am seeing a steep increase on my AWS account costs  The largest cost items are: EC2: 67% RDS: 12%
I have more than 50 stopped EC2s  One of them has been sitting there in a stopped state from September of the year 2015 
I found the way to get the stopped time of EC2s using variable called:

state_transition_reason

Here how the code looks:

It prints out the following information:

My question is: How can I sort instances (EC2s) by their time being stopped  In my example I would love to see the output in the following order starting from year 2015 accordingly:

Thanks 
"
53609409,"I have a Sagemaker Jupyter notebook instance that I keep leaving online overnight by mistake  unnecessarily costing money    
Is there any way to automatically stop the Sagemaker notebook instance when there is no activity for say  1 hour  Or would I have to make a custom script 
"
63166951,"Can we stop an AWS windows server EC2 instance of a development environment when there is no activity in it  say after 2 hours of inactivity  I am having trouble identifying whether any user is connected to the server virtually 
I can easily start/stop the EC2 at a fixed time  programmatically  but in order to cut the cost of my server  I am trying to stop the EC2 when it is not being used 
My intent(or use case) is: If no user is using the EC2 till a specified amount of time  it will automatically stop  Developers can restart it as and when needed 
"
62167741,"I have a Django webapp (a forum) which have few screens like login  profile  posts  replies  etc  
A regular deployment on dedicated instances (with scalability  performance in mind) seems to be expensive  I have come across serverless deployment of Django apps on AWS Lambda  Here is one such  on AWS  But I couldnt find anything similar on GCP 
Is a similar thing possible using Google cloud functions (GCF) 
In other words  can GCF be used to deploy any of the following:

a web app which can serve dynamic pages
a microservice with multiple rest endpoints

"
55958489,"I am currently building a serverless application based in AWS Lambda that creates CloudFront distributions on behalf of users   Currently  when a user calls my delete operation  my API Lambda function disables the CloudFront Distribution  However  the distributions are never cleaned up and deleted because I need to wait for the disable to complete first  Given Lambdas limit of 15 minutes I cant just wait for the disable to finish deploying  and that would be cost-inefficient even if I could 
I realize I could have a Lambda function periodically poll my CloudFront distributions and clean them up  but Im hoping to do this in an event-driven way so that it occurs as close to real-time as possible and I dont need to use any compute when theres nothing to delete 
I tried setting a CloudWatch Event to trigger on UpdateDistribution calls  but that triggers when the distribution begins to disable rather than when it finishes  so that doesnt really fix the issue where I need to wait for the deploy 
Any suggestions on how to accomplish this  Is it even possible 
"
47066949,"AWS Lambda  NET Core functions have the ability to be defined as async entry point methods 
If Im using await in my functions to wait for IO to respond  am I charged the full amount still   
What is the benefit of writing everything as async await in this scenario vs not using async/await  
"
36298053,"My current Situation:
I currently have a Python script that fetches data via HTTP endpoints and calculates and generates hundreds/thousands of reports daily  Currently it runs on an AWS EC2 instance where a queue is used to split the reports it needs to generate across four threads  Four at a time  the script fetches data  computes each report  and saves it to a PostgreSQL Amazon RDS 
The Problem:
As the project scales  my script wont be able to compute fast enough and wont be able to generate all the reports it needs in a day with the current method 
Looking For a Solution:
I stumbled across Amazon Lambda but I havent found anyone using it for a use case similar to mine  My plan would be to upload/put each report needed to be generated into its own S3 bucket then have the Lambda Function trigger when the bucket is created  The Lambda function would do all the data fetching (from HTTP endpoints) and all the calculations and save it to a row in my PostgreSQL Amazon RDS  In theory  this would make everything parallel and would eliminate the need for a queue waiting for resources to be freed up 
Basically I am looking for a solution to make sure my script is able to run daily and finish each day without over-running into the next day 
My Questions:
Would Amazon Lambda be suitable for something like this  
Would it be costly to do something like this with Amazon Lambda (creating hundreds/thousands of s3 buckets a day)  
Is there better options 
Any help  recommendations  insight  or tips is greatly appreciated  Thanks 
"
61475879,"I want my lambda function to access the database aurora serverless mysql  After some research   I found that we need to keep the lambda under the same VPC as aurora serverless  But keeping lambda in VPC leads to increase the cold start and also in order to access the internet we need to use NAT gateway which leads to additional cost  Since our application is small we cannot afford additional cost  Is there any other way we can access the aurora serverless database without keeping the lambda function in vpc 
"
56413651,"This is my first question so I appologize if its not the best quality 
I have a use case: User creates a monitoring task which sends an http request to a website every X hours  User can have thousands of these tasks and can add/modify and delete them  When a user creates a task  django signals create a Celery periodic task which then is running periodically 
Im searching for a more scalable solution using AWS  Ive read about using Lambda + Cloudwatch Events  
My question is: how do I approach this to let my users create tens of thousands of these tasks in the cheapest / most scalable way 
Thank you for reading my question 
Peter
"
61224097,"I am using AWS and SES to send Emails and Sms through lambda function using NodeJs and I need to make more than 1k or 500 REST API calls  the average call takes 3sec to execute single lambda function request so I need process multiple requests in the single request so that we can save billing because of every single request lambda trigger bill generated 

AWS SQS receive message limit that 1 to 10 message receive

My question is how can we proceed with multiple messages on once AWS lambda function trigger so that we can save billing because every API request one MySQL connection created if I do this for 1k it create 1k mysql connection and it crash MySQL while executing 

"
61112628,"Imagine I need a temporary DynamoDB table (created from the latest BACKUP) to run a performance test and as soon as the test is finished I would DROP/REMOVE that table (and its underlying storage) 
Lets say that test required 1TB of storage and ran for 4 hours  How much would I be charged FOR THE STORAGE 
Would I have to pay for the whole month (720 hours) or for the fraction (4/720) of the time I actually used the STORAGE  
Cheers
"
56672041,"I am writing an Azure Durable Function to process various bulk operations  Te code can get 1000 operations in a file and its breaking those down to call the same activity function 1000 times 
The problem is that this can flood an API that the activity function uses up to the point that our activity function gets a 429 - Too Many Requests from the API  We are thinking of reading the Retry-After header offered and putting the thread to sleep for that period of time  
In this case  were wondering if Azure will bill us for the seconds were waiting for  Also  would this time count towards the timeout for the Azure function 
"
69182279,"I have developed multiple microServices in my previous projects  So am well versed on it  Currently we are on the edge to start developing a SaaS webApp using java or springboot &amp; we want to leverage AWS lambda for pricing sake but couple things I couldnt understand and couldnt find good example are:

Is it feasible to develop web app fully on AWS lambda using JAVA or springboot (I
know we can write java function on lambda) 
How do we tackle code reusability on AWS Lambda 
If we end up having 100 lambda functions  does it mean we need to build
100 jars for each function 
Does each end point need to be represent by single lambda function 

I would really appreciate it if you can attache a link for similar scenario   
"
61734414,"I am looking for a solution where the aws api gateway can add few extra headers before forwarding to the actual backend  I can imagine that keeping lambda function as a call back function can be one way to execute it  My calls can be slow  which means  if i use lambda functions in between  i pay a lot 
Is there any other way to do it  
I am looking for something similar to a pre-processor in Tibco Mashery  Which means  when the request comes  this method/logic is executed by api gateway  which will add the extra headers  and api gateway will forward the request to the actual backend 
Edit:
I need to fill the header dynamically based on the incoming request and some mapping tables in db 
Thanks
"
65458856,"Many AWS reference architectures for serverless real-time analytics  suggest pushing processed data from Lambda to S3 through Kinesis Firehose 
e g 

Why can’t we push data from Lambda to S3 directly  Isnt it better to avoid complexity and additional cost by skipping the mediator Kinesis Firehose component  Is there any problem with writing real-time data by Lambda directly to S3 
"
53726405,"I have a DynamoDB table which contains columns names A and B (both numeric)  I would like to find all rows which satisfy A-B &lt; 0  What would be the fastest way to do this assuming that we may have as many as 100000 rows that need to be scanned  
I would be using a Lambda function so the idea is to have least possible memory and CPU cost 
"
60714724,"I cant distinguish between privite subnet and public subnet 
I created a vpc and connected the subnet  and igw was also connected to the route tables  So  isnt the network a public subnet 
As I expected  the public network seems to have to communicate with the outside  but there is no communication at all 
Connection from aws lambda to RDS is possible (vpc)  but timeout occurs for both uploading files to s3 and sending messages to slack 
I have seen a lot of posts about using vpc endpoints  but when I try to set it up

So isnt ec2 currently disconnected from s3  Then  there is a problem with the service and it cannot be set 
In the lambda vpc configuration  even if all inbounds of the security group are opened  the connection is not established 
Is there only a way to set up NAT  
NAT wants to avoid it because of its cost 
my goal is to communicate with rds  s3  slack in lambda on vpc 
"
35878619,"We are trying to develop a true lambda-based application in which certain tasks need to be performed at schedules of variable frequencies  They are actually polling for data  and at certain times of the day  this polling can be as slow as once every hour  while at other times  it has to be once every second  I have looked at the options for scheduling (e g   and )  but it seems that short of spinning up an EC2 instance or a long-running lambda  theres no built-in way of firing up lambdas at a frequency of less than one minute  The lambda rate expression doesnt have a place for seconds  Is there a way to do this without an EC2 instance or long-running lambda  Ideally  something that can be done without incurring additional cost for scheduling 
"
56991822,"Im trying to understand the various steps and requirements I need to go through in order to make our website available from China  both on the regulation side (Great Firewall) but also on the technical side (technical limitations and changes to perform) for 
Right now  it doesnt seem to be allowed: 

I dont need nor want to own a  ch website  I just want to make my website available for Chinese at   Also  the website is currently hosted on AWS Lambda (using the Serverless framework)  and only deployed in the eu-west-1 region (Ireland) only 
The website doesnt sell anything online: Its an information website  not e-commerce 

Ive looked into this issue for a few hours  but Im a bit lost regarding the exact steps needed to make it happen 
Here are a few questions I havent found answers for:

Does deploying the lambda to  (China Beijing) is a requirement or can Chinese users access my  lambda if I get an ICP license 

Regardless of the deploying region  I seem to need an ICP License  as the AWS FAQ says at
:

Q: Do I need to file for ICP Recordal or ICP License if I want to host public content on AWS China (Beijing) Region or AWS China (Ningxia) Region 
Yes  In accordance with Chinese laws and regulations  if you use either AWS China Region to host a website providing non-commercial internet information services  you must undertake filing procedures for a non-commercial website (“ICP Recordal”) through the relevant government authority  If you use either AWS China Region to host a website providing commercial internet information services  you must obtain a value-added telecommunications license for a commercial website (“ICP License”) from the relevant government authority  You may be required to produce your ICP Recordal or ICP License  as applicable  before you host public content using one of the AWS China Regions 
AWS China (Beijing) Region is operated by Sinnet  who is responsible for content hosted in the Beijing Region  while AWS China (Ningxia) Region is operated by NWCD  who is responsible for content hosted in the Ningxia Region  Both Sinnet and NWCD provide support at no additional charge for customers seeking ICP related services  though customers are responsible for any fees imposed by the applicable government authorities  To learn more about the filing procedures  please visit Sinnet at  and NWCD at  

As for actually getting the license  its a bit out of topic here  but I couldnt understand the first provider workflow:

 website is a mix of english and chinese and I got lost in translation (even when using their english website version)
 seems to require to send an email to support@amazonaws com cn  no idea what happens next

Anyway  the process seems to take around 4-6 weeks  So  it likely takes even more time than that 

Regarding the technical details now  it seems like the China region ( Beijing and  Ningxia) behave in a very particular way on AWS Lambda 

They only support  endpoints
They do not support native Serverless  variables

See




Also  there are technical impacts on the website itself:

Google services are banned  or limited (Google Analytics (limited)  Google Tag Manager  Google Fonts (banned)) and must be changed  converted to owned CDN  etc 

And Ive probably missed other technical limitations  since thats just those I learned about within 2h of digging around 
Are there other steps I overlooked  (regulation or technical)
Do you have any advices or feedback about how to make a website hosted on AWS Lambda available in China 
"
39769031,"Simple as that  I am using AWS SDK in Node to make a Lambda procedure that is in charge of sending emails according to data it receives 
I would like to delay that email  delivering in a date and time received  not in the specific moment that the function was called  The Date and Time to deliver are parameters received by the function  Any thoughts  I couldnt find much searching on the web 
Thanks in advance 
"
60457162,"With each lambda invoke either with AWS API or API Gateway HTTP  kms usage is increasing while I havent added any key management with KMS  Is this indirect cost by aws on lambda usage or there is option to disable kms on lambda invoke 
"
48418581,"Ive been messing around with serverless and postgresql  It seems that connection pooling is possible  but when I declared a connection pool to my postgresql instance outside:

Not calling  at the end of request handlers seem to cause  to not terminate when I call it 
If I call  lambda-local does terminate  but I wonder if this means that the function will stop working 
If I dont call pool end()  will the function run forever on AWS  costing me a lot of money 
"
62826010,"Been doing a ton of research  I am a mere padawan  however  I have a project where I must run a users untrusted Python3 code from a website 
I also apologize in advance if this question has some moving parts 

I am looking for an as safe as possible approach  This doesnt need to be 100% perfect unless there is a big risk of leaking extremely sensitive data 

Main questions:

Does my AWS-lambda plan run an extreme risk for leaking sensitive data 
Are there any other simple precautions that I should take which could make this work safer in AWS-lambda 
Are there ways for exec() to break out of the AWS-lambda container and make any other network connections if all I have connected to it is the single AWS-api-gateway for the REST call 
Do I even need to limit  and locals  or are AWS-lambda containers safe enough 

BackGround
It seems most companies use Kubernetes and Docker containers to execute untrusted python code (such a Leetcode  Programiz  or hackerRank) 
See these helpful links:




My Plan
I am thinking that I can POST my arbitrary Python code to an AWS Lambda Function as a microservice  using their containerization/scaling rather than build my own  In the Lambda container  I can just run the code through a simple exec or eval function  perhaps with some limitation like this:


Special Note:

I am not too concerned about infinite loops or crashing things  because I will just timeout and tell the user to try again 
All I need to do is run pretty simple python code (generally less than a few lines) and return exceptions  stdout  prints  and run a check on the result  Need to run:

Math operators  lists  loops  lambda functions  maps  filters  declare methods  declare classes with properties  print 


This doesnt need to be a perfect project for hundreds of thousands of users  I just want to have a live site for a resume booster and maybe make a little money on ads to help with costs 
If there are severe limitations  I can eventually implement it in Kubernetes (as in the above link)  but hopefully  this solution will work well enough 
I just want this to work relatively well and not take too long to build or cost too much money 
I do not want to leak any sensitive information 

Security things I am already planning on doing:

AWS lambda: Limit the time out to around 1-2 seconds
AWS lambda: Limit the memory usage to 128mb
My Own Code: Use regex to make sure no one is passing in double underscores badstuff
Keeping this microservice as minimal as possible (only connecting a single AWS-API-gateway) 

Other notes:

I dont think I can use restrictedPython or PyPys sandbox feature in AWS Lambda because I dont have access to those dependencies OOB  Im hoping that those are not necessary for this use case 
If its impossible to do this with exec()  are there safe python interpreters on GitHub or someplace that I can literally copy-paste into files in AWS-lambda and just call them 
I am planning on allowing the user to print from exec with something like this:



Please let me know if you have any questions or suggestions 
___ Edit ** adding architecture diagram ___

"
43876653,"Some of my data is in Mongo replicas that are hosted in docker containers running in kubernetes cluster  I need to access this data from the AWS lambda that is running in the same VPC and subnet (as the kubernetes minions with mongo db)  lambda as well as the kubernetes minions (hosting mongo containers) are run under the same security group  I am trying to connect using url mongodb://mongo-rs-1-svc mongo-rs-2-svc mongo-rs-3-svc/res replicaSet=mongo_rs where mongo-rs-x-svc are three kubernetes services that enables access to the appropriate replicas  When I try to connect using this url  it fails to resolve the mongo replica url (e g  mongo-rs-2-svc)  Same URL works fine for my web service that is running in its own docker container in the same kubernetes cluster 
Here is the error I get from mongo client that I use   
{\name\:\MongoError\ \message\:\failed to connect to server [mongo-rs-1-svc:27017] on first connect [MongoError: getaddrinfo ENOTFOUND mongo-rs-1-svc mongo-rs-1-svc:27017]\}  I tried replacing mongo-rs-x-svc to their internal ip addresses in the url  In this case the above name resolution error disappeared but got another error - {\name\:\MongoError\ \message\:\failed to connect to server [10 0 170 237:27017] on first connect [MongoError: connection 5 to 10 0 170 237:27017 timed out]\}
What should I be doing to enable this access successfully 
I understand that I can use the webservice to access this data as intermediary but since my lambda is in VPC  I have to deploy NAT gateways and that would increase the cost  Is there a way to access the webservice using the internal endpoint instead of public url  May be that is another way to get data 
If any of you have a solution for this scenario  please share  I went through many threads that showed up as similar questions or in search results but neither had a solution for this case 
"
57940850,"I have a small amount of data (~2kb string) I need to save and retrieve from a lambda function  Whats the best way to do this 
I only need to write these values a couple of times a day but I need to retrieve them each time my Lambda function is called so it will be a lot of reads with just a couple writes 
I know my solutions are DynamoDB  S3 or ElasticCache  I also have seen SSM Parameter Store but Im not clear if its possible to write values or if this is a server just to read values 
I was hoping someone could advise on the best and most cost-effective approach for this in a Lambda Function 
"
53931410,"We are using AWS serverless architecture for our Contact center  We are storing audio recordings on S3 bucket and using lambda functions to process them 
Our requirement is to remove sensitive details from audio recording such as Payment information 
 So we need to fetch audio recording from S3 bucket and slice that using start time and duration for sensitive payment details and then join remaining recording clips into one 
How can we achieve this by using AWS lambda(NodeJS/Python)  S3 
Thanks 
 Ganesh
"
62721295,"I am trying to build a secure teaching platform in AWS  I am planning to host my videos on vooplayer (now spotlightr) and just have the front end web page with authentication  few pages to display the course videos  I am thinking I can host the website on S3  use Cognito for authentication and authorization and store user data and course data i e  video urls in DynamoDB and may be few Lambda functions and API Gateway 
Am I going in the right direction in choosing this serverless architecture for the use case 
I am just going to store few collection in DynamoDB

User - email  name
Course - course id  course name  external (vooplayer/spotlightr) video url  cost
Purchase - email  course  date of purchase  amount paid  currency
Activity - email  course id  started at  valid till

I estimate there will be 100 users in next 6 months  may be more if things goes well 
I hope storing this data shouldnt cost much in the long run 
I chose vooplayer/spotlightr for their encryption and making it really difficult for malicious users to download and play the videos unlike other popular video streaming platforms we know 
I hope streaming video from external hosting sites with front end hosted on AWS wont get charged  Please correct me and point me in the right direction otherwise 
I know I could use off-the-shelf products like Udemy  Teachable  etc  I am between jobs and want to build something and learn something new while building it  Please advise 
"
61939294,"Current AWS configuration which is serving 3 webapps -

Here ELB is taking care of SSL offloading  Currently the Node JS application is deployed on a EC2 machine  It is taking care of handling the backend APIs as well as serving the static files for the 3 SPA react webapps 
We are looking to improve on this by separating out the frontend and backend  We are thinking of moving the 3 SPA react webapps into a single S3 bucket  Each will sit in its own directory on this S3 bucket  The S3 bucket will be configured for static website hosting  We will still have the node JS instance for service backend APIs 

We are looking to avoid using cloud front to route traffic from ELB to S3 since these are internal webapps with limited number of users from a particular region  

Can we use lambda function to route traffic from ELB to Node JS app on EC2 as well as from ELB to the S3 bucket  If possible is it a good practice performance wise and cost wise to take this approach 

Also the lambda function has to route the traffic based on rules -

/api/* --&gt; route traffic to node js app
/ui/site1/* --&gt; route traffic to S3 bucket site1 directory
/ui/site2/* --&gt; route traffic to S3 bucket site2 directory
/ui/site3/* --&gt; route traffic to S3 bucket site3 directory

Can we write such rules in lambda function 


"
61292542,"Im dealing with the CloudFormation limitation of 200 resources per stack  It seems the solution is to split my service (serverless yml file) into multiple files  I have tried automated approaches and   So  Im looking into manual ones  But I dont know how 
This is a sample file that I have:

Can someone please help me split this file into 2 or 3  Feel free to split it in any way you like (as long as the resulting files have fewer resources individually)  Its just that the JS code should remain untouched  Also  please pay close attention to the  plugin  That is a crucial part of my service  Of course  the intention is that the deployment of multiple files should be identical to deploying this single file 
"
68998621,"I have a vue js/aws-nodejs/mongodb-atlas website 
To lock things down better  Im switching the mongodb-atlas database to VPC peering with lambda   That works just fine   But the other aws services now are giving me problems   They tend to just hang and never return 
I understand that I should use vpc endpoints specific to the aws services to make them work  but they are not consistently working or do not exist   Heres what I have:

lambda -&gt; aws secret manager using secretmanager endpoint: works fine
lambda -&gt; invoking other lamdas using lambda endpoint: works fine
lambda -&gt; s3 does not work with interface endpoint  but does work with gateway endpoint 
lambda -&gt; aws ses using smtp-email endpoint: hangs
lambda -&gt; aws cognito admin functions (such as adminCreateUser)  cannot find a cognito endpoint type:  hangs

I have created a separate  non-vpc lambda that calls the SES api   My vpc lambda invokes this non-vpc lambda with parameters to send email 
This does work  but seems kludgey    My old non-vpc code worked fine    Before calling ses or doing anything dangerous  I checked custom permissions in my database   But this new non-vpc lambda does not have access to the database and therefore is missing this check close to the api call   This non-vpc lambda feels like potential weapon of mass destruction 
Apparently  I could use a NAT gateway  But a NAT gateway is expensive  especially if I want redundancy   And using the public internet defeats the purpose of using a vpc in the first place 

Why is the smtp-email endpoint not working while secretmanager and lambda endpoints do work 
How can I call cognito admin functions from a vpc-based lambda if there is no cognito endpoint type 
If there is no available endpoint type for a specific aws service (such as cognito)  does that mean a NAT gateway is required 
Are lambda functions without an apig interface safe from being invoked by hackers over the internet 
Is using a non-vpc lambda to access aws services from a vpc lambda actually a good idea 
Should I just use a NAT gateway 

"
61091659,"Ive been reading some articles regarding this topic and have preliminary thoughts as what I should do with it  but still want to see if anyone can share comments if you have more experience with running machine learning on AWS  I was doing a project for a professor at school  and we decided to use AWS  I need to find a cost-effective and efficient way to deploy a forecasting model on it  
What we want to achieve is:

read the data from S3 bucket monthly (there will be new data coming in every month)  
run a few python files ( py) for custom-built packages and install dependencies (including the files  no more than 30kb)  
produce predicted results into a file back in S3 (JSON or CSV works)  or push to other endpoints (most likely to be some BI tools - tableau etc ) - but really this step can be flexible (not web for sure) 

First thought I have is AWS sagemaker  However  well be using fb prophet model to predict the results  and we built a customized package to use in the model  therefore  I dont think the notebook instance is gonna help us  (Please correct me if Im wrong) My understanding is that sagemaker is a environment to build and train the model  but we already built and trained the model  Plus  we wont be using AWS pre-built models anyways 
Another thing is if we want to use custom-built package  we will need to create container image  and Ive never done that before  not sure about the efforts to do that 
2nd option is to create multiple lambda functions

one that triggers to run the python scripts from S3 bucket (2-3  py files) every time a new file is imported into S3 bucket  which will happen monthly 
one that trigger after the python scripts are done running and produce results and save into S3 bucket 

3rd option will combine both options:
 - Use lambda function to trigger the implementation on the python scripts in S3 bucket when the new file comes in 
 - Push the result using sagemaker endpoint  which means we host the model on sagemaker and deploy from there 
I am still not entirely sure how to put pre-built model and python scripts onto sagemaker instance and host from there 
Im hoping whoever has more experience with AWS service can help give me some guidance  in terms of more cost-effective and efficient way to run model 
Thank you   
"
61499572,"I am trying to pass in AWS Services in a CostExplorer boto3 method but cannot get the names right  AWS seems to call their services by different names when it comes to passing them in as variables in boto methods  Is there a list of what their services are called when you need to pass them in as Boto variables  For example  to get a response from EC2 I need to write Amazon Elastic Compute Cloud - Compute  but for Lambda  I need to write AWS Lambda  There seems to be no pattern 
For example  I get a response for all the services below except Amazon CodeBuild and AWS Code Pipeline - Service  It has been trial and error so far trying to get the names right  and have only found a few random examples in the docs 

"
59299996,"AWS  HTTP API support for Amazon API Gateway  There are some very impressive pricing and performance numbers coming in with this new release  Off the top  AWS says that the general cost of using v2 will be 70% cheaper and have 50% lower latency than v1  Id love to try this out in my existing projects 
I use Serverless framework in my application  How do I convert my existing API to use this new feature  This is what my  file looks like:

"
67017488,"i would like to implement a lambda in aws which receives as input pixel coordinates (x/y)  retrieve that pixels RGB from one image  and then do something with it 
the catch now is that the image is very large: 21600x10800 pixels (a 684MB tif file) 
Many of the images pixels will likely never be accessed (its a world map so it includes e g  oceans  for which no lambda calls will happen  But i dont know which pixels will be needed )
The result of the lambda will be persisted so that the image operation is only done once per pixel 
My main concern is that i would like to avoid large unnecessary processing time and costs  I expect multiple calls per second of the lambda  The naive way would be to throw the image into an s3 bucket  then read it in the lambda to get one pixel - but i would think that then each lambda invoke would become very heavy  I could do some custom solution such as storing the rows separately but was wondering if there is some set of technologies that handles it more elegant 
Right now i am using Node js 14 x but thats not a strong requirement 
the image is in tif format but i could convert it to another image format beforehand if needed  (just not to the answer of the lambda as that is even bigger)
How can i efficiently design this lambda 
"
55740175,"What is the simplest and most cost effective way to trigger/run an AWS Lambda job whenever a file is put in the AWS S3 Bucket (in a certain path; Even though I know its all object in S3 and not like a File System  but still folder system exists for users ease) 
"
63946207,"Hi Im looking for a way to store user session/metadata with the least amount of latency and that will not cost me an arm and a leg 
Brief problem description 
I have a bot that helps users download files from Google Drive 
It uses a Webhook of an AWS lambda function 
Users are provided with clickable filenames  e g 
/File pdf
Once they click on it  it needs to be downloaded and sent to the user 
The problem is I need a way of knowing what file the user chose without having to use a database or iterating through all my files by name 
E g  Is there a way of adding metadata to the clickable message  Such that I can add that metadata to the clickable and if a user clicks /File pdf  Ill be able to extract the metadata 
"
55226441,"I am developing a React Native application for IOS and Android  I am using Django for my backend and aws rds for my database  It is deployed on AWS Lambda and both my lambdas and my rds are in a VPC  Everything worked well except for push notifications as they require my lambda functions to communicate to the public internet 
One way would be to create a NAT Gateway to allow that communication  but a NAT Gateway is quite costly 
I am thinking of another way which involves AWS Simple Notification Services (SNS)  If I integrate that to my Django app  would the lambda functions be able to communicate with AWS SNS without requiring a NAT Gateway 
"
45726185,"Im a junior Laravel PHP Developer with a couple of years of industry experience  I am a great lover to learn new things  Nowadays Im after the Serverless :-)  We were taught a lot of benefits of the OOP over procedural programming (where the procedural programming was presented as a villain)

Can someone please help me to understand about this Serverless   
If it is another player to kill the OOP after the Event Driven 
If not  then how we can go with the OOP and Serverless together 
OR Event Driven Procedural is better than OOP 

As I think first the Event Driven (and now the Serverless) was encouraging the developers to move towards the Procedural Programming  but that wasnt the case for the PHP as a backend language but only with the JS with Node 
But now it seems the serverless is another actor came into existing to kill the OOP and encourage the procedural programming to fool the people on the name of Low Cost and pushing the developers back to the 80s 
If someone  having knowledge of OOP/Procedural Programming  can help me to understand the Serverless thing as my concern is that well have to leave the OOP and which would be a great issue of the maintenance 
"
62298207,"I am working on a requirement  where i am doing multipart upload of the csv file from on prem server to S3 Bucket 
To achieve this using AWS Lambda I create a presigned url and use this url i am uploading the csv file  Now  once i have the file in AWS S3  i want it to be moved to AWS RDS Oracle DB  Initially i was planning to use AWS Lambda for this  
So once i have the file in S3  it triggers lambda(s3 event) and lambda will push this file to RDS  But with this the issue is with the file Size(600 MB) 
I am looking for some other way  where whenever there is a file uploaded to S3  it should trigger any AWS service and that service will push this csv file to RDS  I have gone through AWS DMS/Data Pipeline  but not able to find any way to automate this migration
I need to automate this migration on every s3 upload  that is also cost effective 
"
49070843,"As a quick resume i need to build a product feed that ll be constantly updating based on the people searches on site  Important things to have in mind:

Prices for the same ID change so i need to always keep the lowest (for a given month)
Every day this feed would be uploaded to different marketing providers for custom ads generation 

With all of this in mind i go straight for explaining the possible Architecture i thought (im open and encourage to new ones):
In both i ll be getting the product information making people on site make a request to API gateway with the param of the product and thought proxy implementation to Lambda where i have all the data parsed  After that i can:

Store by day on S3 and run a daily EC2 that retrieves all registers from the day before and cross the to a query on a redshift cluster  After all rows that need to be updated are detected update the redshift table 
Use elasticache and in realtime evaluate if the row (by id) needs to be updated (and update it) directly from lambda  

My biggest concern is being cost efficient  Thoughts  Any other variable i should consider  Any other solution i should look into    
"
62227576,"Working on product which is served as PaaS  backend of product is completely developed for serverless using NodeJS Serverless Framework and deployed on AWS Lambda 
When I started working on it  I found there are lots of duplicate code  LambdaFunctionOne and LambdaFunctionTwo both have same function performing same operation  and this is the problem if we have to change the logic of function then we will have to change the function in all lambda function 
Wanted to remove the duplicated  so if LambdaFunctionTwo required the some function which is LambdaFunctionOne then instead of replicating  should invoke LambdaFunctionOne and call its function  Suppose created a lambda function for utils and used that utils in every function of Lambda by invoking lambda instead of replicating 

How does it will affect the pricing 
Is it good practice to call the lambda from another lambda in terms of cost 
Is it good practice to develop such product in serverless 

"
65933141,"I hope to evaluate AWS Lambdas suitability for long running computing intensive batch jobs  vs EC2 instances  To do that  I need to find out a 24h cost of Lambda vs EC2 for similar computing power  (In the 24h Ill run many small jobs  each a few seconds)
From  I can see At 1 769 MB  a function has the equivalent of one vCPU (one vCPU-second of credits per second)  But there is no description of how powerful this CPU will be 
For EC2 nodes  I can find out the CPU specs of T2 or C5 so I know what to expect  but not the case for Lambda  Anyone has an idea  Thanks 
"
46375132,"I want to create Amazon DirectConnect connection as VPN to transfer data from my company network to RDS instance  The connection is not cheap and I certainly dont need it open the whole time  Probably just 10 minutes every day is enough  Is there a way to schedule connect/disconnect event of the VPN connection using Lambda function just like starting/stopping EC2 or RDS instance like below using Pythons Boto3 library:

Although Boto3 supports   it doesnt seem to have any methods that switch the connection on and off  Is there a way to control the connection 
"
60565652,"Im developing an ecommerce website 
Its for a ground-based clothing store that is used to sells only via third party platform 
 And now want a own website 
I started with Wordpress+Woocommerce 
Then i tried a ZeitNow+Next+Graphql+React version 
It connects itself to Wordpress+Woocomerce database via GraphQL Queries 
It uses ZeitNow to avoid implementing a real Node+Express server on my machine 
Which path to choose to complete the website and publish it   My doubts are related mainly to COSTS 

If i choose the classic WP+Woocommerce way i need :
0-20 EUR /year for Domain Name 
120EUR / year approximately for a classic web server (with PHP+MySQL) hosting plan where to place the Wordpress+Woocommerce 

If id like to choose second option  based on what i know actually i need :
0-20 EUR /year for Domain Name 
120EUR / year approximately for a classic web server (with PHP+MySQL) hosting plan where to place the Wordpress+Woocommerce head part of my project   
0EUR /year for serveless ZeitNow (free plan) 

But where i need to place the App (ZeitNow+Next+GraphQl+React) 
An other Web server (with Node)  
So an other 120EUR/ year plan  
Or beacuse its serverless i can only deploy to zeitNow and only link my domain to ZeitNow 
Its not clear to me 
I found on the web things like Netifly  Firebase  Heroku  AWS     
 Are they all equivalent to Zeit Now 

I would like to publish a website with benefits of WooCommerce CMS system 
Like adding products  managing stocks  handling discounts plans  access to PayPal and Stripe payment methods integrations (i dont trust my self enough to build integration on my own due to security risks) 
I wolud like also the keep benefits of using React for front End like performance (at least perceived) for Final User  or no need of Ajax request to update Cart and Wishlist 
And what about calculating if my project needs a payed plan of ZeitNow/Netifly/AWS to manage the request  How i can calculate them 
Sorry for the high number of question  but for me  understand the co-existence of these things is overwhelming 
Thanks 
"
63054799,"Looking for a way to delay a message in a being sent to a lambda by 5 seconds 
So  message 1 received by lambda then 5 seconds later message 2  then 5 seconds later message 3  etc  for say a thousand messages 
Was looking at SQS delay queue and message timers but theyre not exactly what Im looking for 
Step Functions using wait  but that would be expensive at the scale I need 
Ideally need an SQS queue that restricts messages to only being sent every 5 seconds  is there any way to do this 
p s  not fussed about it being SQS  just need a solution
"
55237861,"I’ve looked at the tutorials but I don’t understand  I have a function that processes stripe payments  I think it has something to do with packages json but I can’t find information about where to put it or how to run it  
This is the code:

With the important line simply being:

The error I get is:

How do I set about including this  Do I have to put a packages json file in the same folder as my function  I tried that and it didn’t make any difference  
"
40724369,"We are using SQS queues for asynchronous messages and need Lambda functions to do some transformations and logging of the messages on certain queues 
After a lot of research I have decided I will go for a recursive Lambda function as the messages are not really critical and going through using SNS or SWF in between seems overly complicated (and Im hoping Amazon soon will add a Lambda trigger for SQS) 
The maximum execution duration per request for a Lambda function is supposed to be 300 seconds (5 minutes) so I figured to invoke the Lambda over-and-over and then have a Cloudwatch trigger set to 5 minutes to re-trigger the Lambda for another 5 minute run 
However the Lambda just keep running (without the Cloudwatch trigger)  I tested it yesterday and was surprised when it kept going past the 300 seconds and now it has been running for over 24 hours   
So  question is  how come it keeps running 
I assume that each time I invoke it Lambda considers it a new request  As the SQS long-poll time-out is 20 seconds and I invoke also after time-out (in case of no new message) it keeps on going as new requests  right 
Also  if I add the Cloudwatch trigger at 5 minutes interval  will I then start multiple instances of the same Lambda function 
(And yes  I am aware I am being billed for the run time but it is still cheaper than an EC2 instance even running 24/7)
EDIT:
Adding Cloudwatch logs that shows the invokation and recursive running:

15:48:22
  START RequestId: ee3f71df-b001-11e6-a0d6-bffc6057d58c Version: $LATEST
15:48:42
  2016-11-21T15:48:42 188Z    ee3f71df-b001-11e6-a0d6-bffc6057d58c    Calling again    and again   
15:48:42
  END RequestId: ee3f71df-b001-11e6-a0d6-bffc6057d58c
15:48:42
  REPORT RequestId: ee3f71df-b001-11e6-a0d6-bffc6057d58c  Duration: 20115 93 ms   Billed Duration: 20200 ms Memory Size: 128 MB   Max Memory Used: 37 MB
15:48:42
  START RequestId: fa443a44-b001-11e6-bea9-4fe2d7bd8fe7 Version: $LATEST
15:49:02
  2016-11-21T15:49:02 386Z    fa443a44-b001-11e6-bea9-4fe2d7bd8fe7    Calling again    and again   
15:49:02
  END RequestId: fa443a44-b001-11e6-bea9-4fe2d7bd8fe7
15:49:02
  REPORT RequestId: fa443a44-b001-11e6-bea9-4fe2d7bd8fe7  Duration: 20156 93 ms   Billed Duration: 20200 ms Memory Size: 128 MB   Max Memory Used: 37 MB
15:49:02
  START RequestId: 0647caad-b002-11e6-adc9-73ebc92281fd Version: $LATEST
15:49:22
  2016-11-21T15:49:22 601Z    0647caad-b002-11e6-adc9-73ebc92281fd    Calling again    and again   
15:49:22
  END RequestId: 0647caad-b002-11e6-adc9-73ebc92281fd
15:49:22
  REPORT RequestId: 0647caad-b002-11e6-adc9-73ebc92281fd  Duration: 20179 49 ms   Billed Duration: 20200 ms Memory Size: 128 MB   Max Memory Used: 37 MB

"
66194572,"I am struggling to understand a basic aspect of Lambda implementation 
Problem: how to use a lambda both inside and outside of an API context 
I have a lambda (nodejs) with an API gateway in front of it:

The handler is used to read (GET) or write (POST) into a a DynamoDB table and returns accordingly  If no method is passed it assumes GET 

Is there an easy way to refactor this code to support both scenarios  For example a step function could call this lambda as well  I know I can have the step function invoking an API but I think this is overkill as step functions support invoking lambdas directly 
I see 2 ways I can go about this:

The lambda has to be aware of whether it is being invoked within an API context or not  It needs to check if theres a http method  queryStringParameters and build its input from these  Then it needs to return a response accordingly as well  A stringified JSON with statusCode or something else  including throwing an Error if outside an API call 

The lambda assumes it is being called from an API  Then the step function needs to format the input to simulate the API call  The problem is that the response will be a string which makes it difficult to process inside a step function  For example assigning it to a ResultPath or trying to decide if there was an error or not inside a choice 


Additionally I could have the step function calling an API directly or the last resort would be to have 2 separate lambdas where the API lambda calls the other one but this will incur additional costs 
Thoughts  Thanks 
"
43034788,"I hope to build a mobile app that sends credit card information to an aws-lambda microservice  which then submits that information to stripe  Im concerned about PCI compliance/security  and Im wondering if there is something Im missing  The following is my plan:
1) Users sign in using PCI compliant passwords - and are assigned unique ids and get cognito access keys 
2) Users enter payment information in the mobile app  The app then sends that credit card data via POST request using HTTPS to a cognito authenticated aws-lambda instance (api gateway is used to create endpoints)  
3) Upon a successful post request the app deletes the local credit card data 
4) The lambda instance decrypts encrypted stripe secret access keys using KMS 
5) The lambda instance uses Stripe NodeJS sdk to send the data to stripe and stores stripe tokens in databases  
6) At no point does the Lambda instance save ANY credit card data - it ONLY writes Stripe tokens to the database 
Is there anything Im missing here  Is there something I should be concerned about 
EDIT:
Additional Info:
Credit card details are collected within the app and stored in the app state until they are deleted  The https POST does not use Stripe tools because Im using React Native  
"
40989800,"As per current implementation by AWS  the response payload size returned by a Lambda function cannot exceed   Is there a provision for increasing this limit to  by requesting a Service Limit Increase  Also  what are the additional charges  if any that would be charged 
Thanks in advance   
"
61914929,"Im well aware of the lambda function deployment package size limit is 50 MB(in case of compressed  zip/ jar) with a direct upload and 250 MB limit (uncompressed) via upload from S3 
What Im not clear is how lambda deploys the package from S3 

Is it on the each invocation of the lambda function 
Will there be any cost associated data transfer between S3 to lambda function 

"
63139851,"Im pretty excited about HTTP Gateways due to the drastically reduced pricing in comparison to REST Gateways  but Im stuck on creating routes that do not completely blow up my  file 
The documentation for  describes this to define routes:

There is a support for   but this causes issues with  cause those will overwrite the created CORS policies (so OPTIONS requests would actually get to the application  which does not make any sense  especially if the route is protected via an authorizer) 
Also  its not possible to define multiple methods 

The only configuration I found is to define all routes separately:

This works fine &amp; the UI is even bundling the routes cause theyre on the same prefixed path:

But with this I have to define all HTTP methods for all my main resources separately including the attached authorizer 
Is there some way to combine this 
"
61620005,"I am trying to pull budget codes out of tags on aws resources I have the following code: 

When the code runs it keep coming back as with one tag coming back as invalid 070-0702-1-000000-5309-7000-0000   I then go and run it locally with just this code for testing and it seems to come back find and it returns it as a valid number   Is there something I am missing why my lambda code is giving me different results  

"
61590633,"TLDR; reading with my AWS lambda    files that are stored on S3 
On my local machine I just use  to read both doc and docx files  
So the intuitive way to do the same on lambda is to download the file from s3 to the local storage () on the lambda and then process the  files like I do on my local machine 
Thats not cost-effective   
Is there a way to make a pipeline from the S3 object straight into some parser like  thatll just convert the / files into a readable object like  
My code so far for reading files like txt 

"
42375009,"My app is offline-first  and therefore Realm has been wonderful for persisting and accessing data  I love it  However  I also want to store the user data in the cloud (for backup but also in case I add web support later)  I know thats exactly what Realm Object Server is for  but I think Id prefer to use DynamoDB for the following reasons:
1) Ive already invested in DynamoDB and Amazons authentication (Cognito) 
2) I like that Realm is effectively a relational database because from the client I do need to run complex queries  However  on the backend I mostly just want to backup all the data in a way that I can easily access it and manipulate if needed through Lambda functions)  Im totally fine with a NoSQL solution for this  and my understanding is that DynamoDB is a cost effective database with horizontal scaling  which is appealing to me  If I wanted to access the data in this way with Realm Object Server  my understanding is it would cost at least 1 500 a month 
3) No offense to the Realm team  but I got screwed by Parse shutting down and so Id like to use something that I can trust will be around for 5+ years as my backend 
Anyway  with that out of the way  heres how Im currently making this work:
1) Whenever I create or edit a Realm object  I have logic that will map that change into my DynamoDB schema (which is made up of far fewer tables than Realm) 
2) I call these updates  and I queue them up and merge them as needed (if you  for instance  changed the same property more than once) 
3) I go through the queue and pass chunks of  to a Lambda function I wrote that will iterate through the updates and perform the necessary put or update commands to DynamoDB 
4) I have retry logic in place in case youre offline or a request fails
5) Assuming everything is synced properly if you got a new phone and signed in  I have a separate Lambda function that will fetch all of the users data and populate the Realm file just as it was before 
Like I said  all of this is working right now  but it feels fragile  and I cant help but feel like Im going about this the wrong way  Plus it doesnt support two-way syncing or real-time communication if I wanted to add some social features
So my question is if this is a reasonable approach to making Realm sync with DynamoDB or if theres a better/more robust way  Also if I should reconsider using Realm Object Server or something else instead of DynamoDB  Id be interested to hear why 
It is a big decision for me  so Id appreciate all the help I can get  Thanks
"
44043162,"I have my Postgres DB with daily increasing data(approx 500 rows added per day) in following format 

Every End of Day  I can write these data to AWS S3 as CSV file
Each CSV file contains data in above format for that day 
10May csv  11May csv
12May csv and so on 
These files will be hardly 25 KB each 
I want to store the above data in AWS and allow client to directly get filtered N number of rows
For example: client can request for data between 10May 11 A M  to 11May 3 P M
Basically I need to mimic this query on multiple CSV files: 

Relevant things i have found so far: 

AWS Athena -&gt; Read csv and query then return result [min charge for
10MB per scan :(]
AWS Gateway -&gt; AWS Lambda fn -&gt; Read file from S3
and return result

What would be better approach to this situation  70% queries will require multiple days data [reading multiple csv files]  
So should I append all data in single file and use Athena  
Or should I get an EC2 with presto  
Or Any other architecture to suit this need  
I am open to suggestions  let me know if any other details are required 
"
53057390,"Im trying to decide whether to use binary  number  or string for my DynamoDB tables partition key   My application is a React js/Node js social event-management application where as much as half of the data volume stored in DynamoDB will be used to store relationships between Items and Attributes to other Items and Attributes  For example: friends of a user  attendees at an event  etc 
Because the schema is so key-heavy  and because the maximum DynamoDB Item size is only 400KB  and for perf &amp; cost reasons  Im concerned about keys taking up too much space  That said  I want to use UUIDs for partition keys  There are well-known reasons to prefer UUIDs (or something with similar levels of entropy and minimal chance of collisions) for distributed  serverless apps where multiple nodes are giving out new keys 
So  I think my choices are: 

Use a hex-encoded UUID (32 bytes stored after dashes are removed)
Encode the UUID using base64 (22 bytes)
Encode the UUID using  (20 bytes)
Use a binary-typed attribute for the key (16 bytes)
Use a number-typed attribute for the key (16-18 bytes ) - the Number type can only accommodate 127 bits  so Id have to perform some tricks like stripping a version bit  but for my app thats probably OK  See
 for more info 

Obviously theres a tradeoff in developer experience  Using a hex string is the clearest but also the largest  Encoded strings are smaller but harder to deal with in logs  while debugging  etc  Binary and Number are harder than strings  but are the smallest  
Im sure Im not the first person to think about these tradeoffs   Is there a well-known best practice or heuristic to determine how UUID keys should be stored in DynamoDB 
If not  then Im leaning towards using the Binary type  because its the smallest storage and because its native representation (as a base64-encoded string) can be used everywhere humans need to view and reason about keys  including queries  logging  and client code  Other than having to transform it to/from a  if I use   am I missing some problem with the Binary type or advantage of one of the other options in the list above 
If it matters  Im planning for all access to DynamoDB to happen via a Lambda API  so even if theres conversion or marshalling required  thats OK because I can do it inside my API  
BTW  this question is a sequel to a 4-year-old question () but 4 years is a looooooong time in a fast-evolving space  so I figured it was worth asking again 
"
62137256,"I am using stripe-node library for integrating the Stripe payment gateway 
Here is my lambda function to cancel the subscription  

I am getting this stack trace error in cloud watch 

When I tried to cancel the subscription via CURL as suggested in docs  It worked fine  

"
52275235,"Im pretty new to the whole Serverless landscape  and am trying to wrap my head around when to use Fargate vs Lambda  
I am aware that Fargate is a serverless subset of ECS  and Lambda is serverless as well but driven by events  But Id like to be able to explain the two paradigms in simple terms to other folks that are familiar with containers but not that much with AWS and serverless  
Currently we have a couple of physical servers in charge of receiving text files  parsing them out  and populating several db tables with the results  Based on my understanding  I think this would be a use case better suited for Lambda because the process that parses out the text files is triggered by a schedule  is not long running  and ramps down when not in use  
However  if we were to port over one of our servers that receive API calls  we would probably want to use Fargate because we would always need at least one instance of the image up and running  
In terms of containers  and in very general terms would it be safe to say that if the container is designed to do:  

Then it is a job for Lambda  
But if the container is designed to do something like:

Then it is a job for Fargate  
Is this a good analogy  
"
69111239,"I’m looking for a way to transfer cloudwatch logs to s3 bucket  I found I can use subscription filter in cloudwatch  I see two options 
One is CW -&gt; Kinesis Firehose -&gt; S3 
Other one is CW -&gt; lambda -&gt; S3 
Do you know which one is better  I feel like Kinesis firehose is easier to set up  but is using lambda cheaper 
"
40829263,"I have the following situation that I try to find the best solution for  
A device writes its GPS coordinates every second to a csv file and uploads the file every x minutes to s3 before starting a new csv 
Later I want to be able to get the GPS data for a specific time period e g 2016-11-11 8am  until 2016-11-11 2pm
Here are two solutions that I am currently considering:

Use a lambda function to automatically save the csv data to a dynamoDB record
Only save the metadata (csv gps timestamp-start  timestamp-end  s3Filename) in dynamoDB and then request the files directly from s3 

However both solutions seem to have a major drawback:

The gps data uses about 40 bytes per record (second)  So if I use 10min chunks this will result in a 24 kB file  dynamoDB charges write capacities by item size (1 write capacity unit = 1 kB)  So this would require 24 units for a single write  Reads (4kB/unit) are even worse since a user may request timeframes greater than 10 min  So for a request covering e g  6 hours (=864kB) it would require a read capacity of 216  This will just be too expensive considering multiple users 
When I read directly from S3 I face the browser limiting the number of concurrent requests  The 6 hour timespan for instance would cover 36 files  This might still be acceptable  considering a connection limit of 6  But a request for 24 hours (=144 files) would just take too long 

Any idea how to solve the problem 
best regards  Chris
"
47804191,"Ive seen this post here:  which gives an example of how to use Spring in a Serverless scenario  but I believe that this still involves creating the Spring context  an expensive thing to do every time a request comes in  And I am wondering if Spring  but also the traditional web application frameworks are even truely compatible with the severless model  as they all tend to assume the server is only going to initialise on start  and then not again till the server is restarted  as opposed to being immediately ready to handle a request and not needing to initialize a Spring context for instance  So then these frameworks tend to do allot of stuff in the start up phase  which is not good I believe when you dont have a server per-say  and you effectively need to start up every time your would call what would be a lambda in AWS 
So my question is are these traditional web frameworks  such as Spring  which perform allot of compute when starting up still applicable in the Serverless model  for instance: AWS lambda 
"
61873077,"Im using an AWS serverless architecture to build an ecommerce platform and was wondering if the following is a smart way to handle images:

Use S3 for image storage 
When a new product is uploaded (description  images  etc) it will trigger a lambda function to create different sized images using a node library called  (a thumbnail  medium and large image size) 
These images will be stored in S3 (forget about caching for now if possible) and the URLs will be saved as part of the products object in a no-sql DB 
Do the same for each product image I want to add (i e  store 3 instances of the same image for each image) 

Aside from using a service like cloudinary is this a cheap and scalable way to handle images 
Many thanks
"
69076040,"I want to use AWS API Gateway HTTP API instead of old REST with my lambda functions  for pricing reasons 
Difference here: 
What is the option in Zappa for this 


[EDIT]
Not sure if its linked  but I encountered 
and then using this as  (using ):

"
45359497,"I have a program that performs several thousand monte-carlo simulations to predict a result; I cant say what they really predict  so Im going to use another example from the indisputable existence of santa claus  since the content of those algorithms are not relevant to the question   I want to know how often each square on a Monopoly board is visited (to predict which the best properties to buy are)   To do this  I simulate thousands of games and collate the results   My current implementation is a stand-alone C# application but I want to move it to the cloud so that I can provide this as a service - each user can get personalised results by submitting the number of sides that each of their dice have 
The current implementation is also quite slow - it is very parallisable since each simulation is entirely independent but I only have 8 cores  so it takes upwards of 20 minutes to complete the full prediction with about 50000 individual simulations on my local machine 
The plan is to have AWS lambda functions each run one (or several) simulations and then collate - basically mapreduce it   I looked in to using AWS EMR (Elastic MapReduce) but that is way too large-scale for what I want  spinning up the instances to run the computations alone seems to take longer than the whole calculation alone (which would not matter for multi-hour offline analyses  but I want low-latency to respond over a web request) 
The ideal as I see it would be:
Lambda 0 - Fires off many other lambda functions  each doing a small part of the calculation 
Lambda 1  N - Do many simulations in parallel (the number is not a constant) 
Lambda N+1 - Collate all the results and return the answer 
There is a lambda mapreduce framework here:

But it seems to have one major drawback - each time a map stage completes  it writes its results to S3 (Im fine with using that as a temporary) then triggers a new lambda via an event   That triggered lambda looks to see if all the results have been written to storage yet   If not  it ends  if yes it does the reduction step   That seems like a fair solution  but Im just slightly concerned about a) race-hazards when two results come in together  could two reducers both compute the results   And b) that seems like it is firing off a lot of lambdas that all just decide not to run (I know theyre cheap to run  but doubling the number to two per simulation - calculate and maybe reduce - will obviously double the costs)   Is there a way to fire off an S3 result after  say  100 files are written to a folder instead of after every one 
I looked at using step functions  but Im not sure how to fire many lambdas in parallel in one step and have them all return before the state machine transitions   Step functions would however be useful for the final wrinkle - I want to hide all this behind an API 
From what Ive read  APIs can fire off a lambda and return the result of that lambda  but I dont want the invoked lambda to be the one returning the result   It isnt when you instead invoke a step function from the API  the results of the last state are returned by the API call instead 
In short  I want:
API request -&gt; Calculate results in parallel -&gt; API response
It is that bit in the middle Im not clear how to do  while being able to return all the results as a response to the original request - either on their own are easy 
A few options I can see:
Use a step function  which is natively supported by the AWS API gateway now  and invoke multiple lambdas in one state  waiting for them all to return before transitioning 
Use AWS EMR  but somehow keep the provisioned instances always live to avoid the provisioning time overheads   This obviously negates the scalability of Lambda and is more expensive 
Use the mapreduce framework  or something similar  and find a way to respond to an incoming request from a different lambda to the one that was initially invoked by the API request   Ideally also reduce the number of S3 events involved here  but thats not a priority 
Respond instantly to the original API request from the first lambda  then push more data to the user later when the calculations finish (they should only take about 30 seconds with the parallelism  and the domain is such that that is an acceptable time to wait for a response  even an HTTP response) 
I doubt it will make any difference to the solution  since it is just an expansion of the middle bit  not a fundamental change  but the real calculation is iterative  so would be:
Request -&gt; Mapreduce -&gt; Mapreduce -&gt;     -&gt; Response
As long as I know how to chain one set of lambda functions within a request  chaining more should be just more of the same (I hope) 
Thank you 
P S   I cant create them  and neither the tags  nor  exist yet 
"
65405656,"After creating and using an Authorizer in Api Gateway  there is an option to enable Authorization Caching  with a variable TTL(seconds) settings 

What is the pricing involved with this authorization caching 
"
66993650,"I am getting the following error message from the Azure logs:

I think the offending code is:

Azure seems to be struggling to pull the referer from the req headers   It works in VScode   I use the referer to build a redirect URL after a Stripe payment request  This redirect is obviously different in DEV  TEST and PROD 
Any ideas what Im doing wrong 
"
54144737,"In my Lambda I am trying to parse the content of a document from s3 bucket  The document I am processing is a txt file with more than 100Mb  I need to parse only the first line of the file  
What is the best cost-effective way to read the file 
Currently  I am taking the content using getObjectContent() method and taking the 1st line from it like this  

Is it a good way to read the entire content just to read the first line  Is there any method available to read n number of lines from a file or n number of bytes from a file  
"
51407771,"I am using Hashicorp Terraform to define an AWS API Gateway to hit a Lambda function  I have a requirement that I need to tag my AWS resources with a particular tag so that costs can be tracked  Terraform seems to allow this for most resources  However  when creating an API Gateway stage using  I do not have the option to specify tags 
I see that Terraform recently added the resource   This one does allow tags to be specified  But  aws_api_gateway_stage requires an aws_api_gateway_deployment  If I give them the same stage_name as so:

Then they both resources try to create the stage and I get an error:
aws_api_gateway_stage PlayLambdaApiGatewayStage: Error creating API Gateway Stage: ConflictException: Stage already exists
    status code: 409  request id: f67a10c4-8aad-11e8-b486-c337ea2d214f
Here it would seem that the aws_api_gateway_deployment already created the stage  so the aws_api_gateway_stage resource failed to create it also  If I add the stage to the deployments depends_on so that the stage gets created first  it complains about there being a cycle between the two  
So  it seems like:

aws_api_gateway_stage is only intended to add additional stages to a deployment  rather than creating a stage to use for the deployment
aws_api_gateway_deployment does not allow tags to be specified when it creates the stage 

Any ideas  What am I missing 
"
55083541,"Looking in CloudWatch logs  I see these errors repeated continuously  approximately twice a second:

Does anyone know what these are  Ive tried Googling the exact and partial errors and was amazed to see that theres nothing out there (well Google  anyway  has never seen them )
I am concerned because --even if they are nothing to worry about-- they are generating millions of log entries and thus costing me lots in AWS fees 
Thanks in advance 
"
56687133,"i use AWS Api Gateway and a Lambda function to process Paypal (Ipn) instant notification messages  how can i secure my api gateway to only allow access to the message sent by Paypal which are then passed on to my lambda function  at the moment the api is open to anyone to access and i am afraid of malicious activity triggering the api and lambda function and thus incurring costs on my behalf 
i have secured my other Apis using Cognito and the associated lambda functions using roles and permission policies but dont know how to handle the calls on my ipn api as these will be unauthorized 
"
45320021,"Im looking into serverless technology (specifically  Python  Django and  on AWS Lambda) and one thing about error handling struck me  In the Zappa docs it says

By default  AWS Lambda will attempt to retry an event based (non-API Gateway  e g  CloudWatch) invocation if an exception has been thrown 

In the   I read:

Depending on the event source  AWS Lambda may retry the failed Lambda function  For example  if Kinesis is the event source  AWS Lambda will retry the failed invocation until the Lambda function succeeds or the records in the stream expire 

Does this mean a function will be called an infinite number of times when it raises an unhandled exception  If this goes on unchecked  the costs must go through the roof 
Related to that; what is meant by until the records in the stream expire  What records  and what stream 
"
44614048,"Im using AWS Lambda to consume from Kinesis  My Lambda function doesnt have any requirements on max concurrency  Is there any reason for me to not have the maximum possible number of shards for my stream  I cant see that number of shards would affect cost 
"
55352734,"I have built a deployment package with pandas  numpy  etc for my sample code to run  The size is some 46 MB  Doubt is  do I have to zip my code update every time and again update the entire deployment package to AWS S3 for a simple code update too 
Is there any other way  by which  I can avoid the 45 MB upload cost of S3 everytime and just upload the few KBs of code 
"
33004830,"I want to create a few HTTP points where mobile clients  servers &amp; IoT devices will be posting data  I may need to preprocess the events &amp; act up on them  Eventually I want to access all the raw data &amp; make queries using Domo  Cloud Business Intelligence | Chartio or Tableau  
I need to understand what are the differences &amp; advantages for the following architectures:

AWS API Management + Lambda + Redshift: I can create an HTTP endpoint &amp; a lambda function that will parse the data  compute &amp; store in Redshift
Kinesis Firehose + Redshift (how do I stream the data over HTTP here )
S3 + Kinesis + Redshift (I can use an HTTP endpoint that writes data to S3)
S3 + Kinesis Firehose + Redshift
S3 + Lambda + Redshift

I feel like 3  4 &amp; 5 create redundancy because of S3 
Will the execution of Lambda functions have a significant cost overhead over using Kinesis 
"
57943748,"The main question is: how is time accounted in a wsgi application deployed on aws Lambda 
Suppose I deploy the following simple Flask app:

using Zappa on AWS Lambda  with the following configuration:

Now if AWS has a request for my website  it will spin up a container with my code inside and let it deal with the request  Suppose the request is served in 200ms 
Obviously the Lambda with the wsgi server inside continues running (Zappa by default makes the lambda run for at least 30s) 
So now to the various subquestions:

How much time am I charged for the execution 

200ms because of the request duration
30s because of the below limit for my lambda execution time
until the lambda is killed by AWS to reclaim space (which could occur even 30-45 minutes after)

If another request come along (and the first one is still being served) will the second request spin up another Lambda container or it will be queued until a threshold time has passed 

I expected to be charged just for the 200ms by reading AWS Lambda pricing page  but I would bet on it charging for 30s because  after all  Im the one who imposed such limit 
In case Im just charged for 200ms (and subsequent requests time) but the container keeps running uninterruptly for 30-45 minutes  I have a third subquestion:

Suppose now that I want to use a global variable as a simple local cache and synchronize it with a database (lets say DynamoDB) before the container is killed 
To do this I would like to raise the execution time limit of my lambdas to 15m  then at lambda creation set a Timer to fire a function that synchronizes the state and aborts the function after 14m30s 
How would accounted running time change in this settings (i e  with a Timer that fires after a certain amount of time) 

The proposed lambda code for this subquestion is:

Thanks in advance for any information 
"
56274163,"I am currently using AWS EC2 for my workloads  
Now I want to convert the EC2 server to the Serverless Platform i e(API Gateway and Lambda)  
I have also followed different blogs and I am ready to go with the serverless  But  my one concern is on pricing  
How can I predict per month cost for the serverless according to my use of EC2  Will the EC2 Cloudwatch metrics help me to calculate the costing  
How can I make cost comparison  
"
58734531,"I am exploring CloudWatch Logs streams to Firehose  As I understand so far  Cloudwatch Subscription Filter is an event that triggers a lambda to digest the CloudWatch logs and send it to a different destination (ElasticSearch or Firehose or     another custom lambda)  Please correct me if I am wrong  
My concern at the case Cloudwatch Logs Stream to Firehose are: 
1/ In term of performance + pricing  is there any difference between : 

Cloudwatch Subscription Filter -&gt; Firehose 
Cloudwatch Subscription Filter -&gt; Lambda -&gt; Firehose 

2/ Which data format does Firehose received from Cloudwatch 

Cloudwatch Subscription Filter -&gt; Firehose : I dont know
Cloudwatch Subscription Filter -&gt; Lambda -&gt; Firehose : I think lambda can transform the logs to JSON then put it to Firehose 

Any suggestion is appreciated 
"
60361736,"I have a lot of dotnet lambda microservices using SSM parameter store for configuration purposes  Its been quite adventageous over environment variables as Im sharing a lot of configuration across different microservices  Though recently Ive started pushing the limits of it  It now affects my throughput and started costing more than Id like 
Ive considered using the amazon extension for dotnet configuration manager  but it falls short for my requirements  I need the configuration to hot swap to keep the microservices running healthy at high uptime  Which wont happen with its current implementation  Deploying all microservices just for a configuration change is not an option either 
This lead me to research a cache solution that is able to at least invalidate the cache from outside  but I couldnt come accross anything that works with SSM parameter store out of box 
At worst  Ill need to come up with another microservice with its own db that takes care of the configuration  but I dont wanna go down that path tbh 
What is the general approach that is being used this kind of scenarios 
"
60580598,"I have data saved in a Microsoft excel file  I need to turn that data into something that a Lambda function can parse 
I think the best way to do this is to convert the excel file into a JSON file (and then my Lambda function can read and parse it) 
Whats the best way to do this 
To convert the excel data file into a JSON file  I have found some handy online converter tools  like   It seems to work 
However  that converter and others add in  wherever there are line breaks in the data  and  wherever there are quotes in the data  (the line breaks and especially quotes need to be in the data)
So to properly read the data in the JSON file  I have to then get rid of these changes to the raw data 
Is there another way to do this  Such as a converter that does not change the raw data in this way  Or some method other than a converter 
Once the raw data has been changed (by adding in stuff like  and  like I mention above)  it becomes cumbersome to remove it  I can do a find/replace to get rid of the changes  but that adds steps that can become costly time wise  And using regex could add performance hits 
**EDIT: Note that I probably need a method that creates an actual document (so a program that produces the data in a client browser would not work)  I am looking to create an actual document that my Lambda can then analyze  **
"
54579390,"The challenge is to run a set of data processing and data science scripts that consume more memory than expected 
Here are my requirements:

Running 10-15 Python 3 5 scripts via Cron Scheduler
These different 10-15 scripts each take somewhere between 10 seconds to 20 minutes to complete
They run on different hours of the day  some of them run every 10 minute while some run once a day
Each script logs what it has done so that I can take a look at it later if something goes wrong
Some of the scripts sends e-mails to me and to my team mates
None of the scripts have an HTTP/web server component; they all run on Cron schedules and not user-facing
All the scripts code is fed from my Github repository; when scripts wake up  they first do a git pull origin master and then start executing  That means  pushing to master causes all scripts to be on the latest version 

Here is what I currently have:

Currently I am using 3 Digital Ocean servers (droplets) for these scripts
Some of the scripts require a huge amount of memory (I get segmentation fault in droplets with less than 4GB of memory)
I am willing to introduce a new script that might require even larger memory (the new script currently faults in a 4GB droplet)
The setup of the droplets are relatively easy (thanks to Python venv) but not to the point of executing a single command to spin off a new droplet and set it up

Having a full dedicated 8GB / 16B droplet for my new script sounds a bit inefficient and expensive  
What would be a more efficient way to handle this 
"
58317315,"I have a requirement of creating an ECS Cluster without using autoscaling 
This is because of a Dedicated Host (DH)  Tenancy=Host  is not supported with ASGs   DH is mainly for cost savings and for some cases because of the savings is worth doing even if we cant use ASGs 
I understand this can be done using Macros and Custom Resources backed up with Lambda or using Troposphere to loop over the instance 
But to start with any example of the same or any other approach would be really appreciated  
Below is my appsec yaml template file:

"
63032033,"I have Next js web application hosted on Vercel with its database on Mongo Cloud Atlas  My goal is to assess cost  speed and convenience
Next js can serve static files by placing the files in the same folder as the website itslef  That being said  is it faster to serve images from next or Mongo 
Also  from a cost perspective  mongo is not free 
"
31728414,"Im looking to create a RESTful API using AWS Lambda/API Gateway connected to a MongoDB database  Ive read that connections to MongoDB are relatively expensive so its best practice to retain a connection for reuse once its been established rather than making new connections for every new query 
This is pretty straight forward for normal applications as you can establish a connection during start up and reuse it during the applications lifetime  But  since Lambda is designed to be stateless retaining this connection seems to be less straight forward 
Therefore  Im wondering what would be the best way to approach this database connection issue  Am I forced to make new connections every time a Lambda function is invoked or is there a way to pool/cache these connections for more efficient queries 
Thanks 
"
66360653,"For a CRUD application what would be the best approach to design AWS lambda function:

Create a single lambda function and differentiate each call with a switch case in the handler 
Create a single lambda function but with a separate handler for each call  Is it possible even 
Create a separate lambda function for each operation 

As these are just simple CRUD operations  size is not a big factor  But I am bit concerns with the managing and cost-effectiveness 
"
69843744,"I have checked most of the GCP services and Cloud Functions &amp; Run are awesome  but they have limited runtime  also the App engine is designed for website hosting  not for temporary backend tasks 
so is there any service that supports my case  with serverless behavior where just pay for usage 
"
46154682,"I am looking at serverless architecture to process some customer data  The process itself is probably quite quick  but for various reasons I would like the cloud service provider to gurantee executional isolation  So far  Ive talked to a rep from Amazon  who said that Amazon Lambda are not effectively isolated  and the lambda container may end up being reused 
Effectively  when running a function and  say  writing something to memory or disk (here we might not have control  as part of the solution would let customers execute arbitrary code) I would like a sandbox isolation gurantee 
Ive read that Microsoft was going to offer such isolation  but apart from a   I couldnt find and concrete information  There they alude to extra costs of sandboxing functions for example  
So is there any provider that could gurantee executional isolation 
"
62699781,"Im attempting to use an AWS Lambda function as a scheduling agent to post recurring payments to a payment api (USIO)  The function used to make the post request is as follows:

where data is an object like so:

and the post function is called like so:

Despite verifying that obj inputs are all valid  I continue to receive a Status code: 404 logged when the POST request is made   No VPCs have been added to the lambda function 
Im new to making api calls via lambda  but was able to receive a 200 status code when testing the function with a different api address   Wondering what may be causing the 404 status code in this instance 
"
45692168,"I have a Python scraping script I wish to run on AWS Lambda  to save on EC2 costs  However  the script also requires PhantomJS  oauth2client  PYOpenSSL  selenium and of course  Beautiful Soup to complete its scraping 
Is it possible to run Beautiful Soup (by running the additional required programs above too) on AWS Lambda 
"
57054559,"I have multiple CSV files containing data for different tables  with different file sizes varying from 1 MB to 1 5 GB  I want to process the data (replace/remove values of columns) row by row and then load the data to existing Redshift tables  This is once a day batch processing 

AWS Lambda:


Lambda has limitations of memory  hence I was not able to run process for  large CSV files 

EC2: I already have EC2 instance where I am running python script to transform and load the data to redshift  


I have keep EC2 running all the time  which has all python scripts which I want to run for all tables and environment created (installing  etc)  leads to more cost 

AWS Batch: 


I created a container image which has all the setup to run the python scripts  and pushed it to ECR 
I then set up AWS Batch job  which can take this container image and run it through ECS 
This is more optimized  I only pay for EC2 used and ECR image storage 
But all the development and unit testing I will have to do on my personal desktop and then push a container  no inline AWS service to test 

AWS Workspaces:


I am not much familiar with AWS Workspaces  but need inputs  can this also be used as aws batch to start and stop instance when required and run python scripts on that  edit or test scripts 
Also  Can I schedule it to run everyday at defined time 


I need a inputs on which service is best suitable  optimized solution for such use-case  Or It would also be great if anyone suggests a better way to use above services I mentioned in better way 
"
57995007,"I have built an EC2 reverse proxy (Nginx) that communicates with an external API endpoint over the internet  I have a Route53 DNS with an A record linking to my EC2  There are a few endpoints (Nginx locations) and depending on which url you hit  you are redirected to a specific proxy location  and forwarded to the right endpoint on the external API  It all works great 
Now i want to create some type of job that will test this process periodically to ensure that its running and notify me if its not  AWS has so many tools and i think i need to use Lambda and API Gateway 
Id like to hit my url(Route53 DNS) go thru the EC2 and receive a response from the endpoint server  My site does this  postman can  but i cant figure out how to accomplish this in an automated way and alert me based on the response values 
how can i test my full pathway (www example com/option -&gt; nginxEC2 path(/option) -&gt; www endpoint com/option) and be notified based on the results 
EDIT: i need to be able to send a body with this  if i send it without body the server returns 404  if i can send with a body/payload  ill get a response 
EDIT: basically looking for a way to hit my DNS  which thru A record  routes to my reverse proxy  to an endpoint  i just need to do an HTTP request to the Domain  and get and answer back and know the status code  
Mark Bs solution is the closest as the free site he sent me has an option to pay for this service  gonna leave it open a few more days  
"
53372107,"Currently  I have an AWS SQS as a trigger to my AWS Lambda function 
I would like to implement long polling to reduce costs since Ive used up 70% of my monthly free tier  mostly from empty receives 
I tried setting up long polling by changing the queue attribute  to :

However  this didnt seem to reduce the number of empty receives  where the settings were changed on 11/19  between 2:00 - 3:00  

According to the    has priority over the queue attribute 

Short polling occurs when the WaitTimeSeconds parameter of a
  ReceiveMessage request is set to 0 in one of two ways:

The ReceiveMessage call sets WaitTimeSeconds to 0 
The ReceiveMessage call doesn’t set WaitTimeSeconds  but the queue    attribute ReceiveMessageWaitTimeSeconds is set to 0 

Note
For the WaitTimeSeconds parameter of the ReceiveMessage action  a
  value set between 1 and 20 has priority over any value set for the
  queue attribute ReceiveMessageWaitTimeSeconds 

Since AWS Lambda is receiving the SQS requests  I dont think  can be configured  
Why doesnt my long polling configuration work in this situation  Am I misunderstanding something  or did I configure it wrong 
Thank you 
"
54287228,"I have an AWS Lambda function which triggers https request to Google API  I want the function to be awaitable  so that it does not end immediately  but only after getting response from Google API 
Yes  I know I pay for the execution  but this will not be called often  so it is fine 
The problem is that the http request does not seem to fire correctly  The callback is never executed 
I have made sure that the async/await works as expected by using setTimeout in a Promise  So the issue is somewhere in the https request 
Also note that I am using Pulumi to deploy to AWS  so there might be some hidden problem in there  I just cant figure out where 

The relevant code:
AWS Lambda which calls the Google API

"
43113198,"I am thinking to use AWS API Gateway and AWS Lambda(Python) to create a serverless APIs   but while designing this i was thinking of some aspects like pagination security caching versioning   etc 
so my question is: 
What is the best approach performance &amp; cost wise to implement API pagination with very big data (1 million records)  

should i implement the pagination in postgresql db  (i think this
would be slow)
should i not use postgresql db pagination and just cache all the results i get from db into aws elastic cache and then do server side pagination in lambda 

I appreciate your help guys   
"
62283393,"Im new to AWS Lambda and I recently started developing Lambda functions together with API Gateway and RDS as a simple backend-solution  
Ive been searching for an IDE where I can edit the code of the functions  Ive tried Cloud9 but Im looking for an environment thats not browser-based and with an app for mac  IntelliJ seems like an option too but its a bit expensive for my needs  
Any free / cheap alternatives for just editing the code of the Lambda-functions in an independent app for mac  
"
55340604,"would love to hear some opinions regarding hosting of an Angular Universal app 
Question - EC2 vs AWS Lambda
After finishing my application I initially created t2 micro linux instance to host my app  was happy to see that the site scores 97 in Googles page speed insight test 
Afterwards I came across AWS lambda  a serverless way to run my server rendering app   as its cost depends on the amount of requests (which Is extremely low on my website) thought that could be a nice way to avoid paying $10 a month 
The only issue is - Google speed test (using AWS Lambda) scored a sad 80     with a huge red flag on server response time 
After doing a few more tests seems like the function became warmer and got up to 92  thats not 98 but I can live with that 
The thing is  as Im planning to get about 20-50 requests spread through out the entire day it will stay cold  so SEO wise Ill stay on 80 score website instead of 98 
Is there something Im missing  As convenient as it is should I just stick with EC2 for my needs 
Thanks for reading &lt;3
"
39312837,"We have a  NET client application that uploads files to S3  There is an event notification registered on the bucket which triggers a Lambda to process the file  If we need to do maintenance  then we suspend our processing by removing the event notification and adding it back later when were ready to resume processing 
To process the backlog of files that have queued up in S3 during the period the event notification was disabled  we write a record to a kinesis stream with the S3 key to each file  and we have an event mapping that lets Lambda consume each kinesis record  This works great for us because it allows us to control our concurrency when we are processing a large backlog by controlling the number of shards in the stream  We were originally using SNS but when we had thousands of files that needed to be reprocessed SNS would keep starting Lambdas until we hit our concurrent executions threshold  which is why we switched to Kinesis 
The problem were facing right now is that the cost of kinesis is killing us  even though we barely use it  We get 150 - 200 files uploaded per minute  and our lambda takes about 15 seconds to process each one  If we suspend processing for a few hours we end up with thousands of files to process  We could easily reprocess them with a 128 shard stream  however that would cost us $1 400 / month  The current cost for running our Lambda each month is less than $300  It seems terrible that we have to increase our COGS by 400% just to be able to control our concurrency level during a recovery scenario 
I could attempt to keep the stream size small by default and then resize it on the fly before we re-process a large backlog  however resizing a stream from 1 shard up to 128 takes an incredibly long time  If were trying to recover from an unplanned outage then we cant afford to sit around waiting for the stream to resize before we can use it  So my questions are:

Can anyone recommend an alternative pattern to using kinesis shards for being able to control the upper bound on the number of concurrent lambdas draining a queue 
Is there something I am missing which would allow us to use Kinesis more cost efficiently 

"
43828054,"I have an AWS Lambda function which calls a deep learning function on   does some post processing on the results and then returns some data  Algorithmia provides a  which I am using that just makes things a little easier to send a request to an algorithm on the Algorithmia platform 
The problem is as follows: When an Algorithmia function hasnt been called for a while it is unloaded and the first call to warm it up (cold start) takes a while  possibly 30 seconds  If my Lambda function is going to be waiting for 30 seconds for a response whenever it happens to be triggering the Algorithmia function from a cold start thats going to be very expensive and wasteful 
Is there some way to send off a HTTP request in Lambda and when the request is finished the results are piped into a new Lambda function so as to not require a Lambda function to be waiting the entire time and wasting resources  Id expect not as Im not sure how that would practically work - does anyone have other ideas as to how to avoid waiting a while for a response and wasting Lambda resources 
Edit: In most cases (except obviously the ones where the Algorithmia algorithm takes a while to load from cold start) latency is an issue and I cant afford to increase latency by doing some workaround method with the Algorithmia function writing its response to S3 (for example) and then triggering a Lambda function 
"
55412624,"If my Lambda function written in Python takes 1 8 seconds to initialize (during a cold start) and 400 ms to execute  am I charged for the 400 ms execution time or the entire 2 2 seconds of initialization + execution time 
From X-Ray  I see:

From CloudWatch logs  I see:

What I understand from this is that I was billed for 500ms of execution time  so does that mean code initialization (e g  importing stuff) is free 
"
63954863,"In legacy AWS Lambda node js project there is a  property in  

I didnt pay attention to it before  but after upgrading  to v 2 0 0 I get the warning on :

It seems this property has become deprecated  but what did it do  Is it safe to remove it from  
"
55870453,"I have set up a simple intent 





But when I ask a question it gives me a generic error response like this:
Me: alexa ask viva bank when is the late fee charged
Alexa: Sorry  I dont know that 
Here is my lambda code  but I dont think it is getting that far 





Im really just looking to create a very simple pass through  where a question is asked to Alexa  and then I pipe that to an external API and have Alexa read the response 
"
69943722,"Im using AWS API Gateway and passing one large CSV file to backend Lambda  Due to limitation of AWS API gateway response time that is 30 seconds  its not processing 
I explored web socket option but its an expensive option because connections need to open all the time 
Can someone please advice me best solution to solve this issue 
Thanks
"
59698857,"We have been running multi-tier application on aws and using various aws services like ECS  Lambda and RDS  Looking for a solution to map billing items to actual system components  finding the most money spending component etc 
AWS improved its Detailed Cost Usage Reports and have Cost Explorer API however it only break down the billing to services or instances  However per instance breakdown does not bring so much value if you looking for what is the cost of each component  Any solutions/recommendations for this     
"
49053158,"I have a sync job (in Node js) which has to process several hundred of documents in one batch  For each of them also perform several tasks  As usually  after deployment  such job will become a blackbox: without propper logging it is impossible to find a problem 
Therefore  I log any reasonable information - which document job is being processed  what task is performing now etc  I use console log / console error for logging  This results in a very large log file  which is not that big problem when running localy 
Once deployed on AWS  is there any best practice / limitation for logging  I am afraid of costs also 
Thanks 
"
61861078,"I am building a basic crud web app and I want to deploy it to AWS  I read about many services only at a high  but before I implemented anything I wanted to know if the following plan was feasible and at least somewhat efficient:

Deploy the static content of a (React) Single Page Application to an S3 bucket  My plan is to use an S3 bucket to serve this static content with a custom domain name 
Deploy an API (that performs crud operations) using API Gateway and Lambda  This API will interact with DynamoDB for storage  This API is expected to only be used by my single page app so my assumption is that I can secure it and make it non-public 

My understanding is that the above is a relatively cost efficient architecture for aws (though I expect to remain in the free tier) 
Any major holes in my plan or something I overlooked  I know I could choose a million ways to do this including Elastic Beanstalk  but I would appreciate any advice on any different ways this can be achieved  as well as any insight on the trade offs I can make  
"
57532771,"I have a Lambda function that needs to connect to S3  RDS  and Rekognition   Obviously this means putting it in a VPC  which of course kills internet access (thanks AWS    )
I was able to maintain access to S3 by simply creating a networking endpoint to    This prevented me from having to create a Gateway  as I refuse to pay $33 a month simply for my Lambda function to access the internet    
But  are there really no endpoints that will work with Rekognition  I didnt see anything obvious  but Im really out of my comfort zone as it is dealing with VPC networking  so I wanted to double check to see if any of the other 45 endpoints would work  or if anyone has come up with any work-arounds 
"
48290694,"I have an RDS database instance on AWS and have turned it off for now   However  every few days it starts up on its own   I dont have any other services running right now 
There is this event in my RDS log:
DB instance is being started due to it exceeding the maximum allowed time being stopped 
Why is there a limit to how long my RDS instance can be stopped   I just want to put my project on hold for a few weeks  but AWS wont let me turn off my DB   It costs $12 50/mo to have it sit idle  so I dont want to pay for this  and I certainly dont want AWS starting an instance for me that does not get used 
Please help 
"
56926793,"I am writing a Lambda Function in Python 3 6 to query out specific conditions from the Cost Explorer API  it will eventually be invoked by API Gateway so I want to be able to send back a pared down response  as well as take that same response and persist it into S3 
I have the overall functionality working correctly  I was hoping to shortcut parsing and just crawl the response  but that was not working with Glue and Athena  The basic functioning code is below:

It gives a response like this according to 

Which looks something like this when I run my function (VS Code did this spacing):

I am trying to parse out only the information I get from Groups  both as the printed response when I proxy it back to API Gateway and also when I persist it to S3 (or Dynamo) to save reports and eventually add some analytics layering to this  I modified the end of my function code to this:

That did not work  and now I am getting this error in CloudWatch Logs

Is there something obvious I am doing wrong  Am I not allowed to parse out only a specific array in the body  Thanks for your help in advance 
"
58980871,"Im using Visual Studio to publish an ASP NET Core 2 1 app to AWS Lambda (serverless)  No matter what Ive tried I cannot get CORS to work  
All I really want to do is add the header  globally to my web app  
Has anyone ever successfully added headers to an ASP NET Core 2 1 Serverless app 
Startup cs

No CORS headers are added to my pages  Im using Chrome dev tools to inspect my headers  I should see them on the homepage (for example) correct 
Any ideas  Im dyin over here  Thanks 
EDIT
This application only uses API Gateway  Lambda and a few other services  Its great because Im only charged when someone hits my app  There are no hourly charges  No EC2 or ELB which is amazing  
Also  I almost added this to my original post  The  @sturcotte06 references has a gotcha  
The API Gateway (automatically generated) uses the ANY method in a proxy integration  The above article says this   

Important
When applying the above instructions to the ANY method in a proxy integration  any applicable CORS headers will not be set  Instead  your backend must return the applicable CORS headers  such as Access-Control-Allow-Origin 

Ugh  So its saying I must do this on the backend (Startup cs right ) which is exactly what seems to get ignored when published  
"
44613416,"Im considering building a serverless web API which uses API Gateway to receive a stream of JSON blobs  Id like to archive every incoming blob (after some basic authentication and validation of course)  What are your recommendations on how to do this 
Additional info:

Im using AWS Lambda reduce cost 
The archives will be accessed very infrequently  so Ive been eyeballing S3 Glacier to reduce pricing  My issue is I need to figure out how to do batching of blobs per S3 file to avoid the overhead of many files 
Alternative storage services that Ive been looking at are Cloudwatch logs and DynamoDB 

"
63156643,"Im developing an application with micronaut using SAM CLI to deploy it on AWS Lambda  As I was including dependencies and developing new features  the function packages got bigger an bigger (now they are around 250MB)  This makes deployment take a while 
On top of that every time I edit  and then run  to try a new configuration on S3  RDS  etc    I have to wait for gradle to build the function again (even though its unchanged since the last deployment) and upload the whole package to S3 
As Im trying to configure this application with many trials and errors on SAM  waiting for this process to complete just to get an error because of some misconfiguration is getting quite counterproductive 
Also my SAM s3 bcuket is at 10GB size after just a single day of work  This may get expensive on the long run 
Is there a way to avoid those gradle rebuilds and reuploads when teh function code is unchanged 
"
52665792,"How is Lambda pricing calculated 
It is f(MemoryTime  # of Calls  Free Quotas) 
So I setup my Lambda with memory of 1GB and a max time of 60 seconds 
Assume I have 10 000 calls and the average call time is 30 seconds 
How would I calculate the MemoryTime  do I use the max time of 60 seconds or the average call time of 30 seconds 
if it is 30 seconds then the max time set up with the Lambda is to put a cap on max processing time and is used for a run-away process 
Thanks 
Marc
"
51210445,"On my project there is REST API which implemented on AWS API Gateway and AWS Lambda  As AWS Lambda functions are serverless and stateless while we make a call to it  AWS starts a container with code of the Lambda function which process our call  According  after finishing of lambda function execution AWS dont stop the container and we are able to process next call in that container  Such approach improves performance of the service - only in time of first call AWS spend time to start container (cold start of Lambda function) and all next calls are executed faster because their use the same container (warm starts) 
As a next step for improving the performance we created cron job which calls periodically our Lambda function (we use Cloudwatch rules for that)  Such approach allow to keep Lambda function warm allowing to avoid stopping and restarting of containers  I e  when the real user will call our REST API  Lambda will not spent time to start a new container 
But we faced with the issue - such approach allow to keep warm only one container of Lambda function while the actual number of parallel calls from different users can be much larger (in our case thats hundreds and sometimes even thousands of users)  Is there any way to implement warm up functionality for Lambda function which could warm not only single container  but some desired number of them 
I understand that such approach can affect cost of Lambda functions using and possibly  at all it will be better to use good old application server  but comparison of these approaches and their costs will be the next steps  I think  and in current moment I would like just to find the way to warm desired count of Lambda function containers 
"
65501733,"Im developing a game using AWS Amplify  The game state will be stored in DynamoDB tables and will be queried and modified with GraphQL  There isnt a pressing need for realtime or low-latency communication; However  I need to detect when a player joins or disconnects from a game  Whats the best mechanism for implementing this 
What I had in mind was an event that fires when a WebSocket connection is established or broken  The best I could glean from the Amplify docs was using   but I dont know if this will work  If possible  I would like to avoid incurring additional API costs 
I already implemented a version of this where the client updates a  field in the database every 30 seconds or so but it felt pretty janky 
"
66269219,"The question is mostly self-explanatory 
If I run  locally (assuming both the bucket and the instance are on the same region)  does the data go from s3 to ec2 internally (in which case there are no data transfer costs)  or does it go first from the bucket to my computer  and only then to the instance (in which case there are s3 download data transfer costs) 
Thanks a lot 
"
58785818,"I am considering sending my logs into StackDriver instead of CloudWatch  But from the docs  it seem to only describe how to do it with EC2  What about lambda  I prefer to send logs directly to StackDriver instead of StackDriver reading from CloudWatch to remove the CloudWatch costs entirely  
"
63086769,"I am creating a Disaster recovery solution in AWS  For second (fallback) region i want to have only 1 EC2 instance to minimise cost  In case of disaster i would like to know if its possible to write a lambda function in the second region that increases the desired capacity of the auto Scaling group to some number 
To achieve this i can subscribe the function to the health check alarm SNS topic 
I would like to know if there is a API to autoscale a ec2 group from Lambda and what sort of roles/permissions is needed  
"
71417552,"I need to do a search in my dynamoDB table that matches multiple values from a single item 
This is the type of Items i am storing:

I need to return an array of items having tags that match all of the tags a the comma-separated list 
For example: i am looking for items that only contains tags tag1 and tag2 
My first aproach was getting all the items from the dynamoDB table and then iterating each item to check if this condition matchs  then add the target item to an object of objects 
My approach is definetly not cost effective  Any suggestions with node js 
"
43870717,"Asynch programming helps to increase the number of requests a server can handle simultaneously but not necessarily the time to produce the response 
Since AWS cost depends only on the number of requests and on the execution time  does it make sense to use asynch programming 
In my case  I have a java lambda that needs to call a single http server  No more than that  
I could either use an http synch or asynch library 
The synch code is more readable  I understand the asynch code is generally better in case of concurrency but probably this not in case of AWS lambda 
"
57566552,"I am having long cold start times on our Lambda functions  We have tried pinging the Lambdas to keep them warm but that can get costly and seems like a poor way to keep performance up  We also have an EC2 instance running 24/7  I could theoretically mirror all of our Lambda functions to our EC2 instance to respond with the same data for our API call  Our Lambdas are on  and our EC2 is  
My question is could we load balance  traffic between the two  (Create a new subdomain to do the following) To have our dev subdomain (EC2) respond to all requests up until a certain requests per minute is hit  Then start to route traffic to our dev subdomain (Lambda) since we have enough traffic coming in to keep the Lambdas hot  Once traffic slows down  we move the traffic back over to our EC2   Is this possible  
"
69923628,"I have about 60 lambda functions in my AWS account 
Is it possible to list AWS lambda functions by their costs (invocations * duration during a period of time) 
Because Im going to change their architecture from  to  to save money  And I want to start doing this from the most expensive lambda funciton 
 doesnt seem to provide this feature 
"
41328205,"Being the cheap-o that I am  I had an idea the other day of running a web app for less than a nickel per month with AWS:

Serve a static site (html/css/javascript) via S3
Client-side code and forms post to Lambda golang microservices via API Gateway
Use DynamoDB (25 read/s  25 write/s  25GB  1GB/mo in  1GB/mo out) as database

Would this scheme work with say  cookie and sesssion-based authentication  as the page is being served by one domain name (S3)  but the javascript is talking to another domain name (API Gateway) 
What other issues am I likely to run into 
"
61324341,"I need to implement functionality:

Receive api request 
From the input  create X different cases
For each case  do calculation
Aggregate all results  and send result back to api gateway

First guess was using Step Functions  but this service has limit for 32kb of data transferred between steps  which is not working for me  Also  since I have about 10 steps  I assume it would be hard to implement and also expensive to try to use S3 for storage of this inter-steps data 
Second guess was calling multiple lambdas from single lambda  and wait for all responses  Since I use AWS C++ SDK  it seems a bit complicated since there is almost no documentation for c++ or good examples of this case 
The simplest solution for me would be to create multiple threads inside single lambda  but it supports only 2 cores  which is also not working for me  I need at least 50-100 
Do you have any other solution or idea  as simple as possible  Is it possible to use aws batch or sqs for this or something else 
"
57591791,"I have a function that writes the cost of the account in a CSV  Now I would like to use assumed role to query all other accounts  Unfortunately he only writes the costs of the account where the Lambda function is located  What do I do wrong to write all further costs into the CSV file  Here is the code as I thought it would be  I left the function of the CSV out of the picture  because it works perfectly 

"
49352907,"My use case is a Lambda function behind API Gateway  I use API as a proxy with /{proxy+} path and method ANY  I want to secure my Lambda function so  that only authorized users can execute it and perform only allowed actions using this function  I know  that the way to go is to create custom authorizer  But I think this approach is pretty ineffective  
Two cons:

Every time my API is used  two Lambda functions will be executed instead of one: authorizer and main Lambda   Both Lambdas in my case will connect to database  Authorizer - to verify user and decide what policy to return  Main Lambda - to perform its task  It will cost extra money and reduce the speed of my app 
Authorizer can only decide  whether user is allowed to execute my function or not  It cannot decide whether user is allowed to perform some specific action by the Lambda function  So my access logic will be splitted: part of it will be in authorizer and another part  more specific  in my Lambda  Not very good 

Isnt it better not to use custom authorizer in my case and just pass all requests to my main Lambda  which will decide whether user is authorized or not  In the latter it will just send response with code 401 (Unauthorized) 
I understand that custom authorizer is a more universal approach  because it allows to protect all types of API integrations besides Lambda (HTTP  Mock  etc )  but in my case it is Lambda function 
"
39208258,"AWS Lambda logging on CloudWatch may become an huge hidden cost if you have a lot of them  because there are no way to tell AWS to stop logging on CloudWatch platform 
The only way I have found to do that is to manage a custom IAM policy (associated with every lambda) and explicitally deny access to the logs:    actions:

Now Im trying to fine graining the policy to let only some lambda to log  To do that Im using the Condition parameters of the policy:

but in this way no log is sent to CloudWatch  I think that the source ARN is wrong but I cant figure out to find the correct one 
Any clues 
"
69556747,"I want to fetch storage capacity  storage type   Throughput capacity and backup storage for FSX and calculate the cost using aws price calculator 
I am new to this and dont have any idea how to do it 
Also let me know if i am going wrong
Thanks in advance
"
57031350,"Background: I am very new to the AWS Management Console  and I just created a very simple AWS Lambda function(Python 3 7) that deletes EBS Volume Snapshots based on a time limit  I also created a CloudWatch event to trigger the function every hour of the day  This works well for a few volumes  but with additions of volumes  this causes cost / speed issues 
Question: I am trying to update my EBS Snapshot Deletion lambda function code to  find the rate limit of requests to avoid throttling  and use that to create an exponential backoff/retry model for the program(making the program scalable no matter how many snapshots there are)  I would assume there is a special API call that can help me with this  but I have not been able to find any concrete information online  Any help would be much appreciated  Pasting my current code below:

"
44468486,"My system architecture looks like as follows:-
SNS -&gt; AWS Lambda -&gt; Dynamo Db
So  SNS is publishing messages to which AWS Lambda function is the subscriber and then AWS Lambda pushes the data into Dynamo Db  In this  I am doing some transformation of messages in AWS Lambda  For the transformation  I have to fetch some rules from some place  These rules are basically the mapping between fields of the original messages to fields to transformed messages 

So  basically I am saying that id should be mapped to id  house to home and so on  
So  I want to keep this mapping at some places like Dynamo Db or some config service  I do not want to directly keep it in aws lambda code as there is a chance that I might have to change  But keeping it in Dynamo Db will be very costly in terms of latency I think because I will make a call on each message request  So  can anyone suggest  any aws resource which can be used for keeping these configs which is very fast and normally used for keeping configuration 
"
52718442,"We already have Azure function in Microsoft Azure  AWS Lambda in AWS  Google Cloud Function in Google 
Then What are reasons do we need to use Spotinst function 
Wil Spotinst function replicated and running on all Cloud Providers such as Azure  AWS  Google and all regions at the same time when we choose all Cloud Providers and regions 
Which Cloud Providers will have to pay for running a Spotinst function 
"
42820043,"I currently have a frontend-only app that fetches 5-6 different JSON feeds  grabs some necessary data from each of them  and then renders a page based on said data  Id like to move the data fetching / processing part of the app to a server-side node application which outputs one simple JSON file which the frontend app can fetch and easily render 
There are two noteworthy complications for this project:
1) The new backend app will have to live on a different server than its frontend counterpart
2) Some of the feeds change fairly often  so Ill need the backend processing to constantly check for changes (every 5-10 seconds)  Currently with the frontend-only app  the browser fetches the latest versions of the feeds on load  Id like to replicate this behavior as closely as possible
My thought process for solving this took me in two directions:
The first is to setup an express application that uses setTimeout to constantly check for new data to process  This data is then sent as a response to a simple GET request:

I would then run a simple get request from the client (after properly adjusting CORS headers) to get the JSON object 
My questions about this approach are pretty generic: Is this even a good solution to this problem  Will this drive up hosting costs based on processing / client GET requests  Is setTimeout a good way to have a task run repeatedly on the server 
The other solution Im considering would deal with setting up an AWS Lambda that writes the resulting JSON to an s3 bucket  It looks like the minimum interval for scheduling an AWS Lambda function is 1 minute  however  I imagine I could set up 3 or 4 identical Lambda functions and offset them by 10-15 seconds  however that seems so hacky that it makes me physically uncomfortable 
Any suggestions / pointers / solutions would be greatly appreciated  I am not yet a super experienced backend developer  so please ELI5 wherever you deem fit 
"
62448306,"My case:
 1  Iam using lambda for connect to redshirt and SQL query execution
 2  using Sam and cloudformation template for this we application 
 3  Generally these SQL queries taking lot of execution time(i e alredy
    we have optimised queries only)  so by this cost will be more for
    single query execution only
Question:

is there any alternate to lambda  to execute sql to reduce cost 

any suggestions 
thanks

"
55458492,"I have a couple of Lambda functions that require access to other services I have in AWS inside a VPC  So I have added these Lambda functions to the same VPC which makes them lose internet access  
One of the service I need access to is a SQS queue  which is not in the VPC as it doesnt support it 
I found two solutions to my problem:

Create a NAT gateway and allow my function to access the internet
Create a VPC endpoint for SQS

I wanted to go with the latter  When I did that  the Lambda worked fine  but I couldnt deploy new code to my Beanstalk instances  That should have nothing to do with it  I spent hours to realize Beanstalk uses SQS to send messages to my instances to perform the deploy 
Questions:

Is it a better solution to use a VPC endpoint rather than a NAT gateway  (it seems to be cheaper)
If so  how can I keep my Beanstalk instances working correctly 

"
62798957,"I have a AWS Lambda function using an AWS SQS trigger to pull messages  process them with an AWS Comprehend endpoint  and put the output in AWS S3  The AWS Comprehend endpoint has a rate limit which goes up and down throughout the day based off something I can control  The fastest way to process my data  which also optimizes the costs I am paying for the AWS Comprehend endpoint to be up  is to set concurrency high enough that I get throttling errors returned from the api  This however comes with the caveat  that I am paying for more AWS Lambda invocations  the flip side being  that to optimize the costs I am paying for AWS Lambda  I want 0 throttling errors 
Is it possible to set up autoscaling for the concurrency limit of the lambda such that it will increase if it isnt getting any throttling errors  but decrease if it is getting too many 
"
53017599,"Heres my setup:
A Python 3 6 lambda function  which I want to keep pre-warmed at a certain concurrency level (say  10)  The lambdas initialization is painful enough that I dont want to inflict this cost on visitors at random  I call these lambdas workers
A Node lambda function which runs every 5 minutes to try to pre-warm 10 instances  It uses the Event invocation type for 9 of them  and RequestResponse for 1  Theres only either one or zero of this lambda running at any one time  I call this a warmer 
I followed the guidelines at [  namely:

Don’t ping more often than every 5 minutes
Invoke the function directly (i e  don’t use API Gateway to invoke it)
Pass in a test payload that can be identified as such
Create handler logic that replies accordingly without running the whole function

Heres a problem: this works great for several minutes  Then  as I watch the logs  I start to get timeouts from my worker lambda invocations  The timeouts quickly take over all the invocations that the warmer is trying to launch  
Now  no worker lambdas are prewarmed any more  But the warmer keeps on trying  on a Cloudwatch event cron schedule  suffering 100% timeouts  Finally  Lambda stops trying to launch my worker lambdas at all  It feels like some aspect of Lambdas getting its state scrambled  The only way to recover is to re-deploy the lambda  That buys me another hour with pre-warmed lambdas working 
Questions:

How do I get visibility into why my worker lambdas start timing out  and then become completely non-responsive 
What is the definition of a Concurrent Execution  On the main Lambda dashboard it shows me this chart of them  Yet  it seems to have more than twice as many Concurrent Executions as Im requesting 


Heres the warmup lambda code (Node):

And heres the worker lambda (Python):

"
45919464,"I have a case where I want to remove cookie in the request and send the request to another server and display response to the end user 
Example:

Current solution:

I want to remove ec2 instance in the middle as its expensive 
Is any way I can achieve using AWS Resources 
"
44376491,"Lets imagine situation like that:
We have node js app  which is rendering view on server-side and sends html to browser  In generated html we have few static assets (like images  stylesheets etc ) 
Why should I (or not) choose S3 over Lambda to serve this content 
Here are pros &amp; cons which I see:
Performance
I was quite sure that providing content from S3 is much more faster then from Lambda (there is no script which need to be executed)   
   Until I performed some tests (file size ~44kB) average of 10 requests:

API GW + S3: 285ms
API GW + Lambda: 290ms
S3: 135ms

As you can see there is no difference between providing content from Lambda via API GW then from S3  The only significant difference is between direct link to s3 and two previous tests 
Lambda 1 : S3 1
Cost
And here Lambda wins definetely 
First of all we have free triage of 1 000 000 requests 
Second here pricing comes:

S3: $0 004 per 10 000 requests
Lambda: around 0 002000624 per 10 000 requests:

($0 20 per 1 million requests + $0 000000208$ per every 100ms)
So in pricing Lambda wins 
Summarizing
My observations shows that Lambda is better way to serve even static content (speed is similar to S3  and pricing is twice cheaper) 
Is there anything what I am missing 
"
61268446,"We are currently an AWS customer and have developed a few internal serverless apps that integrate with some of our business applications  Many of the functions we developed need to access private resources in our VPC  The userbase is small hence the frequency of function invocation are small and the cost is single digits generally 
We are evaluating moving to Azure  One aspect that I am stuck  is the cost of running similar apps to Azure  There are a number of the question here addressing the limitation of the Consumption Plan ( and ) and the breaking down of  the confusing  cost structure of  needed for VNet (to access private resources)  
The difficulty I have is it appears that our cost jumps from a few dollars to $100+ for similar functionality   Are there alternative ways/designs that can be used without having to resort to Azure Function Premium  Have any experienced similar issue and how did you address them  
"
52683265,"Im thinking to launch an open-source project to develop a serverless CMS working on top of AWS technologies  I want to have DynamoDB as the backend for storing data rather than having a simple markdown CMS  I want to know from the community here if this idea is reasonable and sounds good because Im moderately experienced in AWS and so not fully firm about it and seek some help 
I will be developing the CMS in ASP NET MVC Core served though Lambda  This CMS will have an external API which will be ASP NET MVC Core Web API 
I also need some thoughts on the cost of running this CMS i e  Do you think it will be cheaper to run as against the conventional CMS or if DynamoDB can squeeze a lot of juice   
"
58286081,"Im just learning AWS CDK after playing around with Serverless for a bit 
Serverless has a component to   which uses S3 and CloudFront  It updates an existing CloudFront distribution if it  for the same domain  Presumably the reason why it does this is so you dont have to wait 40 minutes while the CloudFront distribution is set up  I cant think of any other reason for it  e g  it would seem to cost the same 
So how do you search for and re-use an existing CloudFront distribution in CDK  Should you actually just create a new one 
"
48031259,"Firstly Im not sure if my approach is right one 
This is what Im doing  Ive some video processing work to do  for which Im gonna use FFMPEG  And it can take from 1 minute to 20 minutes to do work 
so my questions are: 

are CFs good fit for this  I dont want my main server to do these
tasks 
can i make CF to only time out after say 60 minutes  or before if finished 
Is it going to be cheaper than just using server instead  

From what I know its perfect scenario to use cloud functions  Alternative is to use build queue  wait for available processes to finish and then when time comes finish task 
"
35541780,"What ways do exist for handling http(s) requests using  but without using  or    Is it possible at all 
Particular I want implement my own REST API but do not pay for  service  using only  
Im not asking for tutorial or library  this is principal about  architecture 
This all is about  runtime 
"
44320564,"AWS Lambda seems nice for running stress tests  
I understand that is it should be able scale up to 1000 instances  and you are charged by 0 1s rather than per hour  which is handy for short stress tests  On the other hand  automatically scaling up gives you even less control over costs than EC2   For development having explicit budget would be nice  I understand that Amazon doesnt allow for explicit budgets since they can bring down websites in their moment of fame  However  for development having explicit budget would be nice 
Is there a workaround  or best practices for managing cost of AWS Lambda services during development  (For example  reducing the maximum time per request)
"
48054733,"Very interested in getting hands-on with  in 2018  Already looking to implement usage of  in several decentralized app projects  However  I dont yet understand how you can prevent abuse of your endpoint from a 3rd-party app (perhaps even a competitor)  from driving up your usage costs  
Im not talking about a DDoS  or where all the traffic is coming from a single IP  which can happen on any network  but specifically having a 3rd-party apps customers directly make the REST calls  which cause your usage costs to rise  because their app is piggy-backing on your open endpoints 
For example:
I wish to create an endpoint on AWS Lambda to give me the  What would prevent another (or every) dapp developer from using MY lambda endpoint and causing excessive billing charges to my account 
"
54242090,"I have a CodePipeline build running in AWS  and everything works great  except theres no good notification mechanism directly from within CodePipeline   Digging around  it seems that the accepted solution for this is to configure CloudWatch to call Lambda or SNS to send off your message 
OK  so I built a small Java program to send a message to Slack based on CloudWatch CodePipeline events   It works well  except that every single message is repeated a half dozen times or more   This seems different from all the other posts Ive read around duplicated Lambda executions where you get an occasional duplicate here or there 
I know the standard answer is that Lambda wants to ensure delivery  so events may be retried  which is fine - if every 20 or 100 messages I got a duplicate  Id be fine   But I cant flood a Slack channel with 50+ messages for every simple CP run   Not to mention I assume Im getting billed for every one of those Lambda executions  when really I should only be getting 4 per run 
I dont want to have to set up a DB to track unique IDs - again thats adding both complexity and cost (the executions still happen)   It feels like something is mis-configured   E g  Is there a reason CloudWatch would be picking up the same message and forwarding it to Lambda for some reason   Or a reason that Lambda would think the execution needs to be retried even though it exits successfully 
"
61421777,"I am using Serverless and DynamoDB and am relatively new to it  My app has a table called Trips  The parameters of the tables are {id  route  cost  selling  type  date  LR  asset } and a bunch of other irrelevant document numbers  where id is generated by uuid 
According to this guide for ordering data in a date range (see 5th row in the table at the end)  I have added a parameter called  which is a random integer from 1 to 20 sent by frontend and made a  with  as createdAT and  as  
I ran 20 promises concurrently for keeping createdAt from 1 to 20   I am simply combining all the results in one object like this 

Here is the response

Serverless yml for tripsTable

But the issue is the entry on 2020/04/01 and 2020/04/24 have the same createdAt parameter  hence after combining all array results the final result is not ordered by date 
Do I need to sort this list again or am i missing something here  If I need to sort it again wont it become much more inefficient 
"
53219978,"Let say someone is brute forcing my EC2 website and i block that ip address using my EC2 ubuntu firewall and now if that user from that ip would access my website it will show 400 BAD REQUEST 
So my question is that will amazon charge me for this 400 BAD Request as amazon charges you for each request sent out of your instance 
"
58951709,"Hey I am getting started with the serverless framework  apigateway  lambdas and authorizers 
Here my questions:

In order to verify a proper JWT token (which seems nowadays the best solution for serverless authentication)  I would need a client id  Since the authorizer lambda is not capable( ) of reaching any other parameters of the request into the lambda except for the token itself  this is a difficult task to do  How can I achieve this 
Since with every authenticated call  an additional lambda is called  my costs are doubled   May be I am misunderstanding something here  but it seems to me like implementing a method for verifying my token without using the authorizer is cheaper and I dont need to implement the authorizer lambda itself 

"
46168826,"I am using the serverless framework with nodejs(Version 4 4) to create AWS lambda functions  The default timeout is 6 seconds for lambda execution  I am connecting to mysql database using sequelize ORM  I see errors like execution timed out  Sometimes my code works properly even with this error  But sometimes nothing works after this timeout error  Its really hard for me make sense out of this timeout   I am afraid increasing the timeout will incur more charge 
"
57083043,"I am trying to get the cost of the previous day using cost explorer while using  and   But I get and error 

 errorMessage: An error occurred (ValidationException) when
  calling the GetCostAndUsage operation:  and the error type is
  ClientError 

I have specified the region to   Also my policy is 

My Code is below 

"
58295709,"Disclaimer: newbie in aws arena
I have an endpoint that send message to an sqs queue to process order  once process order is done it forward that message to another queue to process payment 
I successfully send my message to first queue to process order  and that also prints success message saying message has been forward to process payment queue  however  I cannot see any logs printing in the cloudwatch logs 
I have created a serverless yml file for process order repo 

Looking forward for your expert opinion please 
regard
"
56843940,"I am creating a MVP(Minimum Viable Product) that has a nodejs server using express for a rest api and a socket io connection for chat features  
My concern is not so much about cost or scalability  but about setup time/maintenance as this is an MVP  Would serverless or not serverless take less time to setup/maintain on AWS 
"
65623434,"I need to know how can I run docker image in aws one time on some event(file upload) 
For example:
I uploaded files to S3 and then I need to run my docker image one time  I know that I can do something like that with ESC tasks  but in this case I will have constantly running EC2  its too expensive 
How to run docker image once on every file upload and shutdown it after its running 
P S  docker image should have at least 8GB memory for working
"
63929609,"Im trying to build a small site that gets its data from a database (currently I use Firebases Cloud Firestore) 
Ive build it using next js and thought to host it on vercel  It looks very nice and was working well 
However  the site needs to handle ~1000 small documents - serve  search  and rarely update  In order to reduce calls to the database on every request  which is costly both in time  and in database pricing  I thought it would be better if the server could get the full list of item when it starts (or on the first request)  and then hold them in memory and make data request get the data from its memory 
It worked well in the local dev server  but when I deployed it to   it didnt work  It seems   where each request is separate  and I cant use a common in-memory cache to get the data 
Am I missing something and there is a way to achieve something like that with  on  
If not  can you recommend other free cloud services that can provide what Im looking for 
"
59026283,"Generalities
I am working in a Lambda authenticator  I have several modules and require a unique authenticator  This means that a client sends a user and password and a custom authenticator returns a JWT  Then another endpoint is called  the JWT is validated and the request forwarded to the final endpoint  
Whats working
The JWT generation is ok and I have a custom authenticator working on lambda which validates the JWT  
The problem
I am using serverless framework  and I cant find how to implement a http integration  If I use the console I just select my custom authenticator and pick http from the integration  and I am done  The request is received  validated using the custom authenticator and forwarded to an external endpoint  
How can I do this in serverless  I have this config 

It obviously do not do what I expect  A lambda handler hello is called after the custom authenticator is done  I dont want to call the external endpoint inside the lambda since it will cost every time  I just want to use an http integration as the one in the console to call another endpoint  Is this possible 
"
36962722,"Im using Lambda and S3 in conjunction with Amazons Skills Kit  The Lambda is running Node js and referencing audio files which I use SSML for playback on Alexa commands  However  since I get charged for GET requests  Id like to limit the requests to just the servers requesting specifically from Alexa  Although I can set an IAM user to restrict access  I think Ill get an access denied response when trying to play back from Alexa  Can I restrict playback based on a known Alexa IP  It appears that the IAM information isnt passed through regular HTTP requests to S3 GETs  
"
37931010,"Is scheduling a lambda function to get called every 20 mins with CloudWatch the best way to get rid of lambda cold start times  (not completely get rid of)    
Will this get pricey or is there something I am missing because I have it set up right now and I think it is working  
Before my cold start time would be like 10 seconds and every subsequent call would complete in like 80 ms  Now every call no matter how frequent is around 80 ms  Is this a good method until say your userbase grows  then you can turn this off  
My second option is just using beanstalk and having a server running 24/7 but that sounds expensive so I dont prefer it 
"
55454539,"While learning the Serverless Framework I came across several tutorials showing how to run an Express instance in a Lambda  This seems to me like an overkill and against the purpose of Lambda functions 
The approach usually involves running an Express instance in the Lambda and proxying API Gateway requests to the Express router for internal handling 
To me the trivial approach is to just create an API in API Gateway and route individual requests to a Lambda for handling  Am I missing something 
Taking into account that Lambdas execution time is 15 minutes  isnt just spinning up the Express instance quite expensive in terms of memory  Also  limited to 100 concurrent Lambda executions would create a bottleneck  no  Wouldnt an EC2 instance be a better fit in such case  Using a Lambda like this seems like an overkill 
The only two benefits I see in running an Express instance in a Lambda are:

In the case of migration of an existing app written in Express  allows to slowly break down the app into API Gateway endpoints 
Internal handling of routing rather than relying on the API Gateway request/response model (proxying to Express router) 

What would be the benefit of such approach  in case I am missing something 
Some resources promoting this approach:





"
53823944,"I have a serverless application deployed using AWS Lambda  Im using java8 as my language as I am also using Dagger for DI  One of the dependencies Im calling has multiple endpoints I can use (It has the concept of multiple endpoints to ensure availability)  
Now  this application needs to call the downstream service with the endpoint which is geographically close  I have a method which returns me the closest endpoint based on geographic distance  Im trying to understand how I can get the Dagger module to refresh periodically so that its able to redirect it to the correct endpoint   I have some relevant code below to illustrate the use case  

Now  Im trying to understand as to how this endpointURL can dynamically be generated  My confusion here is with the fact that since the Dagger provider isnt invoked on every API call/request  it would choose the same endpoint  I looked into the idea of instantiating the client inside my actual business logic and that seemed too expensive  
Im trying to understand if theres a way by which we can force the Dagger module to refreshed periodically of some sort  Is that a possibility  
"
32274228,"I have lambda function and dynamo db table in the same region (us-east-1)  In lambda function I perform very simple query:

There are only few rows in DynamoDB table  there is Hash Key on email and Read/Write throughtputs are set to 5/5 
Lambda function exeutes in ~4 seconds    This is very slow  Am I doing something wrong 

Ive tested my function with different memory settings for lambda function (it was set to 128mb previously):

256mb =&gt; ~2000ms
512mb =&gt; ~1000ms
1024mb =&gt; ~500ms
1536mb =&gt; ~300ms

So it seems that response time depends 1-1 on memory (well in fact on compute capacity as AWS scales it along with memory)  Still this is crazy because to make very simple REST API I have to set 1536mb memory to make it responsive while my program uses 17mb 

Hmm on the other hand Ive calculated that it will cost:

8 32$ per 1 milion 4000ms requests using 128mb memory
10 004$ per 1 milion 300ms requests using 1536mb memory

So its not so bad I guess   
"
48660663,"Im using  3 9 to make a  call in an Android app to update an  by triggering a Lambda function via an Api Gateway  I notice that the database is updated 3 times with each call  Apparently this is due to the default retry option for OkHttp  
As I understand it  the retries can be prevented by setting retryOnConnectionFailure to false when building the client I tried this but still the database is updated 3 times - so the call is still being made 3 times 
Some suggest to handle this behaviour on my server  The problem is that if I handle the issue in the Lambda function  then it means that the api has been called three times and so has the lambda function  all unecessary overhead and cost  Also  if setting retryOnConnectionFailure to false worked and the api was only called once  it means that there is no mechanism to handle failure 
So  why does it retry 3 times even when each call succeeds  and most importantly  how do I stop this from happening so that the api is only called once and then again only if the call failed (i e to succeed in triggering the lambda function)  Setting  to  seems to have no effect 
"
62585130,"I am creating a CI/CD pipeline using AWS codepipeline to deploy several lambda functions  Currently I am manually uploading  zip files for the lambdas functions which include a configuration json file that has credentials to access the RDS database 
I have already created a SAM template to deploy the lambda functions via codepipeline  however  I am unable to think of a solution to provide RDS database credentials to the lambda functions since commiting the configuration json file in the code repository is not an option 
AWS secrets manager is NOT an option for me as it would be very costly due to millions of API calls hitting the lambda functions 
"
52298332,"Im a developer on a startup and right now we are using around 30 cronjobs  some of them run each minute  others run once per day while other run on specific days  The problem are the ones that run every minute  when most of the time is not necessary 
This somewhat increases our expenses because during the night  they still run when most of the times our services have nobody online (and dont require to be run) 
We have been talking about using AWS to replace those cronjobs into something like event based  Yet  I cannot find a solution  Heres an example of one of our cronjobs:

One costumer starts to make a registration and has 8 minutes to complete it  Right now  we have a cronjob that runs every minute to validate if he completed  and if not  to delete it 

I though I could replace this with a SNS + Lambda event  Basically  when an user starts registration  send an message to SNS  that would triger a lambda function  Yet  it could only run after 8 minutes  and not instantly 
Ive seen on SNS that we can delay up to 15 minutes  but we got some other service that sends an email after few hours  which would not work
Anyone have a clue on how can I do it 
Thanks
"
59057565,"Id like to have a lambda expression that every hour makes a query on RDS database  pull some ARN (device tokens) and then sends these devices a notification via SNS  My desire is to remain inside the VPC and Id like to avoid using NAT due to its cost  Should i create a VPC endpoint (is this called AWS PrivateLink ) that can reach out SNS+RDS  Is NAT and Endpoint similar in billing  Globally is this the right way to achieve a cron sending notifications on AWS  
RDS is reachable inside the VPC without the endpoint isnt it 
"
47536542,"Im encountering some problems using Serverless framework  since i accidentally used the same name of a service on another one  

Lets suppose that i have two serverless yml files  both with the same name of service  One of them (lets call it  test1) have resources (DynamoDB tables)  the other hasnt (test2)  Like the following snippets:
Test1

Test2

When i  the test1  he creates the tables as i wanted  with   for the tables with very sensible data  Then i  test2 that has other functions but doesnt have any resources (DynamoDB tables)  he does what is expected: skip the deletion of the tables  
But  when i sls deploy test1 again  he doesnt recognizes the tables  he starts to create existing tables rather than update them  and fails to deploy 
I need the tables that arent deleted  and need the functions on the service  It looks like the Cloud Formation losted the track of the created tables from the first deploy 
I dont whant to separate the services (one only for the resources) like was said on this  
I need the tables that are running  it has a lot of data and its too much expensive to backup and restore it to another one  a lot of users could be affected 
So  how do i tell to Cloud Formation Stack that im updating that table  and not trying to create it  How to keep track of a service on the Cloud Formation Stack  And  how do i prevent to deploy a service with resources without them  
Whats the best solution for this case  Hope that my questions are clear enough to understand  
"
57554595,"I Have AWS Environment where we are giving a training session to students there we want to restrict the large type of Resources Launching like Ec2 and other AWS services 
Is there any IAM roles or any Policy Script in order to avoid unauthorized and cost-saving 
PLS advise 
"
58079600,"I am using Visual Studio code for debugging a lamda function written in python  
Is the local execution of the lamda function is chargeable   since at the end of each execution we are getting an entry in the log showing execution time charged 
Please note we are calling some AWS api from within the lamda function  and that is understandably chargable  I have no issues with that 
"
44760307,"Im new to AWS  so apologies in advance if this question is missing some important considerations  or has incorrect assumptions 
But basically I want to implement a service on AWS to store and retrieve data from multiple clients  which may be Android apps  Windows applications  websites etc  The way Ive considered doing this is via a RESTful service using API Gateway front end  with a Lambda back end and maybe an S3 bucket to hold the data 
The basic requirements are:
(1) Clients can publish data to the server  where it is stored  perhaps with some kind of key/value structure 
(2) Clients can retrieve said data by key 
(3) If it is possible  clients to be able to subscribe to events from the service  so that they are notified if the value of a piece of data changes  This would avoid the need to poll the service  which would presumably start racking up unnecessary charges if the data doesnt change often 
Any pointers on how to get started with this welcome 
"
44456814,"I implemeted a code that deletes multiple records in a table and when that deletion is completed then goes to another table to delete its record  But the thing is I am not deleting all records of a table just making query to some of the records that have range key (id = 1423) and all records related to this key I get and using foreach loop I then delete the records  Same I am doing in other table as well 
KeyPoints about my code : In both table id is not the primary key and also in both Table A and Table B I have this same id = 1423 
Code snippet :

I am calling this data function in other two files just passing different table name in the parameters  i e   here : function(tableName  id) and id is same  Also wanted to know that are there any loopholes in asynchronous way and is it better than synchronous method that I am using  Any performance issue or operation cost 
"
54805578,"I have an application which needs to read data from AWS dynamodb table every 5 seconds 
Currently I fetch the data using lambda  and then getting the data from dynamodb back to the user  
The problem with querying the table every 5 seconds is that it can have performance affect and moreover there is a pricing issue  (Most of the time the data might not even be changed at all but when it is changed I want to be notified it immediately) 
An important clarification is that my app sits outsite of AWS  and only access the AWS dynamodb to get data (using simple http request built with c#) 
Is there any way I can get a notification to my app when a new data is inserted into dynamodb  
"
43256240,"For a project Im working on  there is a need to pull down a largish text file thats updated daily and made available at a specific customer URL  and store it in AWS S3 which then triggers downstream processing of the file (details unimportant)  
I was thinking of having the download + store in S3 done by an AWS Lambda triggered every 24 hours by CloudWatch  which would work  but theres a catch: the file is 36MB in size and is served by a host that throttles downloads to 100kB/s (outside of my control)  This means it takes at least 360s (i e  6 mins) to completely download the file  AWS Lambda functions however have an upper limit of 300s run time  which effectively makes it impossible to use for this task as the Lambda times-out and exits before the file is completely downloaded 
Im looking for suggestions of ways of working around the 300s run time limit of AWS Lambda to achieve this goal 
As long as Im sticking to AWS  the only alternative I see is to set up a cron job on an EC2 instance  but that seems expensive / overkill  especially if I end up not needing an always-on EC2 for anything else 
Thanks 
"
38673310,"I have an  function that makes use of an  cluster 
Since the  cluster is locked in a   the  function must reside in that  too 
For some reason  if the  is allocated an  of a   which has an  - it still cannot make connections to the outside (the internet)  thus making it impossible to use  
For that  they suggest using a  gateway which lets the  connect to the outside 
Basically  this works for me - but my issue is the money 
This solution is expensive for large amount of data transfers and Im looking for some way to make it cheaper 
For a small  that Ive made  I paid  

This is too much for  as my production pipeline will run hundreds of  / month 
How do you suggest I let the  function connect the outside (specifically ) without using a  gateway 
Thank you 
"
57224135,"I have a serverless app running as google cloud function triggered by bucket object finalize 
at the end of the function logic I want to call another action (also function) after exactly one minute (or T time) 
currently couldnt come up with any way to call another action in one minute and had to use sleep in my app 
the problem with sleep is that I have 60 seconds that the cloud function cost money while no real work is being done 
any suggestion on how to execute something from cloud function in T time  so I can just exit from function and save money 
keeping in mind I would like to keep it serverless and using GCP 
"
69395747,"Suppose I have some resources that I want to share between different requests in an aws lambda written in python  How should I implement this 
Are there hooks for post startup  or should I lazily create resources on the first call  The disadvantage of lazy inititializing is that it means some requests will be randomly slow because you pick a consumer to incur the startup cost 
Also    will those resources survive a lambda executable being frozen 
This page  talks about an Init stage  How do I execute things in the init stage  This seems to suggest that Init includes both an unfreeze operation and a freeze operation 
Research

"
59984990,"What is a shadow launch 
Shadow launch means that you launch the new version but it not yet gets live traffic  The traffic of the old version gets 1:1 copied into the the new one and so you can measure the performance and results of the new function against the old one without influencing the live system 
Tried approach
I already tried building something like that myself with a Proxy function that async calls the new function and dumps the results and sync calls the old one returning its results  
The problem are side effects: If both functions do something e g  in DynamoDB there could be an invalid state in the DB because of the shadow launch 
Goal
I want to test new code versions of a particular lambda function  
Intended usage Example
I have a function that calculates Fibbonacci  and stores the result with a timestamp in DynamoDB in my live system  
This function is called via  as one in a chain of many 
As it should be more efficient to calculate it  I implement the function with this new algorithm  
Now I want to test the assumption that the new function is more performant than the old one 
So I shadow deploy it AWS lambda to get the actually live traffic as testing data 
Problem
With the current tooling I found it is only possible to execute the function twice and thereby create two entries in DynamoDB which I consider an unwanted side effect as my data in the DynamoDB is in an unintended invalid state 
If I mock the external services in the new function  it may always be more performant than the old one as the time-expensive external services are not access and thereby my result would be incorrect 
Question
Is it possible to shadow launch a new version of an AWS lambda function without these side effects  
"
69497476,"Im using S3 Batch Operations to invoke a lambda to load a bunch of data into elasticsearch  Reserved concurrency is set to 1 on the lambda while experimenting with the right amount of concurrency 
Strangely when testing I see S3 calls the lambda a few times back-to-back  and then makes no more invocations for about 5 minutes  For example:

Any ideas how to avoid this delay  There are no other batch operations happening on the account and priority is set to 10  Maybe it has something to do with the reserved concurrency value  Although according to the :

When the job runs  Amazon S3 starts multiple function instances to process the Amazon S3 objects in parallel  up to the concurrency limit of the function  Amazon S3 limits the initial ramp-up of instances to avoid excess cost for smaller jobs 

Thank you
"
47837082,"Im implementing a webhooks provider and trying to solve some problems while minimizing the added complexity to my system:

Not blocking processing of the API call that triggered the event while calling all the hooks so the response to that call will not be delayed
Not making a flood of calls to my listeners if some client is quickly calling my APIs that trigger hooks (i e  wait a couple seconds and throw away any earlier calls if duplicates come in later)

My environment is Python (Chalice) and AWS Lambda  Ideal solution will be easy to integrate and cheap 
"
60327663,"Apologies for the long read  but I have only included the relevant parts necessary  I have inherited some code and CloudFormation scripts for a project and the previous developer left a cryptic note:

You must update the trailing date on the following items in app-deploy cfn yaml to get changes to take effect 

Hes long gone and not somewhere I can ask him about his instructions  Here are the items that must be updated:

Honestly  this seems way out of the ordinary  It looks like he is applying cache-busting techniques to the API Gateway  This  to my knowledge  should not ever have to happen 
Boy was I wrong  
I recently needed to make one simple change to an SNS Subscription  adding only  as a source for a particular Lambda subscription  Here is that resource with the new source added:

I deployed the scripts and witnessed the updates take place  I checked the console for the proper JSON  revealing this:

All good  I should be good to go  but when I sent the proper message to test the source I got an error message:

@message
  2020-02-14 19:11:02 &lt;071acec7-096b-4c45-996a-5ed996df7c23&gt; ERROR AbstractEventHandler:66 - java lang IllegalArgumentException: Unable to process message  Invalid format 

And in my UI

Checking the CloudWatch Logs I can see the request being properly made with that source:

@message
  2020-02-14 19:13:41  INFO BHIEventHandler:23 - BHI Handler Received: {[{sns: {messageAttributes: {domain={type: String value: payments}  source={type: String value: redirect}  type={type: String value: payment approved}  brand_id={type: String value: 40}}      


Suddenly I recalled the cryptic message from the previous developer  but I could not see how that would apply to make a change to SNS  especially since that update appeared to be deployed to AWS properly  Another developer who I was discussing this with said  You could just prove old Bruce wrong by trying it  youve got nothing to lose at this point and we can eliminate that as a distraction 
Off we go  we change the dates assigned/appended/tagged to the API resources and redeploy  I see the updates in the console  CodePipeline reports the deployment has been completed successfully  We send the test   
   and the dang thing worked 
My Question
Why does making a change to a completely (apparently) unrelated portion of CF make this work  Have we done something wrong  If so  how do I correct this 
By request
Here is the complete template:

"
59290512,"How can I prevent Denial of Wallet attacks against AWS Cloudfront 
Heres my specific situation: I have a Cloudfront distribution where Lambda@Edge functions serve web pages and API requests for my application  I need to rate-limit requests made to Cloudfront based on the IP address of the user  Without any kind of rate-limiting in place  its possible for a malicious user to make millions of slow requests to the distribution that wouldnt be blocked by AWSs DDOS protections and which would lead to significant charges  This is especially important here since Lambda@Edge functions cost 3x as much as ordinary Lambda functions and dont come with a free tier 
It seemed practical to use AWS WAF in order to accomplish this  However  I  that WAF charges for all incoming requests  regardless of if they are blocked or not  So a Denial of Wallet attack would still be possible here 
Is there a method or a general strategy that I can implement here that doesnt involve AWS WAF   
The limits need to be very tight  Even paying $50 per month for malicious requests would be considered too high 
"
66651066,"I am deploying an application where I am using a NAT gateway with a lambda inside a private subnet to talk to other AWS services outside the vpc  Everything is working fine but the NAT gateway adds alot of extra costs to the billing  I am assuming if I can replace the NAT gateway and use and interface vpc endpoint instead 
"
54077437,"I am experiencing unexpected spikes in timeouts for an AWS Lambda function  The function is called ~7 million times per day - with a constant numbers of calls occurring every 5 minutes  The spikes I see are usually ~1 000 function timeouts within a half hour period  The rest of the day there are generally no timeouts 
Here is an example day with timeouts counted on the y-axis 

The timeout setting on the function is 30 seconds  The function has an average runtime of ~50ms and an expected maximum runtime of ~5 seconds for large input  The function uses the Python3 6 runtime and does not utilize the ENI/VPC Lambda feature  thus cold starts generally only take a couple of seconds 
In order to investigate the timeouts  I dug through the CloudWatch logs while the timeouts were occurring  There were no log messages or exceptions from the timed-out invocations  just the message:   
Originally the function ran in a single thread  so I assumed the code might be hanging somewhere and failing to log  I attempted to add more information to the logs by modifying the function to operate like this:

I tested this functioned correctly by adding sleeps in  and confirming that the function did   However  during the actual timeouts  was never reached  
From this experiment I concluded that the timed-out Lambda invocation was never reaching my code  Due to the spiking nature of the timeouts  I have a suspicion that one of the Lambda microVMs running my function is getting into a bad state  and is unable to process requests for a period before it is recycled  
Question:

Does this theory hold water 
Are there other possible causes I may have overlooked 
Has anyone experienced anything similar 

Other details:

The functions is invoked directly with a SigV4 signed request
I use the  library to process requests 
There are a few large binary files that Python interacts with on every execution through SWIG
The function does not interact with any external resources

Note: I am reluctant to add comprehensive logging for all calls due to the cost of CloudWatch  
"
69234620,"After paying many thousands to AWS due to small programmers mistake I have a question 
How can I set an action which will suspend the whole account activity after budget alarm happened  For me it seems insane that customer isnt allowed to do such thing easily  We had alarm set up but it was weekend and nobody reacted on it 
We were compensated only 5k(its a small part of the whole bill) 
"
53027549,"I am trying to enable Paytm as my payment gateway in the ecommerce website I am creating using  
When I enable the Paytm component in the IDE  I can see the following in my kitsune-settings json file (the preview section)

Where do I find the right values for API_SECRET and API_KEY  
"
36627575,"AWS Lambda functions are supposed to respond quickly to events  I would like to create a function that fires off a quick request to a slow API  and then terminates without waiting for a response  Later  when a response comes back  I would like a different Lambda function to handle the response  I know this sounds kind of crazy  when you think about what AWS would have to do to hang on to an open connection from one Lambda function and then send the response to another  but this seems to be very much in the spirit of how Lambda was designed to be used 
Ideas:

Send messages to an SQS queue that represent a request to be made  Have some kind of message/HTTP proxy type service on an EC2 / EB cluster listen to the queue and actually make the HTTP requests  It would put response objects on another queue  tagged to identify the associated request  if necessary  This feels like a lot of complexity for something that would be trivial for a traditional service 
Just live with it  Lambda functions are allowed to run for 60 seconds  and these API calls that I make dont generally take longer than 10 seconds  Not sure how costly it would to have LFs spend 95% of their running time waiting on a response  but waiting isnt what LFs are for 
Dont use Lambda for anything that interacts with 3rd party APIs that arent lightning fast :( That is what most of my projects do these days  though 

"
59661316,"I can choose to pay more to have dedicated AWS EC2 instances so that my VMs are physically isolated from other peoples instances 
However  using EC2 also means I bear the responsibility of maintenance  either through automation or not 
So I would like to use things like Fargate and Lambda  which removes the maintenance burden from me 
Is possible to still have the same level of hardware isolation 
Can I require Amazon to run my Lambda functions and Fargate containers in a physically isolated fashion 
"
60490004,"I need to create a AWS Bucket Policy which blocks all external IP addresses  except our office IP  but still allows Lambda functions to access the Bucket 
I know how to make this work using a AWS VPC and NAT  however due to the high costs involved the client doesnt want to activate those 
So far this how my bucket policy looks like  but its not working:

}
Ive think I read all of AWS documentation I could find related to this  but I couldnt find what I was looking for  It might be because their docs  are so confusing and do not cover all the functionality  And I have also searched for solutions here on StackOverflow and other forums but nothing worked 
"
53950399,"I have a multi-endpoint webservice written in Flask and running on API Gateway and Lambda thanks to  
I have a second  very tiny  lambda  written in Node  that periodically hits one of the webservice endpoints  I do this by configuring the little lambda to have Internet access then use Nodes  with these options:

and this works beautifully  But now I am wondering whether I should instead make the little lambda invoke the API endpoint directly using the AWS SDK  I have seen other S O  questions on invoking lambdas from lambdas but I did not see any examples where the target lambda was a multi-endpoint webservice  All the examples I found used  and then called  with params 
Is there a way to pass  say  an event to the target lambda which contained the path of the specific endpoint I want to call  (and the auth headers  etc )  * * * * OR * * * * is this just a really dumb idea  given that I have working code already  My thinking is that a direct SDK lambda invocation might (is this true ) bypass API Gateway and be cheaper  BUT  hitting the endpoint directly via API Gateway is better for logging  And since the periodic lambda runs once a day  its probably free anyway 
If what I have now is best  thats a fine answer  A lambda invocation answer would be cool too  since Ive not been able to find a good example in which the target lambda had multiple https endpoints 
"
57569095,"I have a lambda function that gets triggered every time a file is written onto an S3 bucket  My understanding is that every time a single file gets in (this is a potential scenario  rather than having a batch of files being sent)  an API call is fired up and that means that I am charged  My question is: can I batch multiple files so that each API calls will only be called if  for example  I have a batch of 10 files  Is this a good practice  I should not be in the position of having a processing time greater than 15 minutes  so the use of the lambda is still fine  
Thank you
"
69443194,"I set up ALB + Lambda target group and while testing it  I noticed there was a constant flow of requests seemingly from crawlers / bots  The endpoint was not used in any webpages or backend services 
Questions

Is that expected / normal 
What is the recommended way to filter them out 
Since these requests are triggering ALB and also Lambda  it incurs extra cost to us  Is there anything we can do about it 

This histogram shows the number of requests I got 

For example 
1

2

3

"
44424314,"I am creating an iOS app that will query my database without doing any object manipulation or calculation  I can do this in several ways:

Query directly using DynamoDB iOS SDK
Query using AWS Lambda iOS SDK  and then executing a lambda function that queries DynamoDB directly 

My question is  which is more execution-time and cost efficient 
My thoughts are that option 1 is the best as it does not require a function or any execution time 
I know that I am charged for the DynamoDB query and I know that I am charged for the execution time of the lambda function  However  I am not sure if I will be charged for using the DynamoDB SDK method or for something else or if I might forgetting another possible cost or thing that I am not taking into account 
Thank you 
"
54114957,"I am integrating a payment solution which uses web hooks  The payment provider is given the Cognito userid (or user sub) during checkout  Upon successful checkout  the payment provider calls a web hook which Ive implemented using AWS Lambda/Gateway and Python  Within this web hook I get the payment status and the Cognito user id 
What Id like to do next is update or set an attribute on the given Cognito user id for the subscription status  
Ive found pieces of JavaScript code which seem like they get me sort of there but I am missing something from how this should work  Here is the JS code I found to search for a user:

I need a Python version of the above    also I am not quite sure how to initialize the AWS CognitoIdentityServiceProvider in order to do the search  It seems like I need to have an IAM credentials set up in order to search a user identity pool  no  
Any pointers on how to search for a user in a Cognito identity pool using Python would be appreciated 
"
59975071,"I have attached an Appsync pipeline resolver to a field called  in my  object  The idea is that if an organisations last pay day has passed  I want to fetch the payment status from an external API using a Lambda function  If the pay day has not passed  I do not want to invoke the function but simply return a OK 
Is there any way I can conditionally invoke a Lambda function  Something like this:

If I run this  Appsync complains about  attribute missing when the condition is not met  I have also noted that the  attribute which exists for queries is not available for Lambda datasources 
Thank you in advance &lt;3
"
54357901,"We have a number of (micro) services  some as simple as a single lambda function  and some are full RDS apps   One thing that they all need to do is access an foreign ID key mapping   That is  they all are passed a certain type of ID  but need to included the name field associated with that ID in their responses   Basically  just a key/value store 
I could build a separate microservice to manage these mappings (and maybe still will)  but that also needs the simple database 
My services dont usually get a huge amount of throughput  but I need them to be performant 
Id like to keep it cheap  and Id like it to be as low maintenance as possible 
Basically  Id like something Serverless (i e  doesnt require an ongoing EC2 instance or RDS instance running)  fast  and straightforward to access 
Ive thought about just having each key be an S3 key  with the value being the object  but thats not super performant when I need to access a bunch at a time  (should I look into redshift spectrum  is that way overkill   does it matter if is )
I know AWS used to offer simpledb  which is probably basically what Im after   So what would be closest now 
Thanks for your advice 
"
36157907,"At the moment we are running our application on an AWS Beanstalk but are trying to determine the suitablilty of Azure 
Our biggest issue is the amount of wasted CPU time we are paying for but not using  We are running on t2 small instances as these have the min amount of RAM we need but we never use even the base amount of CPU time allotted  (20% for a t2 small ) We need lots of CPU power during short bursts of the day and bringing more instances on line in advance of this is the only way we can handle it 
AWS Lambda looks a good solution for us but we have dependencies on Windows components like SAPI so we have to run inside of Windows VMs 
Looking at Azure cloud services we thought using a Web role would be best fit for our app but it seems a Web role is nothing more than a Win 2012 VM with IIS enabled  So as the app scales it just brings on more of these VMs which is exactly what we have at the moment  Does Azure have a service similar to Lambda where you just pay for the CPU processing time you use  
The reason for our inefficient use of CPU resources is that our speech generation app uses lost of 3rd party voices but can only run single threaded when calling into SAPI because the voice engine is prone to crashing when multithreading   We have no control over this voice engine  It must have access to a system registry and Windows SAPI so the ideal solution is to somehow wrap all dependencies is a package and deploy this onto Azure and then kick off multiple instances of this   What this is I have no Idea
"
52903482,"Ive enjoyed working with  a lot lately  its code generation for GraphQL queries based on defined schema is outstanding 
I came across one complication for defining custom logic / validation server-side  Out of the bag  (part responsible for GraphQL api in Amplify) generates resolvers and DynamoDB tables for your schema  Resolvers are created using  templating language and if you are new to it  its a bit of a learning curve in my opinion 
Furthermore  these resolvers are auto generated by Amplify cli  Im not sure if editing them makes sense either in AppSync console or locally  as every time we push api changes they will be auto generated again 
To add to this  these resolvers that are auto generated actually achieve a lot in terms of linking type models together  enabling search and authentication checks  I really dont want to touch them since development velocity enabled by automatic generation is insane 
Hence only other solution to introduce my custom logic seems to be Lambda functions that listen for create / update events of associated DynamoDB tables 
I think I can set this up in a way thats demonstrated below  essentially allowing users to use GraphQL api normally and when action that requires server validation is made react to it in lambda 
For example player adds item to their inventory  we fire lambda function to check if player had this item before  if not it was purchased  we validate item data and subtract gold of its cost from player table  I think this works fine but my concerns are

We allow to write unvalidated data to database first (although it is validated by graphql type system and auth check prior )
Additional costs for involving Lambda (in my opinion worth it for time saving and ability to use NodeJS instead of Apache Velocity to define language)

Am I missing something else 

So lambda will do validation behind the scenes  we assume majority of users are good actors here and data they pass to GraphQL api is correct since they use our client 
In case data is unexpected (bad actor) lambda will react and ban the user 
Is this solution viable / common  is there other alternative 
"
55227785,"Im processing relatively large images using AWS Lambda ()  
In order to process these images  I split them into smaller images (~1500 chips) which can be processed independently (the number of chips varies unpredictably depending on the content of the source image)  Chips are processed in parallel using multiple invocations of a Lambda that takes in a page of a couple of hundred chips  
Heres where Im stuck: when all pages have been processed  I need to combine results into a single output image  but how to know when all pages - the variable batch of invocations - are complete 
Ive considered e g  writing progress information to s3 or dynamo and invoking the combining function after every page so that only the last invocation of that function goes ahead (when a progress check returns as complete)  Ive seen options like futures/promises  but the processing time of a page of chips is of the order of 10-15 minutes so I dont want to keep a controller function waiting for the futures/promises to complete  because at that point its cheaper to go with multiple invocations 
Is there a better solution that writing out progress information and checking it multiple times 
(NB Ive seen this question: )
"
54294795,"Is there a way to make a python aws-lambda on a local machine which can read and write data from an S3 bucket  I can get this to run on a lambda in AWSs web-page with the following code with no problems 

The issue is that this is a terrible environment to write and debug code so I would like to do it on my own local machine  I have set up AWS-CLI and installed an app that lets you run lambda code in a local environment called python-lambda-local  as shown  

The file pythonLambdaLocalTest py contains the same code that I ran on AWS from the console - the advantage here is that I can use an IDE such as visual studio code to write it  If I run it without calling get_data_from_s3_file then the code seems to run fine on the local machine and cur_day is printed to the console  However  if I run the full script and try to connect to the bucket then I get the following error:

Does anyone have a method to connect to the s3 from the local machine  Im sure there must be a way to use aws-cli  or the serverless-application-model (sam)  However I cant find any guides which are complete enough to follow 
Ive also tried downloading the  yaml file from the console and putting it in the local directory and running:

and I get:

This suggests that potentially an api could connect my local machine to the aws s3 bucket but I have very little experience in setting this kind of thing up and am struggling with the jargon  Any help on getting this approach to run would be great  Ive recently started using docker so some approach using this would also be great 
Ive also tried this approach  and can see my lambda functions listed in visual studio code but I cant seem to see or edit any of the code and there is no obvious link to do so - most of the support seems to be around node js and my lambdas are python 
I also realise that cloud9 is an option but appears to require a running EC2 instance which I would rather not pay for  
I have tried a lot of approaches but there doesnt seem to be any complete guides  Any help highly appreciated 
"
63127037,"Lets say I upload folder/key jpg to a S3 bucket  How would I trigger a lambda function only when a file contains jpg at the end of File Name  is uploaded 
Is this possible or do I need to check the filename in the function and early-out it doesnt match what Im looking for 
The reason I ask is that a lot of stuff will be uploaded to the bucket  and it seems inefficient (and costly) for the function to trigger every time 
"
51168215,"I created a Lambda function for deleting a given thumbnail and I set a trigger on the ObjectRemoved event in order to automatically delete a thumbnail image when the original file was deleted from a given aws-S3 bucket 
However  by analyzing the monthly bill I realized that for some reason that Lambda was called hundred millions of times and wouldnt stop to be triggered  I had to disable the trigger on the Lambda to disable it 
The problem is I have not created or deleted any file on that bucket  so I wonder how its possible the lambda function continued to be triggered continuously 
Any help is appreciated 
Thanks 
Edit:
My AWS Lambda code

"
69063329,"Lets say I have about 20 different types of resources in my dynamodb  which are premium features  Now for each resource I want to validate access of a particular user  I mean an user buys access to particular resource - how should I store its access  In  e g  dynamodb table  and search the table for every user request to a particular resource  Or e g  should I use Cognito and custom attributes  And store e g  resource id and timestamp till a particular user has access  Or create a group in cognito for each resource and check if a particular user is assigned to the group  Or is there any other good  cheap way to validate user access 
"
65306726,"I am using Elasticcloud (hosted elasticsearch) to index my app data  Now I want to start streaming logs from my AWS lambda functions to my Elasticcloud account  I have googled and I can see that there are couple of ways to do this:

Functionbeat
Cloudwatch-&gt; Elasticsearch subscription filter
Cloudwatch-&gt; Lambda subscription filter

My questions are

which is the most cost efficient and performant way to stream logs from AWS cloudwatch to elasticcloud
For functionbeat is it necessary to first send logs to a S3 bucket  (I am referring to this )

"
30876345,"Ive adapted the Amazon example of  to create multiple thumbnail sizes and run in parallel   
My code runs fine locally in a few seconds  but in the the lambda cloud  it will not run in parallel  throwing an error after resizing the first thumbnail size   and if I switch it to be serial instead of parallel it takes around 60 seconds to run serially 
Why would running resize code in parallel in lambda cause the stream yields empty buffer error   How can I increase the performance so that I can create the sizes in a few seconds but still get good value and efficiency out of lambda in terms of processor cost 

"
57782987,"I have a setup were i want to have 2 S3 buckets serving the exact same data  for redundancy  To have them being served (both) by CloudFront  i created an Origin Group  The Origin Group is the origin for the behavior with higher precedence 
My questions are:
1: Are there any fees for keeping content cached for more than the default 24h   I assume not because it might be cheaper to store than to transfer data 
2: The origin access inside the group seems to always be the same  respecting the failover sequence (primary origin -&gt; secondary origin -&gt;    )  Is there any possibility to make the origin group be load balanced   ie  actually pulling from the origin with the lowest latency inside the origin group   I saw that i can use Lambda@Edge to change the domain for the request  How does that work with conjunction with Origin Groups and failover   If i have a bucket A and a bucket B and they both form an Origin Group (A primary  B secondary) and i use the Lambda@Edge to route to B and the request fails  does it route back to A   
Thanks  
"
62093781,"I want to run a Tensorflow 2 LinearClassifier on AWS Lambda  I have a trained LinearClassifier  tensorflow model  I want to run only the prediction in AWS Lambda  because of cost efficeny 
Currently Im not sure how to handle it 

I tried to use normal TF2  but it is too big for AWS Lambda Layers  All descriptions you find are with 
older TF 1 1x versions and Python 2 x 
Then I tried TensorflowJS  but it looks like the LinearClassifier using functions which are not implemented in TFJS 
Last I tried to user Tensorflow Lite  but there I currently have problems to convert my model to TFLite 

Do you have an idea  how I can get TF 2 Estimation of LinearClassifier running on AWS Lambda 
Normally I think not all of the 1 5 GB Tensorflow modules are used for the simple prediction of an existing model  So is there a possibility to only get the files which are used for running the script 
"
38216475,"Im interning at a small company this summer and have been tasked with parsing log files from a kinesis stream  This has an extremely high throughput  so Ive been learning how to do real-time parsing  for lack of a better term  so as to avoid bloating memory and incurring extra costs in lambda 
I went into the project expecting something tedious but manageable  but there are several problems Ive encountered:

Delimiters are lost in translation at some point between the logs being aggregated from many origins to when I receive them  There isnt anything I can easily do like break on tab  4 spaces  2 spaces  3 spaces  colons  commas  etc  because it tends to fracture the logs at unintended points
There are apparently several thousand types of logs that need to be addressed and analyzed  Many of these are from the same source (MSWinEventLog  for example)  but are still unique in their own right  Windows logs make up around ~85% of random samples  The spreadsheet of log types that was supplied to me records 0 instances of many types of logs  but I assume that their presence means theyve been observed at some point outside that collection period 

Everytime I think I find a pattern in a particular type of log  one comes along from a different source and kills it  Field names for the most part are not included  outside of Windows event number specific data  which have colons attached

Right now my approach is somewhat naive and only addressed the Windows events  It employs a combination of regex and smart pair parsing  Regex to get some fields that I can somewhat rely on to be there  and to identify key elements when pairing  The pairing is for the parts that are delimited by colons (or = in the case of powershell logs)  I make a good attempt at separating all fields and values into a list  Then  for each element  I check if its a key  If it is  I pair it with the next element which should be a value  If the next element is also a key  then the last one is either a header or a field with no value  and is discarded  After pairing a key and value  if the next element does not match something: pattern  then I assumed its a key with multiple values  Once another key element is encountered the key: value(s) up to that point are added to a dictionary  So  from the above example Id (hopefully) end up with:

This approach sort of works for windows logs  I try and trim unnecessary information (for example  many logs include the description text from Windows about what an event is  that can be 10+ sentences) 
My worry is that because the volume of logs is so huge its really hard to account for every possible log that might go into the parser  especially with their formats not always being the same even within one log type (date / time Ive noticed is extremely inconsistent in both order and delimiter)  Writing a few thousand Regex doesnt seem practical for one person (me) to do either 
So I guess my question is: from people who have dealt with a similarly messy situation  how can I approach this and fix the duct-taped spaghetti I have now 
"
62759147,"The following are the two key points 

I have a mongo instance deployed in AWS Lightsail 
I have set of lambda functions(written in python) which need to communicate with this particular DB

But every time I run the function (triggered from API Gateway) it times out 
The following are the things I have tried with no luck:

Added VPCExecution IAM role to Lambda 
Tried opening the Lightsail instance to the public(0 0 0 0)  in which communication happens(obviously)  but is definitely not a recommended solution
Tried setting up a NAT Gateway with a static IP and whitelisting it in Lightsails firewall  This also works but I cannot afford the cost 
Tried enabling the VPC Peering from Lighsails account panel  Still no luck  (This is where I was hoping it to work)

Is there anything Im missing  I really dont need to go towards EC2  But if you can offer any advice that results in the same cost  thatd be great 
PS: I am able to connect to the instance after whitelisting my Public IP 
I really need help with this  Any response will be highly appreciated 
"
54709373,"I came across the article : 
where I came to know about upcoming product called Serverless containers on Cloud Functions which is currently in Alpha 
As described in the article:

Today  we’re also introducing serverless containers  which allow you
  to run container-based workloads in a fully managed environment and
  still only pay for what you use 

and in 

Serverless containers on Cloud Functions enables you to run your own containerized workloads on
  GCP with all the benefits of serverless  And you will still pay only
  for what you use  If you are interested in learning more about
  serverless containers  please sign up for the alpha 

So my question is how this serverless containers different from app engine flexible with custom runtime  which also use a docker file 
And its my suspicion  since mentioned named is Serverless containers on Cloud Functions  the differentiation may include role of cloud functions  If so what is the role played by cloud functions in the serverless containers 
Please clarify 
"
61365289,"From what I know about Azure Functions  and serverless computing in general  is that it provides the benefit of not needing to pay for a server that is constantly running  I E  you only pay for the compute that was used 
In my case  I am already paying for servers to host a web application  Would it not make sense to use those same servers to host a backend API  
My guess is that the performance of the web application would take a hit  but aside from that  are there any other reasons why the function apps would make sense over a web API 
"
69902809,"My requirement is to log the full request/response body 
I have a microservice architecture set up with API gateway and lambda functions as a backend 
Now I want a logging solution independent from my backend Lambda functions 
The best thing to consider was API Gateway execution logs  but it is truncating the request/response bodies over 1024 bytes (AWS limitation) 
What can be used as a solution for this with a minimum increase in cost and latency  
"
53719673,"Ive got an iOS Shopping App and want to send crash dumps to an AWS Lambda Function 
To save costs for an API Gateway I want to send them directly to Lambda 
How can I authenticate the App and configure it so no other App can send crash dumps to my Lambda Function 
"
69368331,"Im using  with AWS Fargate  Im trying use  but am getting an error in my  when I try to set the  property under   Heres the relevant  section:

And heres the error I get:

Setting  works without a problem  I tried both  and   thinking that the space would make a difference  Both returned an error though  Im following  documentation  which suggests that a combination of 256 CPU units and  memory is compatible  so Im not sure what the issue could be 
The difference between 512MB and 1GB is trivial from a cost perspective  but at this point I want to solve this on principle 
"
61098504,"Before I even start  Ill say that I was not 100% sure whether SO is the appropriate SX for this question  Let me know if I should ask this on some other SX   
The question is about FaaS in general  but if you can better explain this in a context of a particular FaaS platform/provider  thats great as well   
Im currently reading up on serverless computing (FaaS to be more specific) and trying to get myself somewhat comfortable with the subject  
Now almost everywhere I turn  I encounter the following statements about FaaS:
1) Most FaaS platforms support down-to-zero scaling;
2) FaaS providers charge their users based on their function execution time (usually measured in ms);
3) Potential cold starts (i e   creating a new instance instead of reusing an existing one) are an issue in FaaS as they considerably degrade performance of your application;
Points 1 and 2 are considered benefits - you get exactly what you need (including nothing at all  if applicable) andy pay for exactly what you get 
Point 3 is considered a drawback - the request takes considerably more time to complete  Ive seen authors describing cold starts as a sign of FaaS platforms not yet being mature  Ive seen practitioners saying that they set up periodic requests just to keep their functions from becoming inactive and going under thus triggering the cold start the next time its called 
My question is - why are cold starts viewed as undesirable instead of as a trade-off 
What I mean is  considering that the user pays for execution time in FaaS  wouldnt it usually be in their best interests to avoid having warm  but idle function instances  To me it seems like a cost vs high availibility decision  Do I misunderstand something  Does having a warm  but idle function instance does not count towards ones execution time  Even if so:
a) isnt it undesirable from the providers perspective (having to allocate resources that are neither used nor paid for) 
b) sending periodic requests (as mentioned above) surely does cost you  right 
"
56530171,"I have a key that is being shared among different services and it is currently stored in an s3 bucket inside a text file  
My goal is to read that variable and pass it to my lambda service through cloudformation  
for an ec2 instance it was easy because I could download the file and read it  and that was easily achievable by putting the scripts inside my cloudformation json file  But I dont have any idea how to do it for my lambdas      
I tried to put my credentials in gitlab pipeline but because of the access permissions it doesnt let gitlab pass it on  so my best and least expensive option right now is to do it in cloud formation 
"
59288470,"I have to set up an AWS instance for a web application that is being used sporadically  a few hours at a time  a few times per month  The application requires a sizeable instance in terms of virtual cpus and memory  so keeping it running 24/7 would run up a steep bill  and since the time it is being used is below ~5% I am looking for a way to automatically suspend the instance if CPU utilization drops below 10% for &gt;2 hours (for example)  Also  ideally (but not strictly required) a request to the applications URL would start the instance if it is suspended 

My first idea is to set up CloudWatch to record any requests to the URL  as well as the instances CPU utilization  A Lambda function then periodically checks if the last request was over 2h ago and CPU utilization has been low for that time as well; if true then suspend the instance   
The starting of the instance could be done by having a special wakeup URL (separate from the apps URL) which triggers a lambda function to wake the instance if asleep  

Is there a recommended or more standard way to achieve this 
"
46653586,"This is my first time deploying to AWS Lambda and am getting a little stuck 
I have a large maven project called  which has many submodules  many of them dependent on each other  In there I have one Helper called   I have a parent directory and everything builds and compiles successfully  So  thats good  
In Alerts theres a class called  which has the line

where messages Doers is found in the dependencies 
But  when I do a  on the whole project and I find  and upload it to AWS Lambda and I set my handler as  I get the following error:

{  
com mywebsite alerts PaymentAlerts: com/mywebsite/messaging/Doers 
errorType: java lang NoClassDefFoundError
errorMessage: Error loading class
  }

How do I reconfigure this so that it finds all the necessary files 
Any and all help is appreciated 
"
42333929,"I have AWS DynamoDB table called Users  whose hash key/primary key is UserID which consist of emails  It has two attributes  first called Daily Points and second TimeSpendInTheApp  Now I need to run a query or scan on the table  that will give me top 50 users which have the highest points and top 50 users which have spend the most time in the app  Now this query will be executed only once a day by cron aws lambda  I am trying to find the best solutions for this query or scan  For me  the cost is most important than speed/or efficiency  As maintaining secondary global index or a local index on points can be costly operations  as I have to assign Read and Write units for those indexes  which I want to avoid   Users table will have a maximum of 100 000 to 150 000 records and on average it will have 50 000 records  What are my best options  Please suggest 
I am thinking  my first option is  I can scan the whole table on Filter Expression for records above certain points (5000 for example)  after this scan  if 50 or more than 50 records are found  then simply sort the values and take the top 50 records  If this scan returns no or very less results then reduce the Filter Expression value (3000 for example)  then again do the same scan operation  If Filter Expression value (2500 for example) returns too many records  like 5000 or more  then reduce the Filter Expression value  Is this even possible  I guess it would also need to handle pagination  Is it advisable to scan on a table which has 50 000 record  
Any advice or suggestion will be helpful  Thanks in advance  
"
62360293,"My current stack is like this:

User creates an account via AWS Cognito
A post confirmation lambda is triggered which then adds further user details to a database 

My database uses the  id generated by cognito as the userId so they are the same  I also copy the email address as the Username in my database  My intention is to use Cognito for Authentication and my own database for the functionality of my app  
However if the user wishes to update their email address I need to amend this in both cognito and my database  My first attempt made a call to cognito in my lambda using  but soon realised it was blocked from making external calls to the internet  so i created a nat gateway which worked but it simply costs way too much 
My second idea was to go through cognito  having my front end make the call and then have cognito trigger a lambda to update my database but I dont think this is possible  
Is there a configuration or something Im missing to be able to access AWS cognito via a lambda through the API gateway as they are both AWS services 
I dont want to make two seperate calls via my frontend as this creates a risk of one being completed but not the other  
Thanks  
"
71426926,"I need to setup a proxy apigateway in AWS that gets requests from the internet  stores the body (and headers) in a dynamodb and then forwards it to another external API gateway  Obviously  I need to wait for the response from the external API gateway and then send it back to the original client 
One possible solution is setting up a Lambda function as apigateway backend integration  This Lambda function stores the request in dynamodb and then simply makes a http call to the other external API Gateway  The problem I now have is that this lambda function is active while waiting for the response from the external API Gateway  This could take up several seconds and therefore is not a viable solution for high traffic environments  since hundreds of lambda functions are active for several seconds at all times  This quickly becomes too expensive 
AWS API Gateway also supports to simply proxy the traffic to a HTTP endpoint  which works  but this way I cannot get access to the request body and store it in dynamodb 
Since this task is at its core so easy I assume there is a simple way  but I cant seem to find a solution after a whole day of research  Im open to any feedback and suggestions :)
"
44119835,"Id like to achieve near real time search for a document service  and here is my idea:

I plan to use DynamoDB as my primary document store; 
and then whenever a new document update happens  an event in DynamoDB stream is created;
Id like to ask CloudSearch to pick up the events in the stream and update the index in CloudSearch

My question is how to integrate DynamoDB stream with CloudSearch  I feel I could use Lambda function in between (i e   trigger a lambda function  which execute a write/update the index operation  to process an event in the stream)  I would work  but I just feel it may be an expensive way to achieve my goal (because lambda cost $$)  
Does Amazon provide any hook that directly integrate DynamoDB stream with CloudSearch  I am wondering this approach because of the following illustration figure (it clearly implied that CloudSearch and Lambda are different integration point) 
"
67308220,"We are considering using azure functions to run some compute on  However our computes could take up lots of memory  lets say more than 5GB 
As I understand there is no easy way to scale azure functions based on memory usage  Ie If you reach 15GB start a new instance (since you dont want it to run over the maximum memory of your instance) 
Is there a way around this limitation 
OR
Is there another technical alternative to azure functions that provide pay per use and allows rapid scaling on demand 
"
71517855,"I have an RDS in one AWS Account - say Acct-1 
The RDS is public (i know its not a good idea and there are other solutions for that)
I have a lambda in another AWS Account - say Acct-2 which runs in a VPC 
I have setup VPC peering between the 2 accounts  the route table entries are in place as well as the security groups IN/OUT bound policies in place 
In Acct-2 I can verify that I can connect to the RDS instance in Acct-1 using a mysql cient from an EC2 instance  The EC2 instance is in the same subnet as the Lambda and they both have the same security group 
But the Lambda gets a timeout connection  The Lambda has the typical Lambda execution role that Allows logs  and network interfaces 
Thoughts on what could be missing   Does the RDS need to grant specific access to the Lambda service even if its running in a VPC  
Clarification: There is no route to the RDS instance from the internet  Clearly  the ec2 host is able to resolve the Private IP for the RDS instance from the DNS name and connect 
Lambda is unable to resolve the private IP for the RDS instance 
Im trying to keep the traffic within AWS so as to not pay egress costs 
"
59010349,"I am planning to copy  the AWS CloudWatch Logs to ELK and want to use Kibana Dashboard to visualise the logs 
One option is to stream the logs from CloudWatch to ELK 

But I feel this will involve execution of Lambda functions extensively and it might not be a cost effective option 
Is there any other cost effective way to copy logs from CloudWatch to maybe S3 and then to ELK 
I am Ok  if the logs are not realtime  maybe a delay of 15 mins or maybe one hour is OK 
But I am looking for a cost effective solution 
Btw  what is the best way to purge the CloudWatch logs periodically  ( maybe after one week)
"
54883254,"So I have already got as far as the below  I am trying to make the lambda function apply to a specific VPC (all instances within that VPC)  There is a costed way of doing it within AWS but getting customers to pay the extra $2 20 per instance for detailed monitoring is beyond difficult to justify  Based on what Ive read so far it is ridiculously easy to write the function per instance  again it can be done almost by clicking next next finish within AWS  but we dont want to have to define the individual instances based on how our clients grow so rapidly  

I was hoping the small if statement in the last line could possibly be updated to run against the specific VPC  but havent had much look finding the correct line to reference a single VPC  or security group that may help 
Any advice massively appreciated 
"
55951606,"I am trying to implement a vue js server(-less) side rendered webshop-a-like-site via nuxt js on AWS Lambda backed with Cloudflare 
I prefer Cloudflare over Cloudfront because of http/3  image optimization features  safety against attacks  brotli and some more features that Cloudflare provides out-of-the-box 
Unfortunately i couldnt find any ressources if anyone did this before and what to take care of to work properly 
Right now my setup is like:

I am not sure where to properly integrate Cloudflare 
`I found a blogposts and threads about: 

using Cloudflare Workers instead of AWS API Gateway 

Creating a CNAME for Lambda provided by Cloudfront  but I am not sure if this triggers another Roundtrip to Cloudfront and additional cost  
Connecting a Subdomain to API-Gateway
 
Another solution could be that I build the nuxt js directly in a Cloudflare Worker  but I am not sure of any downsides of this solution  since CPU time is very limited in Pro Plan 
`

Furthermore Ive read an article about the need of securing the API-Gateway against attackers by only allowing Cloudflare IPs 
Did anyone of you already setup Vue + Nuxt with Cloudflare   Am open to any other suggestions or ideas 
Thanks a lot 
Philipp
"
57994393,"I have a client that performs a weekly data upload of 3 CSV files to an S3 bucket  always within (at most) 5 minutes of each other  I have python code that ingests the 3 files  aggregates them  and writes and output that I would like to use to create a lambda function to fully automate this job  The issue is that I cant configure an S3 trigger that is every 3 object creates  I could have the lambda trigger every upload and exit until the 3 files are there but I dont want to do that as its not really cost effective 
So I came across this question  that suggested having an SNS Topic that gets notified after a batch of uploads is completed  however Im having trouble figuring out how to configure that  Basically what Id like to do is create something similar to a CloudWatch Alarm that triggers when 3 object PUTS have occurred within 5 minutes of each other  Is this possible  Or  how can I configure my SNS event in a way as is suggested in the linked question 
"
65833840,"When the subscription is created  like this:

The petition is successful  but when we see the stripe console  nothing was charge   

And the product has its price    (In this case  was used Plan mensual) 

What can we do  Thanks 
"
61683190,"First of all  I hope everyone is safe and healthy in this difficult Covid 19 situation 
Q: What would be ideal &amp; cost effective solution/selection between AWS EC2  or Lambda for below scenario in long term:
Suppose  I have to host a backend (Python based Flask) which contains at most 40 API endpoints which will be used by both react based web app &amp; react native based mobile app 
Out of those 40   Only 5 apis will be having average  concurrency of max 500 and total API hits could be around ~1500 to ~2000  daily average for all 40 APIs 
Idle time could be 8 to 10 hr daily
"
59253400,"I have a problem regarding cache on S3  Basically I have a lambda that reads a file on S3 which is used as configuration  This file is a JSON  I am using python with boto3 to extract the needed info 
Snippet of my code:

The problem is that when I change the json content and I upload the file again on S3  my lambda seems to read the old values  which I suppose is due to S3 doing caching somewhere 
Now I think that there are two ways to solve this problem:

to force S3 to invalidate its cache content
to force my lambda to reload the file from S3 without using the cache

I do prefer the first solution  because I think it will reduce computation time (reloading the file is an expensive procedure)  So  how can I flush my cache  I didnt find on console or on AWS guide the way to do this in a simple manner
"
58361050,"I am using AWS IoT  I want to throttle the connections and messages from a particular device 
( mainly to prevent costs )
Is there any way to achieve this 
AWS IoT device defender can be used for addressing security vulnerabilities  detect anamolies  etc 
But I wan to set up some threshold ( e g  100 messages per day)  after which the messages from the same device should be rejected 
"
49019544,"I have a simple lambda function that recursively traverses a tree structure  At each node in the tree  a few database calls are executed (look up to see if the current object exists  possible create and update parent node record with knowledge of child node ) and lambda calls itself (creating a new lambda execution) passing the list of connected child nodes 
the tree we are traversing isnt massive but is big enough to hit our concurrency almost immediately  
what are solutions to throttle the lambda so we avoid concurrency issues  
a few thoughts:
using a queue system: have a first in first out queue that does the work 
- the pain here is you lose the connection to the parent
- size of the message in sqs is very limited 
- will have to watch execution time to make sure it dies before it runs out of time 
using sns to artificially throttle the requests  (This doesnt seem to be the right approach but people have mentioned it online ) adding an sns call adds more processing time (costs more) but still will call the same number of lambdas at a slower pace 
- the pain here is we have a limited size with the message  (we are passing down all children in each node traversal ) 
- it will cost more in the long run throwing in extra processing just to slow things down a bit 
are there other strictly serverless solutions without upping our concurrency abilities  ideas thoughts 
"
56374391,"I have to make an HTTP request that takes a long time to receive a response   I dont want AWS Lambda to make this request as I will be charged for the time it is waiting for the response   Is there any way to use AWS Lambda to handle the response without being charged while waiting 
"
69886381,"I want to know if there are charges for uploading/dropping files in an S3 bucket created in EU region from a lambda function running in the US region 
Also how much of a performance hit it is  to have lambda function and the S3 bucket to be present in these two different regions 
Please help  
"
69310547,"Im trying to transfer files from an onsite Drobo to S3 Deep Archive   Because of the way S3 stores things in Deep Storage  it never makes sense to archive objects which are 8KB or smaller (because you will pay for 8KB of Standard anyway)   Lifecycle rules are not smart enough to handle this logic  so I wrote a    However  Im not sure what trigger to use   Right now  this lambda only responds to  events- which works fine for my simple online testing  but I suspect may not work when Im doing the transfer with a Snowcone or Snowball   The lambda itself then causes an  event if it archives the file 
So in order to get this to work with Snowcone/Snowball  itd be nice to know: what event is generated when the files are transferred off those devices into S3   Ive contemplated just using DynamoDB and pushing archived filenames into a table so I have a reference  but that seems unnecessary if I can get firm guidance   Another option is to be brutish about it and simply force-archive on every event received  because as far as I can tell  it is as expensive to query the current storage class of the object as it is to attempt the change in storage class 
Checked all the docs  including the 184 page Snowcone User guide PDF    suggests that the  and  events refer back to HTTP  but I dont think the Snow family existed at the time   I tweeted at Jeff Barr and havent heard back yet   Anyone have actual experience with these devices 
"
40961634,"I was wondering if someone could help me out on the following points:-

My aim here is to have a very cost effective architecture using Lambda along with the benefits of Relay to help with querying  caching  optimistic updates  etc  Is this architecture a good idea or am I overlooking something 
Are there any good examples of using Relay with Lambda 

"
60637398,"I would like to get a 2nd option for which AWS services to use in my following use case:

Client calls a lambda function and writes an  record into DynamoDB ()
In the   there is a collection of  stored as a json attribute -  - which I would like to split up and write them individually into   only if the  status is marked as Paid
And if the  is Paid  I will also like to aggregate the amount and updates it to 

Of course  the straight-forward way will be doing them in the lambda function  However  I would like to de-couple  into another process  Im thinking of:
Design 1

Use  on  to trigger another lambda function
In that lambda function  check if the  status is Paid  then do 


Design 2

In the lambda function  if the  status is Paid  add it to 
The  will then invoke a lambda function to do 

Cons
 has a payload limit of 256 KB

Design 3

Use 
Once the  status transit to Paid  it will do 

Cons
 is expensive (cost-wise)

Design 1 seems to be fine in terms of speed -  gets to execute quickly without much delays  But I dont like the idea that it gets trigger everytimes;  should only be triggered if the  status is Paid  and Im afraid over time  the cost will be expensive
Is there any other better design/aws services I should be looking at for my particular use case 
Thanks 
"
56499028,"For our new startup we have implemented our new marketing site on AWS  
We are using Amazon CloudFront as our CDN  AWS S3 for website hosting and AWS Lambda for our sign up API writing to our AWS RDS database  Cloudfront routes to the Lambda function through API gateway 
The Lambda function operates within the VPC so it can write to Amazon RDS 
We want to implement the server side ReCaptcha V3 check within our Lambda function but as Lambdas within a VPC do not have external internet access  the call to validate with Google times out 
Ive read we can overcome this with setting up a NAT gateway but running a gateway continuously is a cost we would like to defer for the moment if we can 
I have thought of the following options:

Create a non vpc lambda function to validate the ReCaptcha token  Call this from the VPC lambda function  Will this work 
As we are using CloudFront  create a Lambda@Edge function to validate the ReCaptcha token  If the validation passes  route to the VPC lambda function as normal  If the validation fails  return a response directly error to the client 
Use SES  Ideally we wanted a synchronous response (i e  any errors are responded to the client)  This would be a bit more work but my only query would be can you write to a SES queue from a non VPC lambda function 

Any pointers or any other options would be much appreciated 
"
53523580,"We have an AWS Kinesis stream that ingests around 15 small binary messages per second  As a last resort data recovery strategy  wed like to dump all messages received in an S3 bucket with 1-2 weeks TTL 
We could use a Lambda function to dump every Kinesis message to a new file in S3  But many small PUTs is expensive  especially because this data will not be accessed often (manually if so) 
Alternatively  AWS Firehose would aggregate messages for us and push them to S3 as a single S3 object  But as I understand - please do correct me - Firehose simply concatenates records  so this doesnt work where messages binary and logically separate (unlike lines in a log file) 
My current thoughts are to use a Lambda function attached to Firehose  so Firehose aggregates records over X minutes which we then zip/tar up  creating a file for each record  and send to S3 as a single archive 
Is this appropriate  If so  how do we aggregate records using Lambda  We process many-to-one  so Im unsure what result/status codes to pass back to Firehose  (The AWS ecosystem is very new to me  so I think I mightve missed the obvious solution )
"
55013881,"I extracted ~348 million row from DynamoDB using the data pipeline   The pipeline completed with no errors 
I noticed the number of files in the S3 bucket is not the same as the number of files indicated in the manifest entries tag   Each file contains 100 000 records and so there are 3 479 files   There are 3 469 files in the entries tag in the resulting manifest 
Does anyone have any idea why 
The manifest file is required in order to import the files back into DynamoDB   This is production data and the 10 file discrepancy could cost us 1 million rows 
"
57690843,"I have an interesting real-life situation:

I have a huge SQS (with really plenty of messages  constantly refilling (worst-case scenario  50 messages per second);
A Lambda that will consume SQS and push them to an external database (the database will process the messages in a sync way  unfortunately) 

Constraints:

The final external database shouldnt process data continuously but needs some idle time  This is due to the database activity costs (cost per CPU usage);
SQS is already part of the architecture;
the final external database is not in my control 

Here are my solutions  concerns and questions:

Sol 1: Using Cloudwatch to schedule the Lambda every hour to give time to consume part of the queue and then leaving the final DB idle for a bit 

Issue: the queue could explode meaning it could fill really quickly and the processing would be slow 

Sol 2: Create a Lambda (A) triggered by Cloudwatch every X time  This Lambda would cycle 10 times and trigger another Lambda (B) that would consume 10 messages (max of msgs per time  in SQS) and should autoscale as well 

Issue: Not sure about the autoscaling criteria    it looks more fantasy 

Sol 3 (bonus): Create a second SQS (2)  An intermediate Lambda (I) will be triggered every X time and move the messages from SQS (1) to SQS (2)  There is an event on SQS (2) that will trigger a Lambda (2) and this will autoscale 

Issue: too messy  overcomplicated  tied to the number of messages moved from SQS (1) to SQS (2) 
Now
Now  it is clear my concern is related to the Lambda autoscaling in consuming SQS and feeding the database 
Also  the Lambda should scale enough to consume a good amount of SQS messages but  at the same time  should leave some idle time to the final database 
I hope Ive explained the situation well and would be happy to have your advice on that (happy to learn ) 
Thanks 
Mauro
"
60259148,"Want to keep this question generic and expected answer in terms of best practice/approach/guidelines 
We need to know the best way to performance test and load test AWS cloud based applications 
What we have tried:
We used Gatling and Jmeter to execute our performance tests  These frameworks are pretty useful to test our functionality and to benchmark our applications latency and request rate 
Problem:
Performance benchmarks and limits of AWS managed services like Lambda and DDB are already specified by AWS e g  Lambda concurrency behavior and DDB autoscaling under load etc  AWS also provides high availability and guaranteed performance of managed services   

Is it really worth executing expensive performance test and load test jobs for AWS managed services 
How to ensure that we are testing our application and not actually testing AWS limits which are already known 
What is the best practice and approach to performance test cloud based applications 

Any suggestions will help tremendously 
Thanks 
"
63078075,"I have a Lambda function that is triggered by API Gateway 
Based on request parameters  this function may call another API endpoint(s) 
The URL of the other API endpoint(s) are passed by parameter in the request 
So  for example  I can call my endpoint like this:

And as a result  the Lambda function will at some point call the other API: 
My real function have some complex logic before calling other APIs  but you got the idea 
There are some cases where the function will call its own endpoint (recursion)  but passing different parameters to process some logic  so that it will not cause infinite loop 
But someone may accidentally configure parameters incorrectly so that it will cause an infinite loop  causing the function to be called millions of times per hour  leading AWS charges to the top 
How can I prevent this Lambda function to cause an accidental infinite loop and avoid enormous AWS bills 
"
37971987,"For example I have lambda functions that consume messages from a KinesisStream  How do stop and resume the function so that I dont incur charges and I dont loose data in the stream 
I know that if the events keep failing  Kinesis will keep retrying and the cost can be very high 
I cannot delete the function because there is lots of automation around it through CloudFormation  Is there a way to stop and restart the function 
SOLUTION:   
NOTE: Event sources for rules  log streaming  cannot be disable using the event source  You will not event get it in the list when calling the API using the SDK  For those you have to disable the Event Rule  or the Log Subscription 
"
46939619,"I have an endpoint in my api that supports writes   The resource in question is collaborative  so it is reasonable to expect that there will be parallel write requests arriving concurrently 
If the number of writes is small  then this is relatively straight forward to do with a simple lambda - read the current state  compute the new state  compare and swap  spin until the swap succeeds or until we give up   In either case  we compute the appropriate http response and return it to the caller 
If the API is successful  then eventually the waste of conflicting writes becomes expensive enough to address 
It looks as though the natural response is to copy the requests into a queue  with a function that consumes batches; within each batch  we process the requests in sequence  storing the new write  and computing the appropriate response to the request 
What are the options for getting those computed responses copied into the http responses  and what are the trade offs to be be considered 
My sense is that in handling the http request  after (synchronously) enqueue the message  I need to block/poll on something that will eventually be populated with the response to the request 
"
57796313,"Im currently working on a project where I use DynamoDB as my nosql database  Before I started I tried to learn how to model nosql databases since its really different to our known relational databases  I learned that I have to stick on the  model  Im using DynamoDB Streams to aggregate some data  for instance the customer count for a product (there are some more complex cases than that)  Since I have only one single table  my lambda function writes in the same table  from which the stream came    If I understand it right  this scenario could lead to an infinite loop since the first insert trigger triggers an update trigger  This is something im escaping in my lambda function  My question now is Am I  getting billed for two lambda functions and two DynamoDb streams each time I make an insert in my db  
If yes should I ignore the best practise way of a nosql db and split the table into multiple or should I invest the money   Because I am doubling my bill in this case  What are the cons of splitting my table in multiple tables   Would be the effect of the cons that big  
"
45601262,"I made a Python web scraper for downloading more than 4PB to 8PB data from the web  I have to run More than 1k + spider per sec for downloading data from 12  websites  If I use ec2 instance it will be very costally  Someone told me to use SWF And lambda  But I didnt find anything on the web About web scraper with SWF 
Is it possible to run this spider via Amazon Simple Workflow Service OR AWS Lambda 
"
67300765,"Since there is aditional costs for using HTTP and REST apis on AWS lambda  i would like to know if i could make AWS Lambda receive gets and posts without the need of these HTTP API services 
In this example it seems to be possible:

"
52473321,"Im new in AWS  For one project we require to purchase server on AWS  I dont know what configuration is required for the server  Our website will be like  and minimum 1000 users every time will be online on the website  Please  what configuration will be best with minimum pricing  Im mentioning details below  what we want;

if anything else is missing please guide me 
"
62957964,"I want to make a bot that makes other bots on Telegram platform  I want to use AWS infrastructure  look like their Lamdba functions are perfect fit  pay for them only when they are active  In my concept  each bot equal to one lambda function  and they all share the same codebase 
At the starting point  I thought to make each new Lambda function programmatically  but this will bring me problems later I think  like need to attach many services programmatically via AWS SDK: Gateway API  DynamoDB  But the main problem  how I will update the codebase for these 1000+ functions later  I think that bash script is a bad idea here 
So  I moved forward and found SAM (AWS Serverless Application Model) and CloudFormatting  which should help me I guess  But I cant understand the concept  I can make a stack with all the required resources  but how will I make new bots from this one stack  Or should I build a template and make new stacks for each new bot programmatically via AWS SDK from this template 
Next  how to update them later  For example  I want to update all bots that have version 1 1 to version 1 2  How I will replace them  Should I make a new stack or can I update older ones  I dont see any options in UI of CloudFormatting or any related methods in AWS SDK for that 
Thanks
"
40118293,"I have an API Gateway endpoint at some url  like this:

The people and/or services that are going to be accessing this endpoint need to pass particular parameters and values to the endpoint  Like this:

Is it possible to limit access to the endpoint if the  parameter is missing OR if the  value is not a specific pre-determined value  Can I setup my endpoint to simply ignore calls that dont have the proper token 
Im planning on using Lambda as the backend  Do I have to deal with this in my Lambda function  Ultimately  Im trying to avoid unnecessary Lambda and API Gateway usage costs by random individuals making bogus calls to the endpoint  So if I can have API Gateway simply ignore these calls without spinning up Lambda that would be ideal 
If I am able to have API Gateway ignore these calls  do I still get billed for usage when bogus calls are made to the endpoint(s) that are missing the token 
The reason Im asking is because the 3rd party service that is going to access this endpoint does not have any options for passing authentication parameters in headers or using AWS Cognito  etc  So Im just trying to think of a simple way to limit access 
"
69143293,"My AWS Lambda function needs to access data that is updated every hour and is going to be called very often via api  What is the most efficient and least expensive way 
The data that is already updated every hour is configured through Lambda batch  but I dont know where to store this data 
How about putting the latest data in the latest bucket of Amazon S3 every time  Or  even if there is a problem with the hot partition  how about storing it in Amazon DynamoDB because it is simple access  I considered the gateway cache  which is updated every hour  but at a cost  Please advise 
"
61661789,"Im in the process of building an application for stripe payments  This application generates a form that passes the data to the Stripe api via nextjs api  I just need to build in some basic authentication so only those submitting their payments via my form have access to the api  How would I go about adding some basic auth to my api without requiring users to login  Would I do this via env variable  Im fairly new to the nextjs/vercel world and come from the python/django/react realm  so maybe my thoughts on this are backwards    Im planning on hosting the api on vercel and the react form on a php site  So the react form will essentially push data to the vercel app api  
(The reason Im not building the api in php is because I dont know php and because Im attempting to build something with as little footprint in the current php site as possible ) Any help or guidance on this would be much appreciated   
My pages/api/customers js file

Part of my checkout form

UPDATE:
Alright  so I added a TOKEN to my  file and now require my api to receive that specific token  
I added this to my checkout form: 

and then added this to the api: 

Since Im not using a login/logout system  Im hoping this is enough  Thoughts or feedback are more than welcome  
"
52872443,"According to  if I want to create a lambda function to send the data from SQS to S3 each SQS message will be stored in an individual S3 object (I assume this is due the lambda function will be trigger each time the SQS recieve a message)
Is there any way to send  for example  all the messages that SQS received in the last 24 hours to the same S3 object 
EDIT
This could be the code to received the message from the queue and send it to S3

But  which would be the best option to send to S3  I mean  in S3 I would pay to put request and if I do it element by element this could be quite inefficient 
I also imagine that storing items in memory would not be a good idea either  so im not sure what should I use for the best result
Other question: when I developed locally i used ReceiveMessage but in Lambda function I have to use ReceiveMessageAsync  why this 
"
60771340,"I was running a serverless web application on a lambda inside a VPC  and connecting to a Aurora-MySQL RDS instance  with inbound rules to allow traffic from the security group of the lambda
The connection was working fine  however  quite often the lambda cold start was giving me a timeout 
After some research  I found out that running a lambda on a VPC brings an additional cost on startup and I saw the recommendation in more than 1 place to avoid using lambda on a VPC except if you strictly need to access some resource in the VPC 
So  I decided to move my RDS to a publicly accessible instance  so my lambda can access it over the internet and remove the lambda from the VPC 
So  I changed the RDS  option to  and edited the security group to allow inbound connection from any IP 
I have also removed the VPC from the lambda  so the lambda is not running on a VPC anymore
I thought it was gonna be enough 
But then my lambda started failing to connect to the database
I tried to connect using my local client  again  failure
tried pinging to the hostname  got request timeouts
After digging a bit into it  I found that my DB instance subnet group having some private subnets might be a problem ( )
So  I have created a new subnet group with only public subnets  and tried to move my db instance to the new subnet group    but got this message:

Ok  it seems that I cant move to a different subnet in the same VPC  I started trying to create a new VPC  but it doesnt seem to be right and Im sure there is something else I am missing here 
I also read about Network ACL  and thought that this might be the problem  but my rules seem to be fine  with the default rule to allow any traffic (and the rule * to DENY)

My RDS Network settings

My Security group inbound rules

Still cant connect  cant connect with my local client  cant even ping it:
Connecting through my local client


Any idea of what I am missing here 
UPDATE
My VPC has internet access (I can access internet services from it  not an issue)  I have an Internet Gateway and NAT Gateway in place 
Im using Zappa for the lambda deployment  which takes care of creating a keep-warm function    however  I know that concurrent requests could still be an issue
The issue with VPC in lambda is that it can add 10s on the cold start  which is a no-deal for some of my use cases:

"
52617888,"What I imagine
On my website  I have a form to buy a product  Information needed are email and domain name 
Payment are managed by stripe and I use Lambda and API gateway to verify payment information 
If payment is successful  Im sending email and domain name to SQS 
What Ive got
The data is not sent to SQS right after the validation 
I dont know why but the first use of the form  nothing is set to SQS ; 
the second time the form is used  data form the first form are send to SQS ; the third time the form is used  its data of the second form they are send to SQS  etc   
Cant find the problem on the lambda code

If someone  can explain me whats wrong  Thanks :)
"
60994174,"I have a script copying a daily backup file to Blob storage using azcopy  On the Blob objects I want to create a lifecycle policy  like GFS  for the backups  Then I want to move older data (perhaps the yearly backup files) to colder storage automatically  Then I need to charge my client per GB storage and need a monthly report  maybe an e-mail  to our finance department with the months maximum storage GB value  I will develop this and need guidance on where to start  Please point me in the right direction  As cheap and serverless as possible  I will answer my own question with the scripts etc to share the knowledge  Thanks 
"
43689282,"Is it possible to substitute default Spring Frameworks way of creating and managing objects via reflections with other dependency injection tool (that would be faster  because would avoid reflections)  while still holding on Springs rich API 
For example  I would like to have beans created by Dagger 2 or Tiger or Feather that would still be able to interact with Spring Data/Social/MVC 



I know that someone is going to say start worrying about performance when it will become problem - well  I would say its about time to start worrying about it right now 
In my option  it would allow Spring to embrace FaaS (Function as a Service)  FaaS jvm is going to be shut down after serving its call  so You either keep it running (like regular server) and pay for literally every millisecond or some calls may be delayed even few seconds (to boot everything up) 
I have found two projects  that are trying to use Spring in FaaS environment and are tackling this problem  but in my option its easier to remove problem (reflections) that try to overcome it with hacks 


Or  maybe there is another way to solve this problem and efficiently use Spring in FaaS  that I am not aware of 
Related question: 
I have been trying to use minimal Spring Framework application (like 3-5 classes) and still it takes (sometimes) 5-15 seconds to handle first request (next are handled in 50-100ms)  so minimizing isnt really working in this case 
"
56402673,"I want to have a lambda function to run batch payment jobs 
When the user send the batch job  I want the user to see the progress of batch payment  So I want the Lambda function to send the messages back to the client  The user needs to see what payment was successful too 
I expect the lambda function will take around 3-5 minutes to run 
What should I use to for Lambda to communicate with the client side code  Sockets  The client side is written in Vuejs 
Thanks
"
63034154,"Is there a way to buffer X log messages from a CloudWatch log group and only then stream it to a lambda function  Ill elaborate:
I have an app that I registered its CloudWatch logs to stream to a lambda function which formats the logs and pushes them to Elastic Search 
So the flow is the following:
(app logs) -&gt; (CloudWatch) --&gt;(Lambda)--&gt;(Elastic Search)
My problem is that my lambda function is invoked very often (most of the time single log message) and bombards ES with write requests  I would like to write the logs in bulks  i e wait until 30 new logs and then invoke the lambda for the 30 logs bulk 
The only way I found to achieve this is to use Kinesis and Firehose but those services cost extra and I want to avoid this 
Are there any other alternatives to achieve this without using something like LogStash 
I am assuming this is a very common usage so there must be some easy way to solve this 
Thanks 
"
37439656,"What Im trying to do here is sending a notification via SNS and APNS when a specific user is part of a newly added DynamoDB Item  I want to send it to the users Cognito Identity ID  not to device token 
So Lambda should be triggered when the item is added and then go through a list of Cognito Identity IDs  which is also part of the item  
Then Lambda is supposed to publish the push notifications to each Cognito Identity ID  
All the devices are registered as endpoints within sns  I also keep the Cognito Identity ID in the user data row for the endpoint 
But i didnt find a way to send notifications directly to a Cognito Identity ID  Do i have to add a topic for each user and send the notification to that topic  Or do i have to store another DynamoDB table to map Cognito Identity IDs to device tokens  It would be great if someone knew an easier and not too expensive way 
Thank you 
"
65240422,"Lambda Specs: Python Version - 3 7 || Memory - 10240MB (10GB)
The Synchronous API timeout limit is 30 seconds  My code executes for 4 seconds  The below code is a sample one that sleeps for 4 seconds 
Im using EFS mounted in Ubuntu for storing the packages as the limit of lambda deployment is 250MB 


This is a simple code integrated with API Gateway  It works fine when executed one or two times but when executed more than 10 times it runs into a timeout error 
I tried to use Provisioned Concurrency but it is so expensive  What to do to make it work all the time  Any Alternatives 

"
69656762,"SQS  mentioned

Every Amazon SQS action counts as a request

SQS pricing strategy has some pricing buckets  like First 1 Million Requests/Month is Free  From 1 Million to 100 Billion Requests/Month for Standard Queue is $0 40  etc 
As per   to trigger lambda from SQS  three SQS actions are required as given below 


 and
 

My questions are

For every lambda invocation (triggering) do all these three actions are execute 
If yes  do all these actions are treated as a request 

In that case  every trigger for each 64KB payload chunk consumes 3 requests  If this understanding is wrong then what is the request count calculation for every trigger execution 
Thanks in advance
"
53716544,"Were hosting our webapp on CloudFront and S3  This infrastructure is configured in a Terraform module  Were using the same module (managed by Terragrunt) to deploy our webapp to our staging and production environments 
Obviously  we dont want public access to our staging environment  As such  weve created a Lambda function to enabled Basic HTTP Auth and are using the  within the  resource to enable it 
The issue is we dont want the Lambda to run on our prod environment as well  I havent been able to conditionally set the association on the resource 
Ive also tried creating two resources with the same name and setting the  property so that only of the resources exists 
e g 

However when I try to deploy the code  I get  
Is there any way to achieve what I want 
Another option that Ive considered is setting the Lambda on both versions  but having it not do anything in prod  However  this seems inefficient and costly as the Lamdba will be called on every request  and would like to avoid it if possible 
"
59135114,"I have a WebSocket API hosted on AWS using the serverless framework  
The problem is that I am seeing 150k logs every minute  and it is costing a bunch 
The following log groups are the problem:

/aws/apigateway/mzl9lpgzn0/production
API-Gateway-Execution-Logs_xkkvpjzgqj/production

I have followed their docs to disable logs like so  but it is showing an error 

Error: 

Is this the right way to disable API logs  so I can reduce my CloudWatch costs 
"
33001798,"I plan to have the following setup:

Completely STATIC front-end web interface (built with AngularJS or the likes)
Serverless Framework back-end APIs

I want to store my front-end in S3 and my back-end in Lambda 
Since Im charged every time the lambda function gets executed  I dont want everyone to be able to make requests directly to it  On the other hand  I want to store my front-end simply in S3 as opposed to a server 
How do I go about protecting my back-end API from abuse or DoS 
"
61548553,"Our institution is trying to make an automatic grading platform set up for an introductory class in java  and we were hoping to use an AWS lambda function for the grading  The problem is  like any sane person  our dev team far prefers python over java  so the grader itself is written in python  but the student programs are written in java 
Since the grader has to call the student functions  it would be best if we could have a lambda runtime that has binaries for both python and java  Does anyone else know how we could go about doing that 
As a side note  it would be possible to use a separate function to run the java files and return the output to the python function  but since amazon charges per function execution  this would be less than ideal 
"
63940867,"I have a JAVA 8  AWS lambda function that has some pretty expensive setup when the container is first spun up  It must make calls to pull various credentials/cacerts  I would like to cache this set up (the output of which is an SSLContext object that is used for making calls to another api) 
I have not had to do this before  and my question that I cannot seem to find an answer for is this:
Are there any issues reusing the SSLContext object over and over again while the Lambda Container is alive  this could be 15 minutes or 5 hours  or 2 days  etc   as long as there is traffic coming through it  it will be alive 
None of the credentials will change  and the SSLContext object would be identical between all invocations 
Do SSLContext objects have a TTL  The code to create the SSLConext is fairly boilerplate  This method is called after I have done the expensive pulls to get the certs/cred and I want to cache this SSLContext object:

}
"
61363833,"I am using Spring Boot in my application  While searching for some IAM tools  I actually liked Auth0  but iam not affordable their pricing  So  I found another called   
Below is Auth0 to restrict our custom access api

Currently  I am trying to restrict access API using AWS cognito  but I am not finding correct documentation to achieve this  Can anyone please tell me whether restricting api access can be possible using aws cognito 
"
69193696,"edit: Turns out the solution is in the docs  I had bog standard normal sam installed but I needed what they call the public preview version AKA sam-beta-cdk  With this installed the API can be started locally with  and works well  While I appreciate the answers which suggest that development should be done using purely TDD I feel there is also value in this more interactive  manual mode as it permits quicker exploration of the problem space 
Im trying to build my first app with CDK + Typescript using API Gateway  Lambdas and DynamoDB  I have built a couple of Lambdas and deployed them and they work fine live on the web  However I dont want a minute long deploy cycle and various associated AWS costs as part of my workflow  What I want is to be able to test my API locally 
I have struggled to find docs on how to do this  Amazon seem to recommend using the SAM CLI  so that is what Ive been trying 
The docs claim running  runs  to make a could assembly in  but I see no evidence of this  Instead what I get is a complaint that sam could not find a template yml  So I manually run  which creates one in the root folder  Then I run  and it seems happy to start up 
Then I try and hit my test lambda using CURL:  I get  and a huge ugly stack trace in the console that is running 
The lambda is this   

Start of the huge ugly stack trace   

The end of the huge ugly stack trace   

So it would seem  cant find  and throws and error which means the API gateway doesnt get a valid lambda response  So far this has not helped me chase down the problem :/ It certainly seems aware that test is a route  as trying to hit other endpoints gives the classic  but it chokes hard trying to fulfill it despite me having both  and the compiled  present 
I have the test route and handler defined in my CDK stack definition like so   

I considered posting my template yml but that is even longer than the big ugly error message so I havent 
So I have three questions (well actually a million but I dont want to be too cheeky )

Is this actually the canonical way of locally testing apps made with CDK
If so  where am I going wrong 
If not  what is the better/proper way 

"
57078937,"I have a requirement to build a basic 3 failed login attempts and your account gets locked functionality  The project uses AWS Cognito for Authentication  and the Cognito PreAuth and PostAuth triggers to run a Lambda function look like they will help here 
So the basic flow is to increment a counter in the PreAuth lambda  check it and block login there  or reset the counter in the PostAuth lambda (so successful logins dont end up locking the user out)  Essentially it boils down to:
PreAuth Lambda

PostAuth Lambda

Now at the moment I am using a dedicated DynamoDB table to store the failed-login-count for a given user  This seems to work fine for now 
Then I figured itd be neater to use a custom attribute in Cognito (using ) so I could throw away the DynamoDB table 
However reading  the section titled Configuring User Pool Attributes states:

Attributes are pieces of information that help you identify individual users  such as name  email  and phone number  Not all information about your users should be stored in attributes  For example  user data that changes frequently  such as usage statistics or game scores  should be kept in a separate data store  such as Amazon Cognito Sync or Amazon DynamoDB 

Given that the counter will change on every single login attempt  the docs would seem to indicate I shouldnt do this   
But can anyone tell me why  Or if there would be some negative consequence of doing so 
As far as I can see  Cognito billing is purely based on storage (i e  number of users)  and not operations  whereas Dynamo charges for read/write/storage 
Could it simply be AWS not wanting people to abuse Cognito as a storage mechanism  Or am I being daft 
"
48758001,"I’m writing a remote application  controlled by a server  The client would be some sort of daemon that’s pretty much always on  The thing is — these remote commands are unpredictable and sparse  The server could go hours or days without sending a message  or it could send several messages in an hour 
I have no experience with networking  so I’m not sure how all this works and I just need pointers for where to look 
What’s the best  most efficient (cheapest) way to do this  I’d be using AWS for all of this 
The first option I thought of  was to store in a database the IPs of all the clients associated with their user ID  When a AWS Lambda function is called  it makes a new connection to the IP associated with that user id  and sends the message  then closes the connection as the lambda function exits 
The second option was to host an EC2 instance  and actively keep alive connections to all the users  But this would require hosting the EC2 24/7 with potentially a lot of clients  and could get very expensive 
I’m not sure what best practice is here  or even what protocols to look into for that kind of thing  For example  on the first option  how would the server connect to the client  Wouldn’t it have to port forward because of firewalls or something 
Again  I don’t have any experience with network programming so I’ll take all the pointers I can get as to how this is generally accomplished 
Thanks 
"
54557325,"I have a little bit of a problem concerning the design of a planned application  especially database engine and Serverless/not serverless 
The goal is a Web Application which talks via the Rest API to the database  The Rest API itself is really just CRUD operations  so for that the Serverless aproach (AWS Lambda) would fit pretty good in my opinion  For that  the probably most efficient database to choose would be DynamoDB (NoSQL)  
I am familliar with RDBMS and have only little knowledge of NoSQL databases 
The Schema of the application is not yet finished and should be expandable at later points  because there could be new features to implement and so on  Because of this  i would rather use a RDBMS and not a NoSQL database  because they dont scale that well in terms of editing the schema at later points  (at least thats what i read the last couple of hours)
Choosing for example Amazon RDS MySQL database  would be much more expensive and i dont know how well they do with the Serverless aproach of the Rest API  
So i am standing at a point i really dont know what services to use here  Could i still use DynamoDB  The schema would propably be very relational  
"
65846053,"Im using Athena and Im dealing with about 1000 raw compressed data files daily (each of 13MB)  I need to process and store efficiently to improve queries speed and cost and I do it by partitions 
I’m currently using lambdas (being triggered for each file creation) as my ETL and it - loads the raw data file  reorganizes columns  changes the file format (to parquet) and then splits it and saves it to multiple files on S3 bucket 
then another lambda starts and creates new partitions for the Athena table:
s3://raw_data/2020/01/01  --&gt; s3://table_name/2020/01/01/0-50/ (Athena table built over these files)
Many partitions affects on the queries speed  so Ive heard of a
new feature called Partitions Projection  using this feature I can speed up the query processing and automate partition management 
I’m a little bit confused of the options 
Another point is that theoretically  if I understand it correctly  I can get rid of the lambdas and save some cost by using Athena CTAS once to create the table and then executing INSERT INTO daily (limited up to 100 partitions) but then I still use partitions and cant use Partitions Projection 
What is the most efficient way to deal ETL when it comes to daily provided files 
"
55087016,"Ive got the order microservice thats written as go AWS lambda function 
The main function named order-service bound to API Gateway  It receives several parameters like  of int  creates an order with artifacts and returns serialized order with order_id and total price 
This function invokes a function named order-item which creates an order-item and returns them in parallel(per product)  These functions invoke product and user functions to retrieve information about user and products by their ids  
Then  the order function invokes another lambda called fee-function which takes just total price and user id and gives back fee price  Of course  it calls some other function like user function and so on  Basically  this is a simple example of how the service works in general  Any function calls some others like user-discount  state taxes etc 
The questions are:

Is it good that order function invokes fee function through Amazon  but it can just import fee handler package and run it inside itself (However  fee function may be called from outside so it must be deployed as a separate function as well)
Is it good that each function receives just user id and loads the user invoking user function  Perhaps  better to preload it and pass it through everywhere  Something else 
Is it good that one function calls other functions and they call some others and so on  is there any better approach in my situation  Use SNS  Step function  dependency injections/aws layers 

The main reason why I asked is to withstand thousands of RPM and not pay a lot 
Thanks for helping  I appreciate this  
"
58770277,"Im working on architecting a micro-service solution where most code will be C# and most likely Angular for any front end  My question is about message chaining  I am still figuring out what message broker to use; Azure Service Bus   RabbitMQ  etc   There is a concept which I havent found much about  
How do I handle cases when I want to fire a message when a specific set of messages have fired  An example but not part of my actual solution: I want to say Notify someone when pays a bill  We send a message 
  which will fire off microservices which will be processed independently:

FinanceService to Debit the ledger and fire 
EmailService: email Customer Saying thank you for paying the bill
 
DiscountService: Check if they get a discount for paying on time then send


If all three messages have fired for the Same : Message      
then I want to email the customer that they will get a discount on their next bill  It Must be done AFTER all three have tiggered and the order doesnt matter  How do I Schedule a new message to be sent  message  without having to poll for what messages have fired every minute  hour  day 
All I can think of is to have a SQL table which marks that each one is complete (by locking the table) and when the last one is filled then send off the message  Would this be a good solution  I find it an anti-pattern for the micro-service &amp; message queue design 
"
53312611,"Is there any reference to connect lex bot with my rest api project   i want to get pricing from my products   this enpoint is included in my project in a rest method (json request and response)  however  I have tried to find any reference to call my rest api but I cant find any example 
The bot is using lambda function (nodejs)  I am just beginning with amazon lex so I do not have any reference  Im trying to modify the existing examples they provide (pizza ordering) but no idea by the moment 
Thanks in advance 
"
59538936,"The thing what i want do:
Im thinking about use aws dynamodb as my new web site(press and bbs mixed type) main server 
But I cant design database  because dynamodb maybe cannot satisfy my requirements 
Somebody knows how can i do 
Foundation
My bosss plan is spawning many websites and close it several days after if its traffic is low  (and go on until it success)
He has many domain names (over hundreads) and want make many websites 
And he also wants selling our system for web solution to customers  ( internet newspaper  blogs  magazines  etc    )
It is very large plan  anyway i must design the system   
Situation
first  most of website is going trashcan after several days 
so make each websites on on-premise server is not good way because it means too much manual-jobs  (just deploying the site  undeploying the site)
And also on-premised pricing is not good in this case because we cant predict any webserver is closing (because traffic size lower than survive-line)  or survive because traffic is grow faster 
i guess 80% of sites are just ghost sites   
second  the amount of spawining websites are not measurable  Because my boss always yelled me as many as can   
And I also consider about this project is abandoned by my company after launching some month after  (maybe they want keep-and-not-maintain mode with not consume many price)   
Anyway  ths problem is the   
1  cant predict how many sites are alive and gets high traffic 
2  cant predict how many sites are ghosts or few traffics (under 1000users/days) 
3  even the project is abandoned  thell want keep-and-not-maintain-mode (with lowcost as they can)
conslusion is
1  most sites are going to keep-and-not-maintain-mode  its cost must low
2  some few sites are burst in after times  it must support this situation also   
So next is my answer:
Server : full faas serverless with stateless server (lambda  cloudrun  function  etc    i think cloudrun is best because development is very it can easy using my own docker)
the reason is   
if this website is just keep and not maintain it  we did not pay for it  or very small price 
if the site growing up or traffic is burst  it can support on-live   
Database : serverless because its traffic is not measurable in this stage 
there only two serverless (means needs no pay for provisioned instance)  Aurora and Dynamodb   
Aurora is my first choice because I always using mysql or mariadb in webservice 
But there is two problem 
Aurora serverless is too sensitive acu scaling  and it never going scale-down until 5 minutes flowed  (and if it scaled up to 4 acu  5*4=20acu/min  just one connection and query once  but pricing=$0 03)
It is pretty sure if one of these sites traffic is changed from nobody use it to a few people comes  Autoscale price is going to very higher  even i set max acu scale limit to 1  there are another problems  (well-known problems)  If aurora start from cold  it takes very long time(about 30seconds)  And if it is scaling  it also takes some delay 
Anyway  i cant make good pricing design for Aurora   
So I moved on Dynamodb 
It has very good pricing rules  In on-demand mode  under $2 per 1 000 000 rcu 
I guess most of site data is stored in S3  So read/write other data is not much than 1kb/4kb  and even i transaction for each unit  under $2 per 500 000rcu   
Actual Problem
But it has trap point 
If I do scan  its pricing is going to very higher  because returns a lot of data (until 1mb)  I accepted  So I must using query  But query is working same as scan in a partition  And pricing is going to scanned amount of read-write-units(until 1mb)  So if I have 100 items in a key and query just one item (total 100 members and just select one of that members)  the dynamodb charges 100 times pricing because it scanned 100 items  (assume each item lower than 1kb)  I cant believe it  (x100 pricing) so googled it 
I found many people are design dynamodb seperated hash-key  (like members-startfrom-a  members-startfrom-b      )
Question
Is it normal 
In this time  I think dynamodb cannot support normal website (bbs or press  or blog)  because they are rdb optimized structures  Even paging articles needs full-scan(or partitioned full-scan)   Is it right  or there is a migration rules for rdb user to dynamodb user 
Someone can show me case-study 
Most case people use dynamodb as subdb   
"
47747326,"I have created case for increasing service rate limit of aws lambda for handling heavy load in our application  I want to get information about whether aws take any charges monthly/one time for increasing limit 
"
63200340,"I have a NLP program which uses Spacy to load in a large word2vec file  This file is 3 75 GB and is too large to put directly in a lambda  Currently I have this program running in an extra large EC2 instance  but this option is expensive  The code also only runs on demand around four times a week  so keeping a server running constantly is not what I want 

Is there any way I can convert this to serverless 
If I use EFS  arent I just converting one server to a server plus a lambda 
Is there an API I can talk to which would return the same information that Spacy can  specifically similarity of two sentences 

"
62442590,"I am a student and new to AWS services 
I am working on a web-based project 
in the server part (AWS )  I need to monitor the outbound data used by each customer  and generate a bill based on the data used by that customer ( Not AWS billing ) 
how I do that which AWS service fit for that please help me 
"
57187771,"I have an AWS account with a Postgres RDS database that represents the production environment for an app   We have another team that is building an analytics infrastructure in a different AWS account   They need to be able to pull data from our production database to hydrate their reports 
From my research so far  it seems there are a couple options:

Create a bash script that runs on a CRON schedule that uses  and  and stash that on an EC2 instance in one of the accounts 
Automate the process of creating a Snapshot on a schedule and then ship that to the other accounts S3 bucket   Then create a Lambda (or other script) that triggers when the snapshot is placed in the S3 bucket and restore it   Downside to this is wed have to create a new RDS instance with each restore (since you cant restore a Snapshot to an existing instance)  which changes the FQDN of the database (which we can mitigate using Route53 and a CNAME that gets updated  but this is complicated) 
Create a read-replica in the origin AWS account and open up security for that instance so they can just access it directly (but then my account is responsible for all the costs associated with hosting and accessing it) 

None of these seem like good options   Is there some other way to accomplish this 
"
60179473,"I am trying the understand how the AWS Lambda charge  I know that the first 1 million requests and the first 400000GB-second compute time if free are free  After that  it will charge 0 20USD per million requests and 400 000 seconds if the function is 1GB RAM  What I am not clear here is how the computing time is charged 
Lets say one request is 0 0000002USD  One the client makes the request  it already charged 0 0000002USD no matter how long it was run  The computing time is charged once the function starts running based on how much memory it consumes and how long it was run for  Is that correct  Lets say the function was run for 2 hours  but it only consumed 1GB RAM (which is not realistic - just for the educational purpose)  so it is gonna charge me 0 0000002USD + (cost of execution/ computing for 400 000 seconds)  Am I right 
Can anyone confirm and explain 
"
55216273,"From my understanding  I can run AWS Lambda outside a VPC  as well as the RDS and have that set to publicly accessible  That would be the perfect solution for me because my lambda functions need internet access and a NAT Gateway which would allow that when inside a VPC is way too expensive  In which cases is it safe to go for that option  When is it a bad idea to have an RDS outside a VPC  What are the risks 
"
58362746,"I raised a similar question recently  which was resolved  however Ive change the  setup slightly 
The Nat Gateway was costing a small fortune so I switched it out for a Nat Instance using EC2  I followed  guide 
Now my Lambda is successfully connecting to both the RDS instance and also has internet connectivity which is great  The problem I now have is Im unable to connect to RDS Postgres through port 5432 from my local machine and Im a bit stumped 
 here  let me know if you need anything else 
Cheers 
"
62688990,"I am very new to AWS Lambda and am struggling to understand its functionalities based on many examples I found online (+reading endless documentations)  I understand the primary goal of using such service is to implement a serverless architecture that is cost and probably effort-efficient by allowing Lambda and the API Gateway to take on the role of managing your server (so serverless does not mean you dont use a server  but the architecture takes care of things for you)  I organized my research into two general approaches taken by developers to deploy a Flask web application to Lambda:

Deploy the entire application to Lambda using zappa-and zappa configurations (json file) will be the API Gateway authentication 

Deploy only the function  the parsing blackbox that transforms user input to a form the backend endpoint is expecting (and backwards as well) -&gt; Grab a proxy url from the API Gateway that configures Lambda proxy -&gt; Have a separate application program that uses the url


(and then theres 3  which does not use the API Gateway and invokes the Lambda function in the application itself-but I really want to get a hands on experience using the API Gateway)
Here are the questions I have for each of the above two approaches:
For 1  I dont understand how Lambda is calling the functions in the Flask application  According to my understanding  Lambda only calls functions that have the parameters event and context-or are the url calls (url formulated by the API Gateway) actually the events calling the separate functions in the Flask application  thus enabling Lambda to function as a serverless environment-this doesnt make sense to me because event  in most of the examples I analyzed  is the user input data  That means some of the functions in the application have no event and some do  which means Lambda somehow magically figures out what to do with different function calls 
I also know that Lambda does have limited capacity  so is this the best way  It seems to be the standard way of deploying a web application on Lambda 
For 2  I understand the steps leading to incorporating the API Gateway urls in the Flask application  The Flask application therefore will use the url to access the Lambda function and have HTTP endpoints for user access  HOWEVER  that means  if I have the Flask application on my local computer  the application will only be hosted when I run the application on my computer-I would like it to have persistent public access (hopefully)  I read about AWS Cloud9-would this be a good solution  Where should I deploy the application itself to optimize this architecture-without using services that take away the architectures severless-ness (like an EC2 instance maybe OR on S3  where I would be putting my frontend html files  and host a website)  Also  going back to 1 (sorry I am trying to organize my ideas in a coherent way  and its not working too well)  will the application run consistently as long as I leave the API Gateway endpoint open 
I dont know whats the best practice for deploying a Flask application using AWS Lambda and the API Gateway but based on my findings  the above two are most frequently used  It would be really helpful if you could answer my questions so I could actually start playing with AWS Lambda  Thank you  (+I did read all the Amazon documentations  and these are the final-remaining questions I have before I start experimenting:))
"
60856781,"When triggering my Spring Boot application on an AWS Lambda  I keep getting the error   I am unsure why this is happening and would like some more information 
Here is the stack trace:

My source code can be found here: 
Yes I know running Spring Boot on a lambda is dumb  but it is temporary  So  I dont have to pay for an EC2 instance  This is also not refined yet so I know there will be other things I should change 
EDIT: Here is the relevant code
This first one is the lambda handler  I originally had the commented out code but switched to the other because the start time was substantially faster  Both methods give the same error 
The second one is the class where the error is being encountered  which is my auth filter  I added the comment  to the second snippet so it is easier to see the exact location of where the exception is being thrown 


For more context  my source code can be found here: 
"
69848043,"We have s3 event notifications defined on a bucket without any prefix filtering and all events are sent to an SNS topic 
We would like to have an SNS filter policy to invoke a lambda for a specific s3 prefix  say   We could not modify the existing s3 event notification to create different event notifications based on prefix  Among other reasons there are limitations on the number of event notifications that can be configured on a bucket  capped at 100  and we have 100s of dirs in the bucket 
Example: SNS message delivery of an S3 event notification 

SNS filter matching doesnt seem to have support to filter strings by regex patterns or 
Options available are

Exact matching
Prefix matching
Anything-but matching
IP address matching

Ref: 
Is there a way to achieve this filtering in SNS  The other option is to have a lambda be invoked for all events and filter events in the lambda  but the volume of events in the specific s3 dir is significantly lower than the total events and it will not be cost efficient to have the lambda be invoked for all events 
"
55683373,"I have created a web application (demo:  or ) of Shopping cart hosted on AWS elastic beanstalk  I want to develop Alexa skill for this web application which takes credentials from a user via Alexa voice and validates them  After this  Alexa will ask which items the user wants to add in cart and checkout 
A web application is running successfully on AWS  I have tried to use AWS Lambda and Alexa skill kit but a bit confused about how to integrate them in Java hibernate  I also have tried to use AWS S3 to generate and store bill of user which user can download manually via clicking on generated URL or via selecting option to send the bill to a mailbox 
There will be two ways to order from the web application 

Using web browser 2  Using Alexa skill voice command

When a user opts for the 2nd option  Alexa will ask for credentials and validates them  After validation Alexa will ask which items the user wants to add in cart  Later on  it will check out  
The web application is running smoothly except that bill generation  Need suggestions for how to link Alexa with Java Hibernate 
"
52220991,"I am using a lambda function in a VPC to connect to an RDS instance in the same VPC  I am considering removing the lambda from the VPC to massively reduce the cold-start time but I want to keep my RDS instance in the VPC 
Can anyone foresee major problems with making the lambda function use an SSH tunnel to connect to a bastion instance within the VPC and subsequently to the RDS instance  Or something similar with a VPN 
There will obviously be some over-head as the traffic has an extra jump so to speak  but would it be significant enough to make this approach non-feasible  Or is the only current approach to keep the Lambda in the same VPC and try to keep and few invocations running 
I also pay for a NAT gateway so my Lambda in a VPC can access the internet  If I can get it out of the VPC by using an SSH tunnel to connect to the RDS instance it will also simplify my architecture here &amp; reduce my operating costs 
"
53498090,"Ive setup my CloudFront distribution to use a wildcard CNAME (* domain com)
Id like to know the subdomain in my Lambda Proxy Integration  For this i need the Host header which is available in CloudFront Access Logs under x-host-header 
API Gateway assigns Host header to example execute-api  endpoint name 
Is it still not possible to realise this with API Gateway  Adding an additional lambda origin request adds too much overhead and cost 
Additional resource related to this:
Link: 
Link: 
"
54901763,"One of the scary things about being a small fish in the AWS ocean is what seems to be unlimited liability in the unlikely event of a flood of transactions on a publicly exposed service  AWS is designed for the big guys  for whom availability is the be-all and end-all  Theres a great deal of effort in keeping services up  but apparently none when it comes to saving us from astronomical bills  Amazon seems to have been repeatedly asked for a spending cap  but AFAIK  the best theyve come up with is billing alerts  Ive read some horror stories  like the guy who set up a small website for family and friends and got a bill for $10 000  The best Amazon has done is provide billing alerts  and what if you are AFK  Quite large sums could disappear before you can shut down 
So  my cunning plan - to write a Lambda fired from a billing threshold event which raises the drawbridge and shuts down any public facing facilities 
So  I started with CloudFront and thats quite do-able  though disabling a distribution take some time to propagate 
Now we come to my first technical quandary  I thought I could just check all the buckets for public permissions and revoke them  But  since I last looked in detail at S3  theres this static website setting  So  how do I  programmatically  turn this off  Obviously I dont want to delete the bucket  To my surprise turning this on does not create a public permission in the ACL  Theres a service in the API to update properties on one of these static websites  but not to revoke it 
It seems to be somewhat the same with the API gateway  You can delete an API  but not suspend it  And if you delete it  then re-building will probably give you a different hostname  which creates some hastle 
Im trying to write a fairly generic Lambda and make it public domain 
"
69259019,"I am new to AWS and cloud technology in general  So  please bear with me if the use case below is a trivial one 
Well  I have a table in Amazon DynamoDB which I am exporting to Amazon S3 using exportTableToPointInTime API (ExportsToS3) on a scheduled basis everyday at 6 AM  It is being done using an AWS Lambda function in this way -

The CFT template of the AWS Lambda function takes care of creating lambda roles and policies  etc  along with scheduling using Cloudwatch events  This setup works and the table is exported to the target Amazon S3 bucket everyday at the scheduled time 
Now  the next thing I want is that after the export to Amazon S3 is complete  I should be able to invoke an another lambda function and pass the export status to that lambda function which does some processing with it 
The problem I am facing is that the above lambda function finishes execution almost immediately with the exportTableToPointInTime call returning status as IN_PROGRESS 
I tried capturing the response of the above call like -

Output of this is -

I am just obfuscating some values in the log with ****
As can be seen  the exportTableToPointInTime API call does not wait for the table to be exported completely  If it would have  it would have returned ExportStatus as either COMPLETED or FAILED 
Is there a way I can design the above use case to achieve my requirement - invoking an another lambda function only when the export is actually complete 
As of now  I have tried a brute force way to do it and which works but it definitely seems to be inefficient as it puts in a sleep there and also the lambda function is running for the entire duration of the export leading to cost impacts 

What can be done to better it or the above solution is okay 
Thanks  
"
55244420,"Im planning to move my lambda function configuration from environment variables to DynamoDb since my lambda functions share configurations and also I dont want to redeploy my lambda functions each time a configuration changes (my config changes frequently and once they do I have to redeploy so many lambda functions) 
But in order to improve the performance of my lambda functions and also to reduce the cost  Im not going to load the configuration per each execution  Instead  I will load the config into a global variable and since global variables persist across executions (as long as the lambda function is warmed up) I can reuse the same config without accessing DynamoDb  Heres a sample code:

So far everything is fine  Now  consider the time that DynamoDb is updated with the new configuration  The warmed-up lambda functions will continue using the old config before they are brought down by AWS and face a cold-start 
What I want to do is to signal lambda functions and force them to flush their warmed-up lambda functions and start over each time the configuration changes  I know I can redeploy them which will do exactly what I wanted  But thats what exactly I was escaping from in the first place  So  what are my options 
"
53467019,"Before everything:
I checked familar questions like:




And this one:



But I still have question:
So  Lets say I have Simple microservices project 
I have:

Ocelot - As Gateway
Identity server 4 - for All authorization and Authentication logic
Asp Core MVC - As my web project app 
Microsetrvice A 
Microservcie B
RabbitMQ - Event bus 
Some databases installed on premise    

Now I want to migrate this to serverless architecture  
From what I understand  I see here 2 options:

First Option 

Is Launch    EC2 (And this mean I need to pay for EC2 instance + Scale this EC2 instances) instance for deploy my Identity server  
Build Authorization Lambda  
Then Build AWS API Gateway  And All endpoint(which actually will AWS LAMBDA)  which required  protect by Authorization Lambda  
This options mean   all time when I call Autorize protected endpoint - I will call 2 lambda funciton ( Authorize lambda + ) - If this correct 

Second options  (IF I understand right) - Is Deploy Identity Server as AWS Lambda as well 

Databases and RabbitMQ I switch to Kinesis/SQS  and databases to RDS/DynamoDB
"
69726172,"I was looking at our bill and apparently we are charged more than $600 for Amazon Simple Storage Service USE2-Requests-Tier2  meaning that we have more than 1 billion GET requests a month  so about 3 million every day  We made sure that none of our S3 buckets are public so attacks should not be possible  I have no idea how we are getting so many requests as we only have about 20 active users of our app everyday  Assuming that each of them were to make about 10 GET requests to our API  which uses lambda and boto3 to download 10 files from S3 bucket to the lambdas tmp folders  then returns a value  it still wouldnt make sense for us to have about 3 millions GET requests a day 
We also have another EventBridge triggered lambda  which uses Athena to query our database (S3)  and will run every 2 hours  I dont know if this is a potential cause  Can anyone shed some light on this  And how we can take a better look into where and why are we getting so many GET requests  Thank you 
"
56927848,"I have a React app which calls API gateway  which in turn triggers my Lambda functions  Now for saving cost purpose due to the potentially let’s say  tens of millions of requests to the API gateway  I did some research and are looking at to potentially use ALB to invoke my Lambdas rather than API GW  My API GW is simply a Lambda-Proxy integration 
My question is with API GW I can add API keys and custom authorizers etc  but for ALB  how do I add a bit of authentication at the ALB layer  say only allow the invocation of my Lambda functions only from the client that I trust  Note my client is a static React app with no server behind it  I don’t need anything too fancy but just want to reject requests other than my trusted request origins  Inside Lambda to cover browser I will just add CORS to response header  But at ALB level  how do I achieve what I required 
Looking forward to getting some shed of lights here 
Thanks
"
63086497,"I try to reduce the costs on my mobile app backend 
Today I use an ASP NET Core Web API plugged to an SQL Server instance and I use Entity Framework Core  Everything in Azure Mobile App services + SQL Server 
I plan to migrate to a serverless approach and cloud paas db instance 
I chose AWS because moving to serverless lambda from an existing API Core project seems much simpler than with Azure Functions 
In my way to migrate I plan to do:

Move my Web API to a serverless app  I will use  way

I will use Aurora under MySql  Then I will not pay anymore the licenses for SQL Server  I will change in my backend the connection string in my Entity Framework Core and do some minor changes to move from SQL Server provider to MySQL  And I will purchase for instance reserved 1 year 


Based on this I think I will reduce my costs (move from SQL Server to aurora MySQL)  gain in scalability and performance with serverless functions 
Is it a good way 
Finally in my Web API  NET Core project  I use Swagger UI and Hangfire UI 
May I use it if I move my project as serverless 
Thanks
"
44347243,"I currently have a functional  implemented with  running on an   but I would like to come up with a  implementation using  with    I am aware that there are wonderful SaaS providers such as   but the price for the thousands of user accounts we will require is prohibitively expensive 
I have discovered   which is useful  but not    For now  I only require a  grant  which seems very simple   But I would like to be able to leverage some  which will make it easier to implement more grants and flows for the future   I have investigated   and  libraries  but the documentation appears to be useless for my requirements 
Does anyone have any advice on how to proceed 
"
65496327,"I need to load a spacy model with more than 600MB to AWS Lambda  but I just found by downloading the model from S3 to /tmp  but it is larger than allowed (512MB)  so an error occurs 
I also tried to use EFS and it worked  but the value was very expensive because it was necessary to configure NAT gateway 
Is it possible to load the model directly from the S3 
I have another idea that can work  which is using container no lambda  but first I would like to know if it is possible to do it with S3 
"
52633661,"I have 2 dozen lambdas  I noticed my bill was high this month and I see have 700k invocations  Is there an easy way to view all the stats for all my lambdas in one view  and ‘sort by invocations within period’  This kind of dashboard would be very valuable 
"
53974548,"I have always learnt in theory that creating new connection to databases is costly operation  So we should keep open connection pool and use it for db operations 
When considering AWS lambda  Suppose lambda function wants to operate on db  then we need to create a connection to db  After operations  db needs to be closed  If simultaneously 100s of lambda function are executing then 100s of db connection open/close are being done  Which is theoretically bad pattern 
If this is so then is it inappropriate to use AWS lambda when db operations are involved 
"
67184556,"I want to redirect all traffic to my pricing page via a subdomain to my homepage  I cant figure out how to add wildcards in the has value 
This syntax does not work:

Any ideas 
"
46104895,"I have to write code in react-native that allows a user to upload videos to amazon s3 to be transcoded for consumption by various devices   For the processing after the upload occurs; I am reviewing two approaches:
1) I can use Lambda with ffmpeg to handle the transcoding immediately after the uploading occurs (my fear here would be the amount of time required to transcode the videos and the effect on pricing if it takes a considerable amount of time)   
2) I can have s3 pass an sns message to a rest api after the created event occurs and the rest api generate a rabbitmq message that will be processed by worker that will perform the transcoding using ffmpeg 
Option 1) seems to be the preferable option based on a completion time perspective   How concerned should I be with using 1) considering how long video transcoding might take as opposed to option 2)   
Also  regardless  I need a way to pass additional parameters to lambda or along the sns messaging that would allow me to somehow associate the user who uploaded the video with their account   Is there a way to pass additional text-based values to s3 to pass along to lambda or along sns when the upload completes  as a caveat I plan to upload the video directly to s3 using the rest layer(found this answer here: ) 
"
